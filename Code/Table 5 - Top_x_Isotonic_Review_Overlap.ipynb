{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Zd8s4wjVz-gv"
   },
   "source": [
    "# **Import Google Drive**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 506,
     "status": "ok",
     "timestamp": 1745868723177,
     "user": {
      "displayName": "Buxin Su",
      "userId": "12574803226597557409"
     },
     "user_tz": 240
    },
    "id": "kpj7DF1k-jRR",
    "outputId": "b67dc307-4ff4-4d1b-f827-206cedce275c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7PcDKgM_0ElJ"
   },
   "source": [
    "# **Setting**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "executionInfo": {
     "elapsed": 1,
     "status": "ok",
     "timestamp": 1745868723179,
     "user": {
      "displayName": "Buxin Su",
      "userId": "12574803226597557409"
     },
     "user_tz": 240
    },
    "id": "3LvEW5gO0E-K"
   },
   "outputs": [],
   "source": [
    "from sklearn.isotonic import isotonic_regression\n",
    "import cvxpy as cp\n",
    "import numpy as np\n",
    "import csv, os\n",
    "from scipy import stats\n",
    "from sklearn import metrics\n",
    "import itertools\n",
    "import pandas as pd\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import matplotlib.pyplot as plt\n",
    "import statistics\n",
    "from scipy.stats import levene\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=RuntimeWarning)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kPWWcc7LiVmU"
   },
   "source": [
    "# **Function: Partition all submissions according to \"Greedy\" and \"Multi-owner\" methods**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "executionInfo": {
     "elapsed": 1,
     "status": "ok",
     "timestamp": 1745868723181,
     "user": {
      "displayName": "Buxin Su",
      "userId": "12574803226597557409"
     },
     "user_tz": 240
    },
    "id": "AlzU8-hqiU4Z"
   },
   "outputs": [],
   "source": [
    "def validate(partition, graph, n):\n",
    "\t# check that\n",
    "\t# 1. each paper is in exactly one partition\n",
    "\t# 2. the number of papers in all partition is equal to the number of papers\n",
    "\t# 3. each partition has at least two authors owns all papers in the partition\n",
    "\n",
    "\tpapers = set()\n",
    "\tfull_author_parts = []\n",
    "\tfor part in partition[:-1]:\n",
    "\t\tassert( len(part.intersection(papers)) == 0 )\n",
    "\t\tpapers |= part\n",
    "\t\t# find all authors that can rank all papers in this part\n",
    "\t\tcnt = 0\n",
    "\t\tauthor_part = set()\n",
    "\t\tfor author, val in graph.items():\n",
    "\t\t\tif len(val.intersection(part)) == len(part):\n",
    "\t\t\t\tcnt += 1\n",
    "\t\t\t\tauthor_part.add(author)\n",
    "\n",
    "\t\t# assert( cnt >= 2 )\n",
    "\t\tfull_author_parts.append(author_part)\n",
    "\n",
    "\t# add the last partition\n",
    "\tfull_author_parts.append(set())\n",
    "\tpapers |= partition[-1]\n",
    "\tassert(len(papers) == n)\n",
    "\n",
    "\treturn full_author_parts\n",
    "\n",
    "\n",
    "def greedy(graph, m, n, randomize=False, level=1):\n",
    "\tpartition = []\n",
    "\tauthor_parts = []\n",
    "\tallocated_papers = set()\n",
    "\n",
    "\tif level == 1:\n",
    "\t\tparts = [ graph[i].copy() for i in range(m) ]\n",
    "\t\tindex2pair = [ set([i]) for i in range(m) ]\n",
    "\telif level == 2:\n",
    "\t\tparts = [ graph[i].intersection(graph[j])  for i in range(m) for j in range(i+1, m) ]\n",
    "\t\tindex2pair = [ set([i,j]) for i in range(m) for j in range(i+1, m) ]\n",
    "\n",
    "\tmax_idx = 0\n",
    "\tmax_val = 0\n",
    "\tactive_indices = set( [i for i in range(len(parts)) if len(parts[i]) > 1] )\n",
    "\t# for i in range(0, len(parts)):\n",
    "\tfor i in active_indices:\n",
    "\t\tif len(parts[i]) > max_val:\n",
    "\t\t\tmax_idx = i\n",
    "\t\t\tmax_val = len(parts[i])\n",
    "\n",
    "\twhile len(allocated_papers) < n and len(parts[max_idx]) > 1:\n",
    "\t\tmax_part = parts[max_idx].copy()\n",
    "\t\tpartition.append( max_part )\n",
    "\t\tauthor_parts.append( index2pair[max_idx] )\n",
    "\t\tallocated_papers |= max_part\n",
    "\n",
    "\t\tmax_idx = 0\n",
    "\t\tmax_val = 0\n",
    "\t\t# for i in range(0, len(parts)):\n",
    "\t\tto_remove = set()\n",
    "\t\tfor i in active_indices:\n",
    "\t\t\tparts[i].difference_update(max_part)\n",
    "\t\t\tif len(parts[i]) < 2:\n",
    "\t\t\t\tto_remove.add(i)\n",
    "\t\t\t\tcontinue\n",
    "\t\t\tif len(parts[i]) > max_val:\n",
    "\t\t\t\tmax_idx = i\n",
    "\t\t\t\tmax_val = len(parts[i])\n",
    "\t\tmax_part = parts[max_idx].copy()\n",
    "\t\tactive_indices.difference_update(to_remove)\n",
    "\n",
    "\t# add all remaining papers to the last partition\n",
    "\tpartition.append(set())\n",
    "\tauthor_parts.append(set())\n",
    "\tfor i in range(n):\n",
    "\t\tif i not in allocated_papers:\n",
    "\t\t\tpartition[-1].add(i)\n",
    "\n",
    "\treturn partition, author_parts\n",
    "\n",
    "\n",
    "def arbitrary(graph, m, n, randomize=False):\n",
    "\tpartition = []\n",
    "\tauthor_parts = []\n",
    "\tallocated_papers = set()\n",
    "\n",
    "\tparts = [ graph[i].copy() for i in range(m) ]\n",
    "\tindex2pair = [ set([i]) for i in range(m) ]\n",
    "\n",
    "\tidx = 0\n",
    "\twhile len(parts[idx]) < 2 and idx < len(parts)-1: idx += 1\n",
    "\n",
    "\twhile len(allocated_papers) < n and idx != -1:\n",
    "\t\tpart = parts[idx].copy()\n",
    "\n",
    "\t\tpartition.append( part )\n",
    "\t\tauthor_parts.append( index2pair[idx] )\n",
    "\t\tallocated_papers |= part\n",
    "\n",
    "\t\tidx = -1\n",
    "\t\tval = None\n",
    "\t\tfor i in range(0, len(parts)):\n",
    "\t\t\tparts[i].difference_update(part)\n",
    "\t\t\tif len(parts[i]) >= 2:\n",
    "\t\t\t\tidx = i\n",
    "\t\t\t\tval = len(parts[i])\n",
    "\n",
    "\tpartition.append(set())\n",
    "\tauthor_parts.append(set())\n",
    "\tfor i in range(n):\n",
    "\t\tif i not in allocated_papers:\n",
    "\t\t\tpartition[-1].add(i)\n",
    "\n",
    "\treturn partition, author_parts\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kQQuVCdX2UKJ"
   },
   "source": [
    "# **Greedy Isotonic Scores, Proxy**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "e27iIugz2grj"
   },
   "source": [
    "## Load CSV file into a pandas DataFrame\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 512,
     "status": "ok",
     "timestamp": 1745868723698,
     "user": {
      "displayName": "Buxin Su",
      "userId": "12574803226597557409"
     },
     "user_tz": 240
    },
    "id": "tn0ZcvFA2g_a"
   },
   "outputs": [],
   "source": [
    "# Load CSV file into a pandas DataFrame\n",
    "df = pd.read_csv(r'proxy_score.csv')\n",
    "df = df.drop_duplicates(['submission_idx', 'author_idx'])\n",
    "\n",
    "\n",
    "# Extract the unique authors from the DataFrame\n",
    "authors = df['author_idx'].unique()\n",
    "submissions = df['submission_idx'].unique()\n",
    "\n",
    "author_submission = {}\n",
    "for author in authors:\n",
    "    submissionss = list( set(df[df['author_idx'] == author]['submission_idx'].tolist()) )\n",
    "    author_submission[author] = submissionss\n",
    "\n",
    "m_2 = len(author_submission)\n",
    "n_2 = len(submissions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lSrynyyK2pdI"
   },
   "source": [
    "## Organize all the authors and submissions as the following 'graph': authors = [..., {..., paper_idx : ranking, ...}, ...]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "executionInfo": {
     "elapsed": 1785,
     "status": "ok",
     "timestamp": 1745868725484,
     "user": {
      "displayName": "Buxin Su",
      "userId": "12574803226597557409"
     },
     "user_tz": 240
    },
    "id": "uNDek9xm2pth"
   },
   "outputs": [],
   "source": [
    "authors = []\n",
    "for author in author_submission:\n",
    "    submission_ranking = {}\n",
    "    for i in range(len(author_submission[author])):\n",
    "        submission_ranking[author_submission[author][i]] = df[(df['submission_idx'] == author_submission[author][i]) & (df['author_idx'] == author)]['rank'].tolist()\n",
    "        submission_ranking[author_submission[author][i]] = submission_ranking[author_submission[author][i]][0]\n",
    "    authors.append(submission_ranking)\n",
    "\n",
    "graph = {}\n",
    "for i, author in enumerate(authors):\n",
    "    graph[i] = set( int(k) for k in author.keys())\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9J4CQkym30mf"
   },
   "source": [
    "## Greedy Isotonic\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "executionInfo": {
     "elapsed": 4249,
     "status": "ok",
     "timestamp": 1745868729732,
     "user": {
      "displayName": "Buxin Su",
      "userId": "12574803226597557409"
     },
     "user_tz": 240
    },
    "id": "tPKDhzqM4aIB"
   },
   "outputs": [],
   "source": [
    "# Partition all the graph according to greedy algorithm\n",
    "partition, author_parts = greedy(graph, m_2, n_2)\n",
    "author_parts = validate(partition, graph, n_2)\n",
    "\n",
    "calibrated_scores = np.zeros(n_2)\n",
    "for part, author_part in zip(partition, author_parts):\n",
    "  if len(author_part) == 0:\n",
    "    for i in part: calibrated_scores[i] = df[df['submission_idx'] == i]['rating_0312_mean'].tolist()[0]\n",
    "    continue\n",
    "  paper_part = list(part)\n",
    "\n",
    "\n",
    "\n",
    "  # Organize each block by {author: [submission, rank, score]}.\n",
    "  author_submission_rank_old = {}\n",
    "  for author in author_part:\n",
    "    author_submission_rank_old[author] = []\n",
    "    for i in range(len(paper_part)):\n",
    "        rank = df[(df['submission_idx'] == paper_part[i]) & (df['author_idx'] == author)]['rank'].tolist()[0]\n",
    "        ratings = df[(df['submission_idx'] == paper_part[i]) & (df['author_idx'] == author)]['rating_0312_mean'].tolist()[0]\n",
    "        author_submission_rank_old[author].append((paper_part[i], rank, ratings))\n",
    "\n",
    "\n",
    "\n",
    "  # Sort submissions by rank; in case of ties, sort by score.\n",
    "  def sort_submissions(author_submission_rank_old):\n",
    "    for author in author_submission_rank_old:\n",
    "      author_submission_rank_old[author].sort(key=lambda x: (x[1], -x[2]), reverse=False)\n",
    "    return author_submission_rank_old\n",
    "  author_submission_rank_old = sort_submissions(author_submission_rank_old)\n",
    "\n",
    "\n",
    "\n",
    "  # Compute isotonic scores for each author in the block.\n",
    "  author_submission_rank_greedy_iso = {}\n",
    "  for author in author_submission_rank_old:\n",
    "      ir_rank = []\n",
    "      for i in range(len(author_submission_rank_old[author])):\n",
    "          r1 = author_submission_rank_old[author][i][2]\n",
    "          ir_rank.append(r1)\n",
    "      ir_rank = np.array(ir_rank)\n",
    "      ir_rank_pred =  isotonic_regression(ir_rank, sample_weight = None, y_min=0.0, y_max=10.0, increasing=False)\n",
    "\n",
    "      author_submission_rank_greedy_iso[author] = []\n",
    "      for i in range(len(author_submission_rank_old[author])):\n",
    "          author_submission_rank_greedy_iso[author].append((author_submission_rank_old[author][i][0], author_submission_rank_old[author][i][1], ir_rank_pred[i]))\n",
    "\n",
    "\n",
    "\n",
    "  # For multi-author submissions in a block, average the scores to get the isotonic score.\n",
    "  submission_greedy_iso_rating = {}\n",
    "  for submission in paper_part:\n",
    "      submission_greedy_iso_rating[submission] = []\n",
    "\n",
    "  for author in author_submission_rank_greedy_iso:\n",
    "      for i in range(len(author_submission_rank_greedy_iso[author])):\n",
    "          submission_greedy_iso_rating[author_submission_rank_greedy_iso[author][i][0]].append(author_submission_rank_greedy_iso[author][i][2])\n",
    "\n",
    "  for submission in submission_greedy_iso_rating:\n",
    "      submission_greedy_iso_rating[submission] = [float(rating) for rating in submission_greedy_iso_rating[submission]]\n",
    "      avg_rating = sum(submission_greedy_iso_rating[submission])/len(submission_greedy_iso_rating[submission])\n",
    "      submission_greedy_iso_rating[submission] = avg_rating\n",
    "\n",
    "  for i in paper_part:\n",
    "    calibrated_scores[i] = submission_greedy_iso_rating[i]\n",
    "\n",
    "\n",
    "\n",
    "# Greedy Isotonic Score\n",
    "greedy_iso_rating = {}\n",
    "for i in range(n_2):\n",
    "  greedy_iso_rating[i] = calibrated_scores[i]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Pb3YkCfz4b8T"
   },
   "source": [
    "## Compute MSE values for all submissions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "executionInfo": {
     "elapsed": 819,
     "status": "ok",
     "timestamp": 1745868730547,
     "user": {
      "displayName": "Buxin Su",
      "userId": "12574803226597557409"
     },
     "user_tz": 240
    },
    "id": "mCQnj1UK5KJY"
   },
   "outputs": [],
   "source": [
    "# proxy\n",
    "submission_true_rating = {}\n",
    "for submission in range(n_2):\n",
    "    submission_true_rating[submission] = df[df['submission_idx'] == submission]['rating_0312_mean'].tolist()\n",
    "    submission_true_rating[submission] = submission_true_rating[submission][0]\n",
    "\n",
    "True_score_multi_iso = []\n",
    "for i in range(n_2):\n",
    "    True_score_multi_iso.append(submission_true_rating[i])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WYVEKwLdmA_J"
   },
   "source": [
    "# Overlap Rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 9,
     "status": "ok",
     "timestamp": 1745868730559,
     "user": {
      "displayName": "Buxin Su",
      "userId": "12574803226597557409"
     },
     "user_tz": 240
    },
    "id": "cnr6z9lZefzi",
    "outputId": "3e8444a9-8447-463d-ae8b-6b5b68761e84"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.7063492063492064,\n",
       " 0.691699604743083,\n",
       " 0.7308707124010554,\n",
       " 0.7806324110671937,\n",
       " 0.7753164556962026,\n",
       " 0.8326745718050066]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Percentage = [0.05, 0.1, 0.15, 0.2, 0.25, 0.3]\n",
    "adhoc_overlap_percentage = []\n",
    "multi_overlap_percentage = []\n",
    "greedy_overlap_percentage = []\n",
    "for i in range(len(Percentage)):\n",
    "  percent = Percentage[i]\n",
    "  # Find the top 10% values in old_rating\n",
    "  top_x_greedy = sorted(greedy_iso_rating, key=greedy_iso_rating.get, reverse=True)[:int(len(greedy_iso_rating)* percent)]\n",
    "\n",
    "  # Find the top 10% values in old_rating\n",
    "  top_x_true = sorted(submission_true_rating, key=submission_true_rating.get, reverse=True)[:int(len(submission_true_rating)* percent)]\n",
    "\n",
    "  top_x_greedy = set(top_x_greedy)\n",
    "  top_x_true = set(top_x_true)\n",
    "\n",
    "  greedy_overlap = top_x_greedy & top_x_true\n",
    "  # Count the number of overlapping elements\n",
    "  greedy_overlap_count = len(greedy_overlap)\n",
    "  greedy_overlap_percentage.append(greedy_overlap_count/len(top_x_true))\n",
    "\n",
    "greedy_overlap_percentage"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyOv9jRBTAznAg6JvE6qJO5e",
   "collapsed_sections": [
    "kPWWcc7LiVmU"
   ],
   "mount_file_id": "1ngu2BIK6f7Db0D82UHdK9A1J1Rc24O3S",
   "provenance": [
    {
     "file_id": "1ngu2BIK6f7Db0D82UHdK9A1J1Rc24O3S",
     "timestamp": 1720710297158
    }
   ]
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
