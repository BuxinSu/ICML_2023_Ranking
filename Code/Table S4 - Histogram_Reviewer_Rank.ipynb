{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Zd8s4wjVz-gv"
   },
   "source": [
    "# **Import Google Drive**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 17581,
     "status": "ok",
     "timestamp": 1745874252990,
     "user": {
      "displayName": "Buxin Su",
      "userId": "12574803226597557409"
     },
     "user_tz": 240
    },
    "id": "kpj7DF1k-jRR",
    "outputId": "aa7e67c4-3aef-44da-e5bc-e9dcf2dcf57c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7PcDKgM_0ElJ"
   },
   "source": [
    "# **Setting**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "executionInfo": {
     "elapsed": 8650,
     "status": "ok",
     "timestamp": 1745874261638,
     "user": {
      "displayName": "Buxin Su",
      "userId": "12574803226597557409"
     },
     "user_tz": 240
    },
    "id": "3LvEW5gO0E-K"
   },
   "outputs": [],
   "source": [
    "from sklearn.isotonic import isotonic_regression\n",
    "import cvxpy as cp\n",
    "import numpy as np\n",
    "import csv, os\n",
    "from scipy import stats\n",
    "from sklearn import metrics\n",
    "import itertools\n",
    "import pandas as pd\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import matplotlib.pyplot as plt\n",
    "import statistics\n",
    "from scipy.stats import levene\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "from sklearn.metrics import r2_score\n",
    "warnings.filterwarnings(\"ignore\", category=RuntimeWarning)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kPWWcc7LiVmU"
   },
   "source": [
    "# **Function: Partition all submissions according to \"Greedy\" and \"Multi-owner\" methods**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "executionInfo": {
     "elapsed": 11,
     "status": "ok",
     "timestamp": 1745874261660,
     "user": {
      "displayName": "Buxin Su",
      "userId": "12574803226597557409"
     },
     "user_tz": 240
    },
    "id": "AlzU8-hqiU4Z"
   },
   "outputs": [],
   "source": [
    "def validate(partition, graph, n):\n",
    "\t# check that\n",
    "\t# 1. each paper is in exactly one partition\n",
    "\t# 2. the number of papers in all partition is equal to the number of papers\n",
    "\t# 3. each partition has at least two authors owns all papers in the partition\n",
    "\n",
    "\tpapers = set()\n",
    "\tfull_author_parts = []\n",
    "\tfor part in partition[:-1]:\n",
    "\t\tassert( len(part.intersection(papers)) == 0 )\n",
    "\t\tpapers |= part\n",
    "\t\t# find all authors that can rank all papers in this part\n",
    "\t\tcnt = 0\n",
    "\t\tauthor_part = set()\n",
    "\t\tfor author, val in graph.items():\n",
    "\t\t\tif len(val.intersection(part)) == len(part):\n",
    "\t\t\t\tcnt += 1\n",
    "\t\t\t\tauthor_part.add(author)\n",
    "\n",
    "\t\t# assert( cnt >= 2 )\n",
    "\t\tfull_author_parts.append(author_part)\n",
    "\n",
    "\t# add the last partition\n",
    "\tfull_author_parts.append(set())\n",
    "\tpapers |= partition[-1]\n",
    "\tassert(len(papers) == n)\n",
    "\n",
    "\treturn full_author_parts\n",
    "\n",
    "\n",
    "def greedy(graph, m, n, randomize=False, level=1):\n",
    "\tpartition = []\n",
    "\tauthor_parts = []\n",
    "\tallocated_papers = set()\n",
    "\n",
    "\tif level == 1:\n",
    "\t\tparts = [ graph[i].copy() for i in range(m) ]\n",
    "\t\tindex2pair = [ set([i]) for i in range(m) ]\n",
    "\telif level == 2:\n",
    "\t\tparts = [ graph[i].intersection(graph[j])  for i in range(m) for j in range(i+1, m) ]\n",
    "\t\tindex2pair = [ set([i,j]) for i in range(m) for j in range(i+1, m) ]\n",
    "\n",
    "\tmax_idx = 0\n",
    "\tmax_val = 0\n",
    "\tactive_indices = set( [i for i in range(len(parts)) if len(parts[i]) > 1] )\n",
    "\t# for i in range(0, len(parts)):\n",
    "\tfor i in active_indices:\n",
    "\t\tif len(parts[i]) > max_val:\n",
    "\t\t\tmax_idx = i\n",
    "\t\t\tmax_val = len(parts[i])\n",
    "\n",
    "\twhile len(allocated_papers) < n and len(parts[max_idx]) > 1:\n",
    "\t\tmax_part = parts[max_idx].copy()\n",
    "\t\tpartition.append( max_part )\n",
    "\t\tauthor_parts.append( index2pair[max_idx] )\n",
    "\t\tallocated_papers |= max_part\n",
    "\n",
    "\t\tmax_idx = 0\n",
    "\t\tmax_val = 0\n",
    "\t\t# for i in range(0, len(parts)):\n",
    "\t\tto_remove = set()\n",
    "\t\tfor i in active_indices:\n",
    "\t\t\tparts[i].difference_update(max_part)\n",
    "\t\t\tif len(parts[i]) < 2:\n",
    "\t\t\t\tto_remove.add(i)\n",
    "\t\t\t\tcontinue\n",
    "\t\t\tif len(parts[i]) > max_val:\n",
    "\t\t\t\tmax_idx = i\n",
    "\t\t\t\tmax_val = len(parts[i])\n",
    "\t\tmax_part = parts[max_idx].copy()\n",
    "\t\tactive_indices.difference_update(to_remove)\n",
    "\n",
    "\t# add all remaining papers to the last partition\n",
    "\tpartition.append(set())\n",
    "\tauthor_parts.append(set())\n",
    "\tfor i in range(n):\n",
    "\t\tif i not in allocated_papers:\n",
    "\t\t\tpartition[-1].add(i)\n",
    "\n",
    "\treturn partition, author_parts\n",
    "\n",
    "\n",
    "def arbitrary(graph, m, n, randomize=False):\n",
    "\tpartition = []\n",
    "\tauthor_parts = []\n",
    "\tallocated_papers = set()\n",
    "\n",
    "\tparts = [ graph[i].copy() for i in range(m) ]\n",
    "\tindex2pair = [ set([i]) for i in range(m) ]\n",
    "\n",
    "\tidx = 0\n",
    "\twhile len(parts[idx]) < 2 and idx < len(parts)-1: idx += 1\n",
    "\n",
    "\twhile len(allocated_papers) < n and idx != -1:\n",
    "\t\tpart = parts[idx].copy()\n",
    "\n",
    "\t\tpartition.append( part )\n",
    "\t\tauthor_parts.append( index2pair[idx] )\n",
    "\t\tallocated_papers |= part\n",
    "\n",
    "\t\tidx = -1\n",
    "\t\tval = None\n",
    "\t\tfor i in range(0, len(parts)):\n",
    "\t\t\tparts[i].difference_update(part)\n",
    "\t\t\tif len(parts[i]) >= 2:\n",
    "\t\t\t\tidx = i\n",
    "\t\t\t\tval = len(parts[i])\n",
    "\n",
    "\tpartition.append(set())\n",
    "\tauthor_parts.append(set())\n",
    "\tfor i in range(n):\n",
    "\t\tif i not in allocated_papers:\n",
    "\t\t\tpartition[-1].add(i)\n",
    "\n",
    "\treturn partition, author_parts\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "F7Y3yIRN8_p2"
   },
   "source": [
    "# **Simple-averaging Isotonic Scores, Proxy**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RnkrFd1f0YIN"
   },
   "source": [
    "## Load CSV file into a pandas DataFrame\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1920,
     "status": "ok",
     "timestamp": 1745874263588,
     "user": {
      "displayName": "Buxin Su",
      "userId": "12574803226597557409"
     },
     "user_tz": 240
    },
    "id": "lKt6q-xygDdO",
    "outputId": "0da847cc-be92-475a-921b-96d43040de12"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1340\n"
     ]
    }
   ],
   "source": [
    "# Load CSV file into a pandas DataFrame\n",
    "df = pd.read_csv(r'proxy_score.csv')\n",
    "df = df.drop_duplicates(['submission_idx', 'author_idx'])\n",
    "\n",
    "# Extract the unique authors from the DataFrame\n",
    "authors = df['author_idx'].unique()\n",
    "print(len(authors))\n",
    "\n",
    "# Load confidence dataset\n",
    "df_conf_path = \"aggregated_results_anonymized.csv\"\n",
    "df_conf = pd.read_csv(df_conf_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bdAAbN5DgDzu"
   },
   "source": [
    "## Filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 13,
     "status": "ok",
     "timestamp": 1745874263613,
     "user": {
      "displayName": "Buxin Su",
      "userId": "12574803226597557409"
     },
     "user_tz": 240
    },
    "id": "Ak-WjHX90Zv6",
    "outputId": "22087923-e6f4-4b3c-e94b-9f43db6ba8e8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "859\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Find authors with 'Not very confident' confidence level\n",
    "low_conf_authors = df_conf[df_conf['would_you_review_for_ICML_2023'].isin(['No'])]['author_id'].unique()\n",
    "# Remove these authors from the original dataset\n",
    "df = df[~df['author_id'].isin(low_conf_authors)]\n",
    "# Extract the unique authors from the DataFrame\n",
    "\n",
    "authors = df['author_idx'].unique()\n",
    "print(len(authors))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 39,
     "status": "ok",
     "timestamp": 1745874263653,
     "user": {
      "displayName": "Buxin Su",
      "userId": "12574803226597557409"
     },
     "user_tz": 240
    },
    "id": "NVn3MGtxgjod",
    "outputId": "8dff2d53-6c86-4708-ffd6-2e427dc0cf00"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-6-513a9d726c2d>:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['author_idx'] = df['author_id'].map(author_idx_mapping)\n",
      "<ipython-input-6-513a9d726c2d>:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['submission_idx'] = df['submission_id'].map(submission_idx_mapping)\n"
     ]
    }
   ],
   "source": [
    "# Step 2: Assign unique indices to author_id\n",
    "unique_authors = df['author_id'].unique()\n",
    "author_idx_mapping = {author: idx for idx, author in enumerate(unique_authors)}\n",
    "df['author_idx'] = df['author_id'].map(author_idx_mapping)\n",
    "\n",
    "# Step 3: Assign unique indices to submission_id\n",
    "unique_submissions = df['submission_id'].unique()\n",
    "submission_idx_mapping = {submission: idx for idx, submission in enumerate(unique_submissions)}\n",
    "df['submission_idx'] = df['submission_id'].map(submission_idx_mapping)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7mCPHu1C0bDc"
   },
   "source": [
    "## Organize each block by {author: [submission, rank, score]}.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "executionInfo": {
     "elapsed": 3076,
     "status": "ok",
     "timestamp": 1745874266728,
     "user": {
      "displayName": "Buxin Su",
      "userId": "12574803226597557409"
     },
     "user_tz": 240
    },
    "id": "Sx-FhyBm0ebi"
   },
   "outputs": [],
   "source": [
    "author_submission_rank_old = {}\n",
    "authors = df['author_idx'].unique()\n",
    "for author in authors:\n",
    "    author_submission_rank_old[author] = []\n",
    "    submissions = list(set(df[df['author_idx'] == author]['submission_idx'].tolist()))\n",
    "\n",
    "    for i in range(len(submissions)):\n",
    "        rank = df[(df['submission_idx'] == submissions[i]) & (df['author_idx'] == author)]['rank'].tolist()[0]\n",
    "        ratings = df[(df['submission_idx'] == submissions[i]) & (df['author_idx'] == author)]['score'].tolist()[0]\n",
    "        author_submission_rank_old[author].append((submissions[i], rank, ratings))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MFF6_8mg0pJZ"
   },
   "source": [
    "## Sort submissions by rank; in case of ties, sort by score.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1745874266729,
     "user": {
      "displayName": "Buxin Su",
      "userId": "12574803226597557409"
     },
     "user_tz": 240
    },
    "id": "aVSHptys0quM"
   },
   "outputs": [],
   "source": [
    "def sort_submissions(author_submission_rank_old):\n",
    "    for author in author_submission_rank_old:\n",
    "        author_submission_rank_old[author].sort(key=lambda x: (x[1], -x[2]), reverse=False)\n",
    "    return author_submission_rank_old\n",
    "\n",
    "author_submission_rank_old = sort_submissions(author_submission_rank_old)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BZUWHz7j0udU"
   },
   "source": [
    "## Compute isotonic scores for each author.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "executionInfo": {
     "elapsed": 268,
     "status": "ok",
     "timestamp": 1745874266995,
     "user": {
      "displayName": "Buxin Su",
      "userId": "12574803226597557409"
     },
     "user_tz": 240
    },
    "id": "KVQW_Pc70yTL"
   },
   "outputs": [],
   "source": [
    "author_submission_rank_new = {}\n",
    "for author in author_submission_rank_old:\n",
    "    ir_rank = []\n",
    "    for i in range(len(author_submission_rank_old[author])):\n",
    "        r1 = author_submission_rank_old[author][i][2]\n",
    "        ir_rank.append(r1)\n",
    "    ir_rank = np.array(ir_rank)\n",
    "    ir_rank_pred =  isotonic_regression(ir_rank, sample_weight = None, y_min=0.0, y_max=10.0, increasing=False)\n",
    "\n",
    "    author_submission_rank_new[author] = []\n",
    "    for i in range(len(author_submission_rank_old[author])):\n",
    "        author_submission_rank_new[author].append((author_submission_rank_old[author][i][0], author_submission_rank_old[author][i][1], ir_rank_pred[i]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bFKfCIwq00Bx"
   },
   "source": [
    "## For multi-author submissions, average the scores to get the isotonic score.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "executionInfo": {
     "elapsed": 74,
     "status": "ok",
     "timestamp": 1745874267076,
     "user": {
      "displayName": "Buxin Su",
      "userId": "12574803226597557409"
     },
     "user_tz": 240
    },
    "id": "hRHAlg3u01Xj"
   },
   "outputs": [],
   "source": [
    "final_submission_list = df['submission_idx'].unique()\n",
    "\n",
    "submission_new_rating = {}\n",
    "for submission in final_submission_list:\n",
    "    submission_new_rating[submission] = []\n",
    "\n",
    "for author in author_submission_rank_new:\n",
    "    for i in range(len(author_submission_rank_new[author])):\n",
    "      if author_submission_rank_new[author][i][0] in final_submission_list:\n",
    "        submission_new_rating[author_submission_rank_new[author][i][0]].append(author_submission_rank_new[author][i][2])\n",
    "\n",
    "for submission in final_submission_list:\n",
    "    submission_new_rating[submission] = [float(rating) for rating in submission_new_rating[submission]]\n",
    "    avg_rating = sum(submission_new_rating[submission])/len(submission_new_rating[submission])\n",
    "    submission_new_rating[submission] = avg_rating"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SdDxNarq1IiI"
   },
   "source": [
    "## Compute MSE values for all submissions and Plot.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1936,
     "status": "ok",
     "timestamp": 1745874269011,
     "user": {
      "displayName": "Buxin Su",
      "userId": "12574803226597557409"
     },
     "user_tz": 240
    },
    "id": "nbHJiLkM1QgC",
    "outputId": "26ea9665-aa0d-418b-da1d-d603048fa3b7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Simple-averaging Isotonic Mechanism 1.9344992728846817\n",
      "Review Rating 2.542196833930705\n",
      "Before Rebuttal with proxy t-test for greedy: 12.408551112545776\n",
      "Before Rebuttal with proxy p-value for greedy: 2.5097316053309944e-34\n"
     ]
    }
   ],
   "source": [
    "# Isotonic score\n",
    "adhoc_iso_rating = []\n",
    "for submission in final_submission_list:\n",
    "  adhoc_iso_rating.append(submission_new_rating[submission])\n",
    "\n",
    "\n",
    "\n",
    "# Proxy\n",
    "submission_true_rating = {}\n",
    "for submission in final_submission_list:\n",
    "    submission_true_rating[submission] = df[df['submission_idx'] == submission]['proxy'].tolist()\n",
    "    submission_true_rating[submission] = submission_true_rating[submission][0]\n",
    "\n",
    "True_score_multi_iso = []\n",
    "for submission in final_submission_list:\n",
    "    True_score_multi_iso.append(submission_true_rating[submission])\n",
    "\n",
    "\n",
    "\n",
    "# Score\n",
    "old_rating = {}\n",
    "for submission in final_submission_list:\n",
    "    old_rating[submission] = df[df['submission_idx'] == submission]['score'].tolist()\n",
    "    old_rating[submission] = old_rating[submission][0]\n",
    "\n",
    "old_score_multi_iso = []\n",
    "for submission in final_submission_list:\n",
    "    old_score_multi_iso.append(old_rating[submission])\n",
    "\n",
    "\n",
    "\n",
    "# Compute MSE\n",
    "print('Simple-averaging Isotonic Mechanism', mean_squared_error(adhoc_iso_rating, True_score_multi_iso))\n",
    "print('Review Rating', mean_squared_error(old_score_multi_iso, True_score_multi_iso))\n",
    "\n",
    "\n",
    "\n",
    "# Create two lists to record: (y - R)^2 and (\\hat{R} - R)^2 values.\n",
    "adhoc_diff = []\n",
    "old_diff = []\n",
    "for i in range(len(True_score_multi_iso)):\n",
    "  adhoc_diff.append( (adhoc_iso_rating[i] - True_score_multi_iso[i])**2 )\n",
    "  old_diff.append( (old_score_multi_iso[i] - True_score_multi_iso[i])**2 )\n",
    "\n",
    "\n",
    "\n",
    "#Perform the paired sample t-test\n",
    "t_statistic, p_value = stats.ttest_rel(old_diff, adhoc_diff, alternative='greater')\n",
    "print(\"Before Rebuttal with proxy t-test for greedy:\", t_statistic)\n",
    "print(\"Before Rebuttal with proxy p-value for greedy:\", p_value)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3WsD3-VNf2lD"
   },
   "source": [
    "## Compute L_1 values for all submissions and Plot.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1755,
     "status": "ok",
     "timestamp": 1745874270763,
     "user": {
      "displayName": "Buxin Su",
      "userId": "12574803226597557409"
     },
     "user_tz": 240
    },
    "id": "s01AsZfRf2lL",
    "outputId": "2338b1c8-dbe0-419a-d095-2795d9aa7468"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Simple-averaging Isotonic Mechanism 1.0835456135859363\n",
      "Review Rating 1.246989247311828\n",
      "Before Rebuttal with proxy t-test for greedy: 11.412902963452472\n",
      "Before Rebuttal with proxy p-value for greedy: 1.649813003387367e-29\n"
     ]
    }
   ],
   "source": [
    "# Isotonic score\n",
    "adhoc_iso_rating = []\n",
    "for submission in final_submission_list:\n",
    "  adhoc_iso_rating.append(submission_new_rating[submission])\n",
    "\n",
    "\n",
    "\n",
    "# Proxy\n",
    "submission_true_rating = {}\n",
    "for submission in final_submission_list:\n",
    "    submission_true_rating[submission] = df[df['submission_idx'] == submission]['proxy'].tolist()\n",
    "    submission_true_rating[submission] = submission_true_rating[submission][0]\n",
    "\n",
    "True_score_multi_iso = []\n",
    "for submission in final_submission_list:\n",
    "    True_score_multi_iso.append(submission_true_rating[submission])\n",
    "\n",
    "\n",
    "\n",
    "# Score\n",
    "old_rating = {}\n",
    "for submission in final_submission_list:\n",
    "    old_rating[submission] = df[df['submission_idx'] == submission]['score'].tolist()\n",
    "    old_rating[submission] = old_rating[submission][0]\n",
    "\n",
    "old_score_multi_iso = []\n",
    "for submission in final_submission_list:\n",
    "    old_score_multi_iso.append(old_rating[submission])\n",
    "\n",
    "\n",
    "\n",
    "# Create two lists to record: (y - R)^2 and (\\hat{R} - R)^2 values.\n",
    "adhoc_diff = []\n",
    "old_diff = []\n",
    "for i in range(len(True_score_multi_iso)):\n",
    "  adhoc_diff.append( abs(adhoc_iso_rating[i] - True_score_multi_iso[i]) )\n",
    "  old_diff.append( abs(old_score_multi_iso[i] - True_score_multi_iso[i]) )\n",
    "\n",
    "\n",
    "\n",
    "# Compute MSE\n",
    "print('Simple-averaging Isotonic Mechanism', np.mean(adhoc_diff) )\n",
    "print('Review Rating', np.mean(old_diff) )\n",
    "\n",
    "\n",
    "\n",
    "#Perform the paired sample t-test\n",
    "t_statistic, p_value = stats.ttest_rel(old_diff, adhoc_diff, alternative='greater')\n",
    "print(\"Before Rebuttal with proxy t-test for greedy:\", t_statistic)\n",
    "print(\"Before Rebuttal with proxy p-value for greedy:\", p_value)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kQQuVCdX2UKJ"
   },
   "source": [
    "# **Greedy/Multi-owner Isotonic Scores, Proxy**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "e27iIugz2grj"
   },
   "source": [
    "## Load CSV file into a pandas DataFrame\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 306,
     "status": "ok",
     "timestamp": 1745874271071,
     "user": {
      "displayName": "Buxin Su",
      "userId": "12574803226597557409"
     },
     "user_tz": 240
    },
    "id": "tn0ZcvFA2g_a"
   },
   "outputs": [],
   "source": [
    "# # Load CSV file into a pandas DataFrame\n",
    "# df = pd.read_csv(r'proxy_score.csv')\n",
    "# df = df.drop_duplicates(['submission_idx', 'author_idx'])\n",
    "\n",
    "\n",
    "# # Find authors with 'Not very confident' confidence level\n",
    "# low_conf_authors = df_conf[df_conf['would_you_review_for_ICML_2023'].isin(['No'])]['author_idx'].unique()\n",
    "\n",
    "# Extract the unique authors from the DataFrame\n",
    "authors = df['author_idx'].unique()\n",
    "submissions = df['submission_idx'].unique()\n",
    "\n",
    "author_submission = {}\n",
    "for author in authors:\n",
    "    submissionss = list( set(df[df['author_idx'] == author]['submission_idx'].tolist()) )\n",
    "    author_submission[author] = submissionss\n",
    "\n",
    "m_2 = len(author_submission)\n",
    "n_2 = len(submissions)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lSrynyyK2pdI"
   },
   "source": [
    "## Organize all the authors and submissions as the following 'graph': authors = [..., {..., paper_idx : ranking, ...}, ...]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "executionInfo": {
     "elapsed": 1344,
     "status": "ok",
     "timestamp": 1745874272427,
     "user": {
      "displayName": "Buxin Su",
      "userId": "12574803226597557409"
     },
     "user_tz": 240
    },
    "id": "uNDek9xm2pth"
   },
   "outputs": [],
   "source": [
    "authors = []\n",
    "for author in author_submission:\n",
    "    submission_ranking = {}\n",
    "    for i in range(len(author_submission[author])):\n",
    "        submission_ranking[author_submission[author][i]] = df[(df['submission_idx'] == author_submission[author][i]) & (df['author_idx'] == author)]['rank'].tolist()\n",
    "        submission_ranking[author_submission[author][i]] = submission_ranking[author_submission[author][i]][0]\n",
    "    authors.append(submission_ranking)\n",
    "\n",
    "graph = {}\n",
    "for i, author in enumerate(authors):\n",
    "    graph[i] = set( int(k) for k in author.keys())\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aZOd2Vb63M-W"
   },
   "source": [
    "## Multi-owner Isotonic\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "executionInfo": {
     "elapsed": 2666,
     "status": "ok",
     "timestamp": 1745874275095,
     "user": {
      "displayName": "Buxin Su",
      "userId": "12574803226597557409"
     },
     "user_tz": 240
    },
    "id": "JprHQPzQ3wBU"
   },
   "outputs": [],
   "source": [
    "# Partition all the graph according to Multi-owner algorithm\n",
    "partition, author_parts = arbitrary(graph, m_2, n_2)\n",
    "author_parts = validate(partition, graph, n_2)\n",
    "\n",
    "calibrated_scores = np.zeros(n_2)\n",
    "for part, author_part in zip(partition, author_parts):\n",
    "  if len(author_part) == 0:\n",
    "    for i in part: calibrated_scores[i] = df[df['submission_idx'] == i]['score'].tolist()[0]\n",
    "    continue\n",
    "  paper_part = list(part)\n",
    "\n",
    "\n",
    "\n",
    "  # Organize each block by {author: [submission, rank, score]}.\n",
    "  author_submission_rank_old = {}\n",
    "  for author in author_part:\n",
    "      author_submission_rank_old[author] = []\n",
    "      for i in range(len(paper_part)):\n",
    "          rank = df[(df['submission_idx'] == paper_part[i]) & (df['author_idx'] == author)]['rank'].tolist()[0]\n",
    "          ratings = df[(df['submission_idx'] == paper_part[i]) & (df['author_idx'] == author)]['score'].tolist()[0]\n",
    "          author_submission_rank_old[author].append((paper_part[i], rank, ratings))\n",
    "\n",
    "\n",
    "\n",
    "  # Sort submissions by rank; in case of ties, sort by score.\n",
    "  def sort_submissions(author_submission_rank_old):\n",
    "    for author in author_submission_rank_old:\n",
    "      author_submission_rank_old[author].sort(key=lambda x: (x[1], -x[2]), reverse=False)\n",
    "    return author_submission_rank_old\n",
    "  author_submission_rank_old = sort_submissions(author_submission_rank_old)\n",
    "\n",
    "\n",
    "\n",
    "  # Compute isotonic scores for each author in the block.\n",
    "  author_submission_rank_multi_iso = {}\n",
    "  for author in author_submission_rank_old:\n",
    "      ir_rank = []\n",
    "      for i in range(len(author_submission_rank_old[author])):\n",
    "          r1 = author_submission_rank_old[author][i][2]\n",
    "          ir_rank.append(r1)\n",
    "      ir_rank = np.array(ir_rank)\n",
    "      ir_rank_pred =  isotonic_regression(ir_rank, sample_weight = None, y_min=0.0, y_max=10.0, increasing=False)\n",
    "\n",
    "      author_submission_rank_multi_iso[author] = []\n",
    "      for i in range(len(author_submission_rank_old[author])):\n",
    "          author_submission_rank_multi_iso[author].append((author_submission_rank_old[author][i][0], author_submission_rank_old[author][i][1], ir_rank_pred[i]))\n",
    "\n",
    "\n",
    "\n",
    "  # For multi-author submissions in a block, average the scores to get the isotonic score.\n",
    "  submission_multi_iso_rating = {}\n",
    "  for submission in paper_part:\n",
    "      submission_multi_iso_rating[submission] = []\n",
    "\n",
    "  for author in author_submission_rank_multi_iso:\n",
    "      for i in range(len(author_submission_rank_multi_iso[author])):\n",
    "          submission_multi_iso_rating[author_submission_rank_multi_iso[author][i][0]].append(author_submission_rank_multi_iso[author][i][2])\n",
    "\n",
    "  for submission in submission_multi_iso_rating:\n",
    "      submission_multi_iso_rating[submission] = [float(rating) for rating in submission_multi_iso_rating[submission]]\n",
    "      avg_rating = sum(submission_multi_iso_rating[submission])/len(submission_multi_iso_rating[submission])\n",
    "      submission_multi_iso_rating[submission] = avg_rating\n",
    "\n",
    "  for i in paper_part:\n",
    "    calibrated_scores[i] = submission_multi_iso_rating[i]\n",
    "\n",
    "\n",
    "\n",
    "# Multi-owner Isotonic Score\n",
    "multi_iso_rating = []\n",
    "for i in range(n_2):\n",
    "  multi_iso_rating.append(calibrated_scores[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9J4CQkym30mf"
   },
   "source": [
    "## Greedy Isotonic\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "executionInfo": {
     "elapsed": 2502,
     "status": "ok",
     "timestamp": 1745874277598,
     "user": {
      "displayName": "Buxin Su",
      "userId": "12574803226597557409"
     },
     "user_tz": 240
    },
    "id": "tPKDhzqM4aIB"
   },
   "outputs": [],
   "source": [
    "# Partition all the graph according to greedy algorithm\n",
    "partition, author_parts = greedy(graph, m_2, n_2)\n",
    "author_parts = validate(partition, graph, n_2)\n",
    "\n",
    "calibrated_scores = np.zeros(n_2)\n",
    "for part, author_part in zip(partition, author_parts):\n",
    "  if len(author_part) == 0:\n",
    "    for i in part: calibrated_scores[i] = df[df['submission_idx'] == i]['score'].tolist()[0]\n",
    "    continue\n",
    "  paper_part = list(part)\n",
    "\n",
    "\n",
    "\n",
    "  # Organize each block by {author: [submission, rank, score]}.\n",
    "  author_submission_rank_old = {}\n",
    "  for author in author_part:\n",
    "    author_submission_rank_old[author] = []\n",
    "    for i in range(len(paper_part)):\n",
    "        rank = df[(df['submission_idx'] == paper_part[i]) & (df['author_idx'] == author)]['rank'].tolist()[0]\n",
    "        ratings = df[(df['submission_idx'] == paper_part[i]) & (df['author_idx'] == author)]['score'].tolist()[0]\n",
    "        author_submission_rank_old[author].append((paper_part[i], rank, ratings))\n",
    "\n",
    "\n",
    "\n",
    "  # Sort submissions by rank; in case of ties, sort by score.\n",
    "  def sort_submissions(author_submission_rank_old):\n",
    "    for author in author_submission_rank_old:\n",
    "      author_submission_rank_old[author].sort(key=lambda x: (x[1], -x[2]), reverse=False)\n",
    "    return author_submission_rank_old\n",
    "  author_submission_rank_old = sort_submissions(author_submission_rank_old)\n",
    "\n",
    "\n",
    "\n",
    "  # Compute isotonic scores for each author in the block.\n",
    "  author_submission_rank_greedy_iso = {}\n",
    "  for author in author_submission_rank_old:\n",
    "      ir_rank = []\n",
    "      for i in range(len(author_submission_rank_old[author])):\n",
    "          r1 = author_submission_rank_old[author][i][2]\n",
    "          ir_rank.append(r1)\n",
    "      ir_rank = np.array(ir_rank)\n",
    "      ir_rank_pred =  isotonic_regression(ir_rank, sample_weight = None, y_min=0.0, y_max=10.0, increasing=False)\n",
    "\n",
    "      author_submission_rank_greedy_iso[author] = []\n",
    "      for i in range(len(author_submission_rank_old[author])):\n",
    "          author_submission_rank_greedy_iso[author].append((author_submission_rank_old[author][i][0], author_submission_rank_old[author][i][1], ir_rank_pred[i]))\n",
    "\n",
    "\n",
    "\n",
    "  # For multi-author submissions in a block, average the scores to get the isotonic score.\n",
    "  submission_greedy_iso_rating = {}\n",
    "  for submission in paper_part:\n",
    "      submission_greedy_iso_rating[submission] = []\n",
    "\n",
    "  for author in author_submission_rank_greedy_iso:\n",
    "      for i in range(len(author_submission_rank_greedy_iso[author])):\n",
    "          submission_greedy_iso_rating[author_submission_rank_greedy_iso[author][i][0]].append(author_submission_rank_greedy_iso[author][i][2])\n",
    "\n",
    "  for submission in submission_greedy_iso_rating:\n",
    "      submission_greedy_iso_rating[submission] = [float(rating) for rating in submission_greedy_iso_rating[submission]]\n",
    "      avg_rating = sum(submission_greedy_iso_rating[submission])/len(submission_greedy_iso_rating[submission])\n",
    "      submission_greedy_iso_rating[submission] = avg_rating\n",
    "\n",
    "  for i in paper_part:\n",
    "    calibrated_scores[i] = submission_greedy_iso_rating[i]\n",
    "\n",
    "\n",
    "\n",
    "# Greedy Isotonic Score\n",
    "greedy_iso_rating = []\n",
    "for i in range(n_2):\n",
    "  greedy_iso_rating.append(calibrated_scores[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Pb3YkCfz4b8T"
   },
   "source": [
    "## Compute MSE values for all submissions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1469,
     "status": "ok",
     "timestamp": 1745874279075,
     "user": {
      "displayName": "Buxin Su",
      "userId": "12574803226597557409"
     },
     "user_tz": 240
    },
    "id": "mCQnj1UK5KJY",
    "outputId": "38c91386-40b1-42cf-ac9e-82dd02ad1fe1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Greedy Isotonic Mechanism 1.9697868130226999\n",
      "Multiowner Isotonic Mechanism 2.0314329450418165\n",
      "Review Rating 2.542196833930705\n",
      "Before Rebuttal with proxy t-test for greedy: 11.548577928945898\n",
      "Before Rebuttal with proxy p-value for greedy: 3.810907199012494e-30\n",
      "Before Rebuttal with proxy t-test for multi-owner: 10.98827369346689\n",
      "Before Rebuttal with proxy p-value for multi-owner: 1.4707368255107937e-27\n"
     ]
    }
   ],
   "source": [
    "# proxy\n",
    "submission_true_rating = {}\n",
    "for submission in range(n_2):\n",
    "    submission_true_rating[submission] = df[df['submission_idx'] == submission]['proxy'].tolist()\n",
    "    submission_true_rating[submission] = submission_true_rating[submission][0]\n",
    "\n",
    "True_score_multi_iso = []\n",
    "for i in range(n_2):\n",
    "    True_score_multi_iso.append(submission_true_rating[i])\n",
    "\n",
    "\n",
    "\n",
    "# score\n",
    "old_rating = {}\n",
    "for submission in range(n_2):\n",
    "    old_rating[submission] = df[df['submission_idx'] == submission]['score'].tolist()\n",
    "    old_rating[submission] = old_rating[submission][0]\n",
    "\n",
    "old_score_multi_iso = []\n",
    "for i in range(n_2):\n",
    "    old_score_multi_iso.append(old_rating[i])\n",
    "\n",
    "\n",
    "\n",
    "# print the MSE\n",
    "print('Greedy Isotonic Mechanism', mean_squared_error(greedy_iso_rating, True_score_multi_iso))\n",
    "print('Multiowner Isotonic Mechanism', mean_squared_error(multi_iso_rating, True_score_multi_iso))\n",
    "#print('Singal Isotonic Mechanism:', mean_squared_error(iso_rating, True_score))\n",
    "print('Review Rating', mean_squared_error(old_score_multi_iso, True_score_multi_iso))\n",
    "\n",
    "\n",
    "\n",
    "# Create two lists to record: (y - R)^2 and (\\hat{R} - R)^2 values.\n",
    "greedy_diff = []\n",
    "multi_diff = []\n",
    "old_diff = []\n",
    "for i in range(len(True_score_multi_iso)):\n",
    "  greedy_diff.append( (greedy_iso_rating[i] - True_score_multi_iso[i])**2 )\n",
    "  multi_diff.append( (multi_iso_rating[i] - True_score_multi_iso[i])**2 )\n",
    "  old_diff.append( (old_score_multi_iso[i] - True_score_multi_iso[i])**2 )\n",
    "\n",
    "\n",
    "\n",
    "#Perform the paired sample t-test\n",
    "t_statistic, p_value = stats.ttest_rel(old_diff, greedy_diff, alternative='greater')\n",
    "print(\"Before Rebuttal with proxy t-test for greedy:\", t_statistic)\n",
    "print(\"Before Rebuttal with proxy p-value for greedy:\", p_value)\n",
    "\n",
    "\n",
    "\n",
    "#Perform the paired sample t-test\n",
    "t_statistic, p_value = stats.ttest_rel(old_diff, multi_diff, alternative='greater')\n",
    "print(\"Before Rebuttal with proxy t-test for multi-owner:\", t_statistic)\n",
    "print(\"Before Rebuttal with proxy p-value for multi-owner:\", p_value)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2TZFKZQ1hb1s"
   },
   "source": [
    "## Compute L1 values for all submissions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1599,
     "status": "ok",
     "timestamp": 1745874280673,
     "user": {
      "displayName": "Buxin Su",
      "userId": "12574803226597557409"
     },
     "user_tz": 240
    },
    "id": "s-7e228Shb10",
    "outputId": "09669842-496a-47c1-8ae1-ec341428c355"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Greedy Isotonic Mechanism 1.0926056067588328\n",
      "Multiowner Isotonic Mechanism 1.1110394265232975\n",
      "Review Rating 1.246989247311828\n",
      "Before Rebuttal with proxy t-test for greedy: 10.632029288972516\n",
      "Before Rebuttal with proxy p-value for greedy: 5.679613363790794e-26\n",
      "Before Rebuttal with proxy t-test for multi-owner: 10.001391419279937\n",
      "Before Rebuttal with proxy p-value for multi-owner: 2.8274031285581437e-23\n"
     ]
    }
   ],
   "source": [
    "# proxy\n",
    "submission_true_rating = {}\n",
    "for submission in range(n_2):\n",
    "    submission_true_rating[submission] = df[df['submission_idx'] == submission]['proxy'].tolist()\n",
    "    submission_true_rating[submission] = submission_true_rating[submission][0]\n",
    "\n",
    "True_score_multi_iso = []\n",
    "for i in range(n_2):\n",
    "    True_score_multi_iso.append(submission_true_rating[i])\n",
    "\n",
    "\n",
    "\n",
    "# score\n",
    "old_rating = {}\n",
    "for submission in range(n_2):\n",
    "    old_rating[submission] = df[df['submission_idx'] == submission]['score'].tolist()\n",
    "    old_rating[submission] = old_rating[submission][0]\n",
    "\n",
    "old_score_multi_iso = []\n",
    "for i in range(n_2):\n",
    "    old_score_multi_iso.append(old_rating[i])\n",
    "\n",
    "\n",
    "\n",
    "# Create two lists to record: (y - R)^2 and (\\hat{R} - R)^2 values.\n",
    "greedy_diff = []\n",
    "multi_diff = []\n",
    "old_diff = []\n",
    "for i in range(len(True_score_multi_iso)):\n",
    "  greedy_diff.append( abs(greedy_iso_rating[i] - True_score_multi_iso[i]) )\n",
    "  multi_diff.append( abs(multi_iso_rating[i] - True_score_multi_iso[i]) )\n",
    "  old_diff.append( abs(old_score_multi_iso[i] - True_score_multi_iso[i]) )\n",
    "\n",
    "\n",
    "\n",
    "# print the MSE\n",
    "print('Greedy Isotonic Mechanism', np.mean(greedy_diff) )\n",
    "print('Multiowner Isotonic Mechanism', np.mean(multi_diff) )\n",
    "print('Review Rating', np.mean(old_diff) )\n",
    "\n",
    "\n",
    "\n",
    "#Perform the paired sample t-test\n",
    "t_statistic, p_value = stats.ttest_rel(old_diff, greedy_diff, alternative='greater')\n",
    "print(\"Before Rebuttal with proxy t-test for greedy:\", t_statistic)\n",
    "print(\"Before Rebuttal with proxy p-value for greedy:\", p_value)\n",
    "\n",
    "\n",
    "\n",
    "#Perform the paired sample t-test\n",
    "t_statistic, p_value = stats.ttest_rel(old_diff, multi_diff, alternative='greater')\n",
    "print(\"Before Rebuttal with proxy t-test for multi-owner:\", t_statistic)\n",
    "print(\"Before Rebuttal with proxy p-value for multi-owner:\", p_value)\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyNToD08eORcxk+g8g+msR9I",
   "collapsed_sections": [
    "Zd8s4wjVz-gv",
    "7PcDKgM_0ElJ",
    "kPWWcc7LiVmU"
   ],
   "mount_file_id": "1ngu2BIK6f7Db0D82UHdK9A1J1Rc24O3S",
   "provenance": [
    {
     "file_id": "1ngu2BIK6f7Db0D82UHdK9A1J1Rc24O3S",
     "timestamp": 1739598477740
    }
   ],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
