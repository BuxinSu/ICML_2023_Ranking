{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"1IUxbpfup43gMa2_piakybzrU-BH5qQLu","timestamp":1736742582322},{"file_id":"1ngu2BIK6f7Db0D82UHdK9A1J1Rc24O3S","timestamp":1736740144259}],"collapsed_sections":["Zd8s4wjVz-gv","7PcDKgM_0ElJ","kPWWcc7LiVmU","MFF6_8mg0pJZ","BZUWHz7j0udU","bFKfCIwq00Bx"],"toc_visible":true,"mount_file_id":"1ngu2BIK6f7Db0D82UHdK9A1J1Rc24O3S","authorship_tag":"ABX9TyPp4T2/BSqLXyPas+hF3ZWU"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# **Import Google Drive**\n"],"metadata":{"id":"Zd8s4wjVz-gv"}},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"id":"kpj7DF1k-jRR","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1745892461751,"user_tz":240,"elapsed":16150,"user":{"displayName":"Buxin Su","userId":"12574803226597557409"}},"outputId":"c282b74f-cc87-4167-b52e-796b91e5b5a3"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"markdown","source":["# **Setting**\n"],"metadata":{"id":"7PcDKgM_0ElJ"}},{"cell_type":"code","source":["from sklearn.isotonic import isotonic_regression\n","import cvxpy as cp\n","import numpy as np\n","import csv, os\n","from scipy import stats\n","from sklearn import metrics\n","import itertools\n","import pandas as pd\n","from sklearn.metrics import mean_squared_error\n","import matplotlib.pyplot as plt\n","import statistics\n","from scipy.stats import levene\n","import seaborn as sns\n","import warnings\n","warnings.filterwarnings(\"ignore\", category=RuntimeWarning)\n"],"metadata":{"id":"3LvEW5gO0E-K","executionInfo":{"status":"ok","timestamp":1745892470222,"user_tz":240,"elapsed":8472,"user":{"displayName":"Buxin Su","userId":"12574803226597557409"}}},"execution_count":2,"outputs":[]},{"cell_type":"markdown","source":["# **Function: Partition all submissions according to \"Greedy\" and \"Multi-owner\" methods**\n"],"metadata":{"id":"kPWWcc7LiVmU"}},{"cell_type":"code","source":["def validate(partition, graph, n):\n","\t# check that\n","\t# 1. each paper is in exactly one partition\n","\t# 2. the number of papers in all partition is equal to the number of papers\n","\t# 3. each partition has at least two authors owns all papers in the partition\n","\n","\tpapers = set()\n","\tfull_author_parts = []\n","\tfor part in partition[:-1]:\n","\t\tassert( len(part.intersection(papers)) == 0 )\n","\t\tpapers |= part\n","\t\t# find all authors that can rank all papers in this part\n","\t\tcnt = 0\n","\t\tauthor_part = set()\n","\t\tfor author, val in graph.items():\n","\t\t\tif len(val.intersection(part)) == len(part):\n","\t\t\t\tcnt += 1\n","\t\t\t\tauthor_part.add(author)\n","\n","\t\t# assert( cnt >= 2 )\n","\t\tfull_author_parts.append(author_part)\n","\n","\t# add the last partition\n","\tfull_author_parts.append(set())\n","\tpapers |= partition[-1]\n","\tassert(len(papers) == n)\n","\n","\treturn full_author_parts\n","\n","\n","def greedy(graph, m, n, randomize=False, level=1):\n","\tpartition = []\n","\tauthor_parts = []\n","\tallocated_papers = set()\n","\n","\tif level == 1:\n","\t\tparts = [ graph[i].copy() for i in range(m) ]\n","\t\tindex2pair = [ set([i]) for i in range(m) ]\n","\telif level == 2:\n","\t\tparts = [ graph[i].intersection(graph[j])  for i in range(m) for j in range(i+1, m) ]\n","\t\tindex2pair = [ set([i,j]) for i in range(m) for j in range(i+1, m) ]\n","\n","\tmax_idx = 0\n","\tmax_val = 0\n","\tactive_indices = set( [i for i in range(len(parts)) if len(parts[i]) > 1] )\n","\t# for i in range(0, len(parts)):\n","\tfor i in active_indices:\n","\t\tif len(parts[i]) > max_val:\n","\t\t\tmax_idx = i\n","\t\t\tmax_val = len(parts[i])\n","\n","\twhile len(allocated_papers) < n and len(parts[max_idx]) > 1:\n","\t\tmax_part = parts[max_idx].copy()\n","\t\tpartition.append( max_part )\n","\t\tauthor_parts.append( index2pair[max_idx] )\n","\t\tallocated_papers |= max_part\n","\n","\t\tmax_idx = 0\n","\t\tmax_val = 0\n","\t\t# for i in range(0, len(parts)):\n","\t\tto_remove = set()\n","\t\tfor i in active_indices:\n","\t\t\tparts[i].difference_update(max_part)\n","\t\t\tif len(parts[i]) < 2:\n","\t\t\t\tto_remove.add(i)\n","\t\t\t\tcontinue\n","\t\t\tif len(parts[i]) > max_val:\n","\t\t\t\tmax_idx = i\n","\t\t\t\tmax_val = len(parts[i])\n","\t\tmax_part = parts[max_idx].copy()\n","\t\tactive_indices.difference_update(to_remove)\n","\n","\t# add all remaining papers to the last partition\n","\tpartition.append(set())\n","\tauthor_parts.append(set())\n","\tfor i in range(n):\n","\t\tif i not in allocated_papers:\n","\t\t\tpartition[-1].add(i)\n","\n","\treturn partition, author_parts\n","\n","\n","def arbitrary(graph, m, n, randomize=False):\n","\tpartition = []\n","\tauthor_parts = []\n","\tallocated_papers = set()\n","\n","\tparts = [ graph[i].copy() for i in range(m) ]\n","\tindex2pair = [ set([i]) for i in range(m) ]\n","\n","\tidx = 0\n","\twhile len(parts[idx]) < 2 and idx < len(parts)-1: idx += 1\n","\n","\twhile len(allocated_papers) < n and idx != -1:\n","\t\tpart = parts[idx].copy()\n","\n","\t\tpartition.append( part )\n","\t\tauthor_parts.append( index2pair[idx] )\n","\t\tallocated_papers |= part\n","\n","\t\tidx = -1\n","\t\tval = None\n","\t\tfor i in range(0, len(parts)):\n","\t\t\tparts[i].difference_update(part)\n","\t\t\tif len(parts[i]) >= 2:\n","\t\t\t\tidx = i\n","\t\t\t\tval = len(parts[i])\n","\n","\tpartition.append(set())\n","\tauthor_parts.append(set())\n","\tfor i in range(n):\n","\t\tif i not in allocated_papers:\n","\t\t\tpartition[-1].add(i)\n","\n","\treturn partition, author_parts\n"],"metadata":{"id":"AlzU8-hqiU4Z","executionInfo":{"status":"ok","timestamp":1745892470258,"user_tz":240,"elapsed":27,"user":{"displayName":"Buxin Su","userId":"12574803226597557409"}}},"execution_count":3,"outputs":[]},{"cell_type":"markdown","source":["#**Generate simulation dataset**"],"metadata":{"id":"Uz9kGazNypcN"}},{"cell_type":"code","source":["# Load the dataset\n","df = pd.read_csv('/content/drive/MyDrive/Research/ICML_2023_Result/proxy_score.csv')\n","\n","# Step 1: Keep only 'submission_id' and 'author_id' columns\n","df = df[['submission_id', 'author_id', 'submission_idx', 'author_idx']]\n","\n","# Step 2: Generate 'ground_truth' for each unique 'submission_id'\n","unique_submission_ids = df['submission_id'].unique()\n","np.random.seed(42)  # For reproducibility\n","ground_truth_map = {sub_id: np.random.normal(loc=5, scale=np.sqrt(1.25)) for sub_id in unique_submission_ids}\n","\n","# Define the sigmoid function\n","def sigmoid(x):\n","    return 1 / (1 + np.exp(-x))\n","\n","# Define the review generation function\n","def generate_review_bold(ground_truth):\n","    noise = np.random.normal(0, 1.25)  # Gaussian noise N(0, 2)\n","    bias = sigmoid(ground_truth - 5) - 0.5\n","    review = round(ground_truth + noise + bias)\n","    return min(max(review, 0), 10)  # Clamp between 0 and 10\n","\n","# Define the review generation function\n","def generate_review_conserve(ground_truth):\n","    noise = np.random.normal(0, 1.25)  # Gaussian noise N(0, 2)\n","    bias = sigmoid(ground_truth - 5) - 0.5\n","    review = round(ground_truth + noise - bias)\n","    return min(max(review, 0), 10)  # Clamp between 0 and 10\n","\n","# Step 3: Precompute reviews for each unique submission_id\n","review_map = {}\n","for sub_id in unique_submission_ids:\n","    ground_truth = ground_truth_map[sub_id]\n","    # Randomly assign a function for each reviewer\n","    review_1_fn = np.random.choice([generate_review_bold, generate_review_conserve])\n","    review_2_fn = np.random.choice([generate_review_bold, generate_review_conserve])\n","    review_3_fn = np.random.choice([generate_review_bold, generate_review_conserve])\n","\n","    review_1 = review_1_fn(ground_truth)\n","    review_2 = review_2_fn(ground_truth)\n","    review_3 = review_3_fn(ground_truth)\n","    review_map[sub_id] = {'ground_truth': ground_truth, 'review_1': review_1, 'review_2': review_2, 'review_3': review_3}\n","\n","# Map the precomputed values back to the dataframe\n","df['ground_truth'] = df['submission_id'].map(lambda x: review_map[x]['ground_truth'])\n","df['review_1'] = df['submission_id'].map(lambda x: review_map[x]['review_1'])\n","df['review_2'] = df['submission_id'].map(lambda x: review_map[x]['review_2'])\n","df['review_3'] = df['submission_id'].map(lambda x: review_map[x]['review_3'])\n","\n","# Step 4: Compute 'score'\n","df['score'] = (df['review_1'] + df['review_2'] + df['review_3']) / 3\n","\n"],"metadata":{"id":"Z1BXWqzXym6A"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Step 6: Add a ranking column for each author based on ground_truth\n","# Group submissions by 'author_idx' and rank submissions within each author by 'ground_truth'\n","df['rank'] = (\n","    df.groupby('author_idx')['ground_truth']\n","    .rank(method='dense', ascending=False)  # Rank submissions in descending order of ground_truth\n","    .astype(int)  # Convert to integer for clean ranking\n",")\n","\n","# Step 7: Save to a new CSV\n","df.to_csv('/content/drive/MyDrive/Research/ICML_2023_Result/proxy_score_bias_simulation.csv', index=False)\n"],"metadata":{"id":"aeE7M4EiBtlS"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# **Simple-averaging Isotonic Scores, Proxy**\n"],"metadata":{"id":"F7Y3yIRN8_p2"}},{"cell_type":"markdown","source":["## Load CSV file into a pandas DataFrame\n"],"metadata":{"id":"RnkrFd1f0YIN"}},{"cell_type":"code","source":["# Load CSV file into a pandas DataFrame\n","df = pd.read_csv(r'/content/drive/MyDrive/Research/ICML_2023_Result/proxy_score_bias_simulation.csv')\n","df = df.drop_duplicates(['submission_idx', 'author_idx'])"],"metadata":{"id":"Ak-WjHX90Zv6","executionInfo":{"status":"ok","timestamp":1745892471439,"user_tz":240,"elapsed":1168,"user":{"displayName":"Buxin Su","userId":"12574803226597557409"}}},"execution_count":4,"outputs":[]},{"cell_type":"markdown","source":["## Organize each block by {author: [submission, rank, score]}.\n"],"metadata":{"id":"7mCPHu1C0bDc"}},{"cell_type":"code","source":["author_submission_rank_old = {}\n","authors = df['author_idx'].unique()\n","for author in authors:\n","    author_submission_rank_old[author] = []\n","    submissions = list(set(df[df['author_idx'] == author]['submission_idx'].tolist()))\n","\n","    for i in range(len(submissions)):\n","        rank = df[(df['submission_idx'] == submissions[i]) & (df['author_idx'] == author)]['rank'].tolist()[0]\n","        ratings = df[(df['submission_idx'] == submissions[i]) & (df['author_idx'] == author)]['score'].tolist()[0]\n","        author_submission_rank_old[author].append((submissions[i], rank, ratings))"],"metadata":{"id":"Sx-FhyBm0ebi","executionInfo":{"status":"ok","timestamp":1745892478926,"user_tz":240,"elapsed":7488,"user":{"displayName":"Buxin Su","userId":"12574803226597557409"}}},"execution_count":5,"outputs":[]},{"cell_type":"markdown","source":["## Sort submissions by rank; in case of ties, sort by score.\n"],"metadata":{"id":"MFF6_8mg0pJZ"}},{"cell_type":"code","source":["def sort_submissions(author_submission_rank_old):\n","    for author in author_submission_rank_old:\n","        author_submission_rank_old[author].sort(key=lambda x: (x[1], -x[2]), reverse=False)\n","    return author_submission_rank_old\n","\n","author_submission_rank_old = sort_submissions(author_submission_rank_old)"],"metadata":{"id":"aVSHptys0quM","executionInfo":{"status":"ok","timestamp":1745892478928,"user_tz":240,"elapsed":11,"user":{"displayName":"Buxin Su","userId":"12574803226597557409"}}},"execution_count":6,"outputs":[]},{"cell_type":"markdown","source":["## Compute isotonic scores for each author.\n"],"metadata":{"id":"BZUWHz7j0udU"}},{"cell_type":"code","source":["author_submission_rank_new = {}\n","for author in author_submission_rank_old:\n","    ir_rank = []\n","    for i in range(len(author_submission_rank_old[author])):\n","        r1 = author_submission_rank_old[author][i][2]\n","        ir_rank.append(r1)\n","    ir_rank = np.array(ir_rank)\n","    ir_rank_pred =  isotonic_regression(ir_rank, sample_weight = None, y_min=0.0, y_max=10.0, increasing=False)\n","\n","    author_submission_rank_new[author] = []\n","    for i in range(len(author_submission_rank_old[author])):\n","        author_submission_rank_new[author].append((author_submission_rank_old[author][i][0], author_submission_rank_old[author][i][1], ir_rank_pred[i]))\n"],"metadata":{"id":"KVQW_Pc70yTL","executionInfo":{"status":"ok","timestamp":1745892479416,"user_tz":240,"elapsed":493,"user":{"displayName":"Buxin Su","userId":"12574803226597557409"}}},"execution_count":7,"outputs":[]},{"cell_type":"markdown","source":["## For multi-author submissions, average the scores to get the isotonic score.\n"],"metadata":{"id":"bFKfCIwq00Bx"}},{"cell_type":"code","source":["final_submission_list = df['submission_idx'].unique()\n","\n","submission_new_rating = {}\n","for submission in final_submission_list:\n","    submission_new_rating[submission] = []\n","\n","for author in author_submission_rank_new:\n","    for i in range(len(author_submission_rank_new[author])):\n","      if author_submission_rank_new[author][i][0] in final_submission_list:\n","        submission_new_rating[author_submission_rank_new[author][i][0]].append(author_submission_rank_new[author][i][2])\n","\n","for submission in final_submission_list:\n","    submission_new_rating[submission] = [float(rating) for rating in submission_new_rating[submission]]\n","    avg_rating = sum(submission_new_rating[submission])/len(submission_new_rating[submission])\n","    submission_new_rating[submission] = avg_rating"],"metadata":{"id":"hRHAlg3u01Xj","executionInfo":{"status":"ok","timestamp":1745892479489,"user_tz":240,"elapsed":76,"user":{"displayName":"Buxin Su","userId":"12574803226597557409"}}},"execution_count":8,"outputs":[]},{"cell_type":"markdown","source":["## Compute MSE values for all submissions and Plot.\n"],"metadata":{"id":"SdDxNarq1IiI"}},{"cell_type":"code","source":["# Isotonic score\n","adhoc_iso_rating = []\n","for submission in final_submission_list:\n","  adhoc_iso_rating.append(submission_new_rating[submission])\n","\n","\n","\n","# Proxy\n","submission_true_rating = {}\n","for submission in final_submission_list:\n","    submission_true_rating[submission] = df[df['submission_idx'] == submission]['ground_truth'].tolist()\n","    submission_true_rating[submission] = submission_true_rating[submission][0]\n","\n","True_score_multi_iso = []\n","for submission in final_submission_list:\n","    True_score_multi_iso.append(submission_true_rating[submission])\n","\n","\n","\n","# Score\n","old_rating = {}\n","for submission in final_submission_list:\n","    old_rating[submission] = df[df['submission_idx'] == submission]['score'].tolist()\n","    old_rating[submission] = old_rating[submission][0]\n","\n","old_score_multi_iso = []\n","for submission in final_submission_list:\n","    old_score_multi_iso.append(old_rating[submission])\n","\n","\n","\n","# Compute MSE\n","print('Simple-averaging Isotonic Mechanism', mean_squared_error(adhoc_iso_rating, True_score_multi_iso))\n","print('Review Rating', mean_squared_error(old_score_multi_iso, True_score_multi_iso))\n","\n","\n","\n","# Create two lists to record: (y - R)^2 and (\\hat{R} - R)^2 values.\n","adhoc_diff = []\n","old_diff = []\n","for i in range(len(True_score_multi_iso)):\n","  adhoc_diff.append( (adhoc_iso_rating[i] - True_score_multi_iso[i])**2 )\n","  old_diff.append( (old_score_multi_iso[i] - True_score_multi_iso[i])**2 )\n","\n","\n","\n","#Perform the paired sample t-test\n","t_statistic, p_value = stats.ttest_rel(old_diff, adhoc_diff, alternative='greater')\n","print(\"Before Rebuttal with proxy t-test for greedy:\", t_statistic)\n","print(\"Before Rebuttal with proxy p-value for greedy:\", p_value)\n","\n","\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"nbHJiLkM1QgC","executionInfo":{"status":"ok","timestamp":1745892482063,"user_tz":240,"elapsed":2575,"user":{"displayName":"Buxin Su","userId":"12574803226597557409"}},"outputId":"39970da3-586e-496f-c41a-d7b659a49ae3"},"execution_count":9,"outputs":[{"output_type":"stream","name":"stdout","text":["Simple-averaging Isotonic Mechanism 0.438335497798118\n","Review Rating 0.5733162280027286\n","Before Rebuttal with proxy t-test for greedy: 15.077508775914177\n","Before Rebuttal with proxy p-value for greedy: 1.4759253048907838e-49\n"]}]},{"cell_type":"markdown","source":["## Compute L_1 values for all submissions and Plot.\n"],"metadata":{"id":"3WsD3-VNf2lD"}},{"cell_type":"code","source":["# Isotonic score\n","adhoc_iso_rating = []\n","for submission in final_submission_list:\n","  adhoc_iso_rating.append(submission_new_rating[submission])\n","\n","\n","\n","# Proxy\n","submission_true_rating = {}\n","for submission in final_submission_list:\n","    submission_true_rating[submission] = df[df['submission_idx'] == submission]['ground_truth'].tolist()\n","    submission_true_rating[submission] = submission_true_rating[submission][0]\n","\n","True_score_multi_iso = []\n","for submission in final_submission_list:\n","    True_score_multi_iso.append(submission_true_rating[submission])\n","\n","\n","\n","# Score\n","old_rating = {}\n","for submission in final_submission_list:\n","    old_rating[submission] = df[df['submission_idx'] == submission]['score'].tolist()\n","    old_rating[submission] = old_rating[submission][0]\n","\n","old_score_multi_iso = []\n","for submission in final_submission_list:\n","    old_score_multi_iso.append(old_rating[submission])\n","\n","\n","\n","# Create two lists to record: (y - R)^2 and (\\hat{R} - R)^2 values.\n","adhoc_diff = []\n","old_diff = []\n","for i in range(len(True_score_multi_iso)):\n","  adhoc_diff.append( abs(adhoc_iso_rating[i] - True_score_multi_iso[i]) )\n","  old_diff.append( abs(old_score_multi_iso[i] - True_score_multi_iso[i]) )\n","\n","\n","\n","# Compute MSE\n","print('Simple-averaging Isotonic Mechanism', np.mean(adhoc_diff) )\n","print('Review Rating', np.mean(old_diff) )\n","\n","\n","\n","#Perform the paired sample t-test\n","t_statistic, p_value = stats.ttest_rel(old_diff, adhoc_diff, alternative='greater')\n","print(\"Before Rebuttal with proxy t-test for greedy:\", t_statistic)\n","print(\"Before Rebuttal with proxy p-value for greedy:\", p_value)\n","\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1745892483614,"user_tz":240,"elapsed":1549,"user":{"displayName":"Buxin Su","userId":"12574803226597557409"}},"outputId":"abe1da68-0f02-4ab7-f449-53a5717e714d","id":"s01AsZfRf2lL"},"execution_count":10,"outputs":[{"output_type":"stream","name":"stdout","text":["Simple-averaging Isotonic Mechanism 0.5196146653632123\n","Review Rating 0.6003783108517696\n","Before Rebuttal with proxy t-test for greedy: 17.358875730593343\n","Before Rebuttal with proxy p-value for greedy: 3.673374027461033e-64\n"]}]},{"cell_type":"markdown","source":["# **Greedy/Multi-owner Isotonic Scores, Proxy**"],"metadata":{"id":"kQQuVCdX2UKJ"}},{"cell_type":"markdown","source":["## Load CSV file into a pandas DataFrame\n"],"metadata":{"id":"e27iIugz2grj"}},{"cell_type":"code","source":["# Load CSV file into a pandas DataFrame\n","df = pd.read_csv(r'/content/drive/MyDrive/Research/ICML_2023_Result/proxy_score_bias_simulation.csv')\n","df = df.drop_duplicates(['submission_idx', 'author_idx'])\n","\n","\n","# Extract the unique authors from the DataFrame\n","authors = df['author_idx'].unique()\n","submissions = df['submission_idx'].unique()\n","\n","author_submission = {}\n","for author in authors:\n","    submissionss = list( set(df[df['author_idx'] == author]['submission_idx'].tolist()) )\n","    author_submission[author] = submissionss\n","\n","m_2 = len(author_submission)\n","n_2 = len(submissions)"],"metadata":{"id":"tn0ZcvFA2g_a","executionInfo":{"status":"ok","timestamp":1745892484143,"user_tz":240,"elapsed":516,"user":{"displayName":"Buxin Su","userId":"12574803226597557409"}}},"execution_count":11,"outputs":[]},{"cell_type":"markdown","source":["## Organize all the authors and submissions as the following 'graph': authors = [..., {..., paper_idx : ranking, ...}, ...]\n"],"metadata":{"id":"lSrynyyK2pdI"}},{"cell_type":"code","source":["authors = []\n","for author in author_submission:\n","    submission_ranking = {}\n","    for i in range(len(author_submission[author])):\n","        submission_ranking[author_submission[author][i]] = df[(df['submission_idx'] == author_submission[author][i]) & (df['author_idx'] == author)]['rank'].tolist()\n","        submission_ranking[author_submission[author][i]] = submission_ranking[author_submission[author][i]][0]\n","    authors.append(submission_ranking)\n","\n","graph = {}\n","for i, author in enumerate(authors):\n","    graph[i] = set( int(k) for k in author.keys())\n","\n"],"metadata":{"id":"uNDek9xm2pth","executionInfo":{"status":"ok","timestamp":1745892485680,"user_tz":240,"elapsed":1535,"user":{"displayName":"Buxin Su","userId":"12574803226597557409"}}},"execution_count":12,"outputs":[]},{"cell_type":"markdown","source":["## Multi-owner Isotonic\n"],"metadata":{"id":"aZOd2Vb63M-W"}},{"cell_type":"code","source":["# Partition all the graph according to Multi-owner algorithm\n","partition, author_parts = arbitrary(graph, m_2, n_2)\n","author_parts = validate(partition, graph, n_2)\n","\n","calibrated_scores = np.zeros(n_2)\n","for part, author_part in zip(partition, author_parts):\n","  if len(author_part) == 0:\n","    for i in part: calibrated_scores[i] = df[df['submission_idx'] == i]['score'].tolist()[0]\n","    continue\n","  paper_part = list(part)\n","\n","\n","\n","  # Organize each block by {author: [submission, rank, score]}.\n","  author_submission_rank_old = {}\n","  for author in author_part:\n","    author_submission_rank_old[author] = []\n","    for i in range(len(paper_part)):\n","        rank = df[(df['submission_idx'] == paper_part[i]) & (df['author_idx'] == author)]['rank'].tolist()[0]\n","        ratings = df[(df['submission_idx'] == paper_part[i]) & (df['author_idx'] == author)]['score'].tolist()[0]\n","        author_submission_rank_old[author].append((paper_part[i], rank, ratings))\n","\n","\n","\n","  # Sort submissions by rank; in case of ties, sort by score.\n","  def sort_submissions(author_submission_rank_old):\n","    for author in author_submission_rank_old:\n","      author_submission_rank_old[author].sort(key=lambda x: (x[1], -x[2]), reverse=False)\n","    return author_submission_rank_old\n","  author_submission_rank_old = sort_submissions(author_submission_rank_old)\n","\n","\n","\n","  # Compute isotonic scores for each author in the block.\n","  author_submission_rank_multi_iso = {}\n","  for author in author_submission_rank_old:\n","      ir_rank = []\n","      for i in range(len(author_submission_rank_old[author])):\n","          r1 = author_submission_rank_old[author][i][2]\n","          ir_rank.append(r1)\n","      ir_rank = np.array(ir_rank)\n","      ir_rank_pred =  isotonic_regression(ir_rank, sample_weight = None, y_min=0.0, y_max=10.0, increasing=False)\n","\n","      author_submission_rank_multi_iso[author] = []\n","      for i in range(len(author_submission_rank_old[author])):\n","          author_submission_rank_multi_iso[author].append((author_submission_rank_old[author][i][0], author_submission_rank_old[author][i][1], ir_rank_pred[i]))\n","\n","\n","\n","  # For multi-author submissions in a block, average the scores to get the isotonic score.\n","  submission_multi_iso_rating = {}\n","  for submission in paper_part:\n","      submission_multi_iso_rating[submission] = []\n","\n","  for author in author_submission_rank_multi_iso:\n","      for i in range(len(author_submission_rank_multi_iso[author])):\n","          submission_multi_iso_rating[author_submission_rank_multi_iso[author][i][0]].append(author_submission_rank_multi_iso[author][i][2])\n","\n","  for submission in submission_multi_iso_rating:\n","      submission_multi_iso_rating[submission] = [float(rating) for rating in submission_multi_iso_rating[submission]]\n","      avg_rating = sum(submission_multi_iso_rating[submission])/len(submission_multi_iso_rating[submission])\n","      submission_multi_iso_rating[submission] = avg_rating\n","\n","  for i in paper_part:\n","    calibrated_scores[i] = submission_multi_iso_rating[i]\n","\n","\n","\n","# Multi-owner Isotonic Score\n","multi_iso_rating = []\n","for i in range(n_2):\n","  multi_iso_rating.append(calibrated_scores[i])"],"metadata":{"id":"JprHQPzQ3wBU","executionInfo":{"status":"ok","timestamp":1745892489108,"user_tz":240,"elapsed":3431,"user":{"displayName":"Buxin Su","userId":"12574803226597557409"}}},"execution_count":13,"outputs":[]},{"cell_type":"markdown","source":["## Greedy Isotonic\n"],"metadata":{"id":"9J4CQkym30mf"}},{"cell_type":"code","source":["# Partition all the graph according to greedy algorithm\n","partition, author_parts = greedy(graph, m_2, n_2)\n","author_parts = validate(partition, graph, n_2)\n","\n","calibrated_scores = np.zeros(n_2)\n","for part, author_part in zip(partition, author_parts):\n","  if len(author_part) == 0:\n","    for i in part: calibrated_scores[i] = df[df['submission_idx'] == i]['score'].tolist()[0]\n","    continue\n","  paper_part = list(part)\n","\n","\n","\n","  # Organize each block by {author: [submission, rank, score]}.\n","  author_submission_rank_old = {}\n","  for author in author_part:\n","    author_submission_rank_old[author] = []\n","    for i in range(len(paper_part)):\n","        rank = df[(df['submission_idx'] == paper_part[i]) & (df['author_idx'] == author)]['rank'].tolist()[0]\n","        ratings = df[(df['submission_idx'] == paper_part[i]) & (df['author_idx'] == author)]['score'].tolist()[0]\n","        author_submission_rank_old[author].append((paper_part[i], rank, ratings))\n","\n","\n","\n","  # Sort submissions by rank; in case of ties, sort by score.\n","  def sort_submissions(author_submission_rank_old):\n","    for author in author_submission_rank_old:\n","      author_submission_rank_old[author].sort(key=lambda x: (x[1], -x[2]), reverse=False)\n","    return author_submission_rank_old\n","  author_submission_rank_old = sort_submissions(author_submission_rank_old)\n","\n","\n","\n","  # Compute isotonic scores for each author in the block.\n","  author_submission_rank_greedy_iso = {}\n","  for author in author_submission_rank_old:\n","      ir_rank = []\n","      for i in range(len(author_submission_rank_old[author])):\n","          r1 = author_submission_rank_old[author][i][2]\n","          ir_rank.append(r1)\n","      ir_rank = np.array(ir_rank)\n","      ir_rank_pred =  isotonic_regression(ir_rank, sample_weight = None, y_min=0.0, y_max=10.0, increasing=False)\n","\n","      author_submission_rank_greedy_iso[author] = []\n","      for i in range(len(author_submission_rank_old[author])):\n","          author_submission_rank_greedy_iso[author].append((author_submission_rank_old[author][i][0], author_submission_rank_old[author][i][1], ir_rank_pred[i]))\n","\n","\n","\n","  # For multi-author submissions in a block, average the scores to get the isotonic score.\n","  submission_greedy_iso_rating = {}\n","  for submission in paper_part:\n","      submission_greedy_iso_rating[submission] = []\n","\n","  for author in author_submission_rank_greedy_iso:\n","      for i in range(len(author_submission_rank_greedy_iso[author])):\n","          submission_greedy_iso_rating[author_submission_rank_greedy_iso[author][i][0]].append(author_submission_rank_greedy_iso[author][i][2])\n","\n","  for submission in submission_greedy_iso_rating:\n","      submission_greedy_iso_rating[submission] = [float(rating) for rating in submission_greedy_iso_rating[submission]]\n","      avg_rating = sum(submission_greedy_iso_rating[submission])/len(submission_greedy_iso_rating[submission])\n","      submission_greedy_iso_rating[submission] = avg_rating\n","\n","  for i in paper_part:\n","    calibrated_scores[i] = submission_greedy_iso_rating[i]\n","\n","\n","\n","# Greedy Isotonic Score\n","greedy_iso_rating = []\n","for i in range(n_2):\n","  greedy_iso_rating.append(calibrated_scores[i])"],"metadata":{"id":"tPKDhzqM4aIB","executionInfo":{"status":"ok","timestamp":1745892492513,"user_tz":240,"elapsed":3395,"user":{"displayName":"Buxin Su","userId":"12574803226597557409"}}},"execution_count":14,"outputs":[]},{"cell_type":"markdown","source":["## Compute MSE values for all submissions."],"metadata":{"id":"Pb3YkCfz4b8T"}},{"cell_type":"code","source":["# proxy\n","submission_true_rating = {}\n","for submission in range(n_2):\n","    submission_true_rating[submission] = df[df['submission_idx'] == submission]['ground_truth'].tolist()\n","    submission_true_rating[submission] = submission_true_rating[submission][0]\n","\n","True_score_multi_iso = []\n","for i in range(n_2):\n","    True_score_multi_iso.append(submission_true_rating[i])\n","\n","\n","\n","# score\n","old_rating = {}\n","for submission in range(n_2):\n","    old_rating[submission] = df[df['submission_idx'] == submission]['score'].tolist()\n","    old_rating[submission] = old_rating[submission][0]\n","\n","old_score_multi_iso = []\n","for i in range(n_2):\n","    old_score_multi_iso.append(old_rating[i])\n","\n","\n","\n","# print the MSE\n","print('Greedy Isotonic Mechanism', mean_squared_error(greedy_iso_rating, True_score_multi_iso))\n","print('Multiowner Isotonic Mechanism', mean_squared_error(multi_iso_rating, True_score_multi_iso))\n","#print('Singal Isotonic Mechanism:', mean_squared_error(iso_rating, True_score))\n","print('Review Rating', mean_squared_error(old_score_multi_iso, True_score_multi_iso))\n","\n","\n","\n","# Create two lists to record: (y - R)^2 and (\\hat{R} - R)^2 values.\n","greedy_diff = []\n","multi_diff = []\n","old_diff = []\n","for i in range(len(True_score_multi_iso)):\n","  greedy_diff.append( (greedy_iso_rating[i] - True_score_multi_iso[i])**2 )\n","  multi_diff.append( (multi_iso_rating[i] - True_score_multi_iso[i])**2 )\n","  old_diff.append( (old_score_multi_iso[i] - True_score_multi_iso[i])**2 )\n","\n","\n","\n","#Perform the paired sample t-test\n","t_statistic, p_value = stats.ttest_rel(old_diff, greedy_diff, alternative='greater')\n","print(\"Before Rebuttal with proxy t-test for greedy:\", t_statistic)\n","print(\"Before Rebuttal with proxy p-value for greedy:\", p_value)\n","\n","\n","\n","#Perform the paired sample t-test\n","t_statistic, p_value = stats.ttest_rel(old_diff, multi_diff, alternative='greater')\n","print(\"Before Rebuttal with proxy t-test for multi-owner:\", t_statistic)\n","print(\"Before Rebuttal with proxy p-value for multi-owner:\", p_value)\n","\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"mCQnj1UK5KJY","executionInfo":{"status":"ok","timestamp":1745892497749,"user_tz":240,"elapsed":5235,"user":{"displayName":"Buxin Su","userId":"12574803226597557409"}},"outputId":"1bd6643b-3190-45b7-d405-6399f8fb9d60"},"execution_count":15,"outputs":[{"output_type":"stream","name":"stdout","text":["Greedy Isotonic Mechanism 0.4430935570617077\n","Multiowner Isotonic Mechanism 0.46731765944353937\n","Review Rating 0.5733162280027286\n","Before Rebuttal with proxy t-test for greedy: 14.279465187972411\n","Before Rebuttal with proxy p-value for greedy: 7.556777081480864e-45\n","Before Rebuttal with proxy t-test for multi-owner: 12.734297299365455\n","Before Rebuttal with proxy p-value for multi-owner: 2.379849650966112e-36\n"]}]},{"cell_type":"markdown","source":["## Compute L1 values for all submissions."],"metadata":{"id":"2TZFKZQ1hb1s"}},{"cell_type":"code","source":["# proxy\n","submission_true_rating = {}\n","for submission in range(n_2):\n","    submission_true_rating[submission] = df[df['submission_idx'] == submission]['ground_truth'].tolist()\n","    submission_true_rating[submission] = submission_true_rating[submission][0]\n","\n","True_score_multi_iso = []\n","for i in range(n_2):\n","    True_score_multi_iso.append(submission_true_rating[i])\n","\n","\n","\n","# score\n","old_rating = {}\n","for submission in range(n_2):\n","    old_rating[submission] = df[df['submission_idx'] == submission]['score'].tolist()\n","    old_rating[submission] = old_rating[submission][0]\n","\n","old_score_multi_iso = []\n","for i in range(n_2):\n","    old_score_multi_iso.append(old_rating[i])\n","\n","\n","\n","# Create two lists to record: (y - R)^2 and (\\hat{R} - R)^2 values.\n","greedy_diff = []\n","multi_diff = []\n","old_diff = []\n","for i in range(len(True_score_multi_iso)):\n","  greedy_diff.append( abs(greedy_iso_rating[i] - True_score_multi_iso[i]) )\n","  multi_diff.append( abs(multi_iso_rating[i] - True_score_multi_iso[i]) )\n","  old_diff.append( abs(old_score_multi_iso[i] - True_score_multi_iso[i]) )\n","\n","\n","\n","# print the MSE\n","print('Greedy Isotonic Mechanism', np.mean(greedy_diff) )\n","print('Multiowner Isotonic Mechanism', np.mean(multi_diff) )\n","print('Review Rating', np.mean(old_diff) )\n","\n","\n","\n","#Perform the paired sample t-test\n","t_statistic, p_value = stats.ttest_rel(old_diff, greedy_diff, alternative='greater')\n","print(\"Before Rebuttal with proxy t-test for greedy:\", t_statistic)\n","print(\"Before Rebuttal with proxy p-value for greedy:\", p_value)\n","\n","\n","\n","#Perform the paired sample t-test\n","t_statistic, p_value = stats.ttest_rel(old_diff, multi_diff, alternative='greater')\n","print(\"Before Rebuttal with proxy t-test for multi-owner:\", t_statistic)\n","print(\"Before Rebuttal with proxy p-value for multi-owner:\", p_value)\n","\n","\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1745892500010,"user_tz":240,"elapsed":2256,"user":{"displayName":"Buxin Su","userId":"12574803226597557409"}},"outputId":"5bb4ac56-7190-4684-b7a8-8d3c1528c789","id":"s-7e228Shb10"},"execution_count":16,"outputs":[{"output_type":"stream","name":"stdout","text":["Greedy Isotonic Mechanism 0.5222092977858515\n","Multiowner Isotonic Mechanism 0.5381671749188246\n","Review Rating 0.6003783108517696\n","Before Rebuttal with proxy t-test for greedy: 16.392197514238784\n","Before Rebuttal with proxy p-value for greedy: 9.005197558361844e-58\n","Before Rebuttal with proxy t-test for multi-owner: 14.481101740918152\n","Before Rebuttal with proxy p-value for multi-owner: 5.1130291060688026e-46\n"]}]}]}