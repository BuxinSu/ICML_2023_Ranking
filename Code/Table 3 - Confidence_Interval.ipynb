{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Zd8s4wjVz-gv"
   },
   "source": [
    "# **Import Google Drive**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 525,
     "status": "ok",
     "timestamp": 1745866528234,
     "user": {
      "displayName": "Buxin Su",
      "userId": "12574803226597557409"
     },
     "user_tz": 240
    },
    "id": "kpj7DF1k-jRR",
    "outputId": "ca93eaf6-9fa7-41ca-9bb4-a2f4e27a6c59"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7PcDKgM_0ElJ"
   },
   "source": [
    "# **Setting**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1745866528235,
     "user": {
      "displayName": "Buxin Su",
      "userId": "12574803226597557409"
     },
     "user_tz": 240
    },
    "id": "3LvEW5gO0E-K"
   },
   "outputs": [],
   "source": [
    "from sklearn.isotonic import isotonic_regression\n",
    "import cvxpy as cp\n",
    "import numpy as np\n",
    "import csv, os\n",
    "from scipy import stats\n",
    "from sklearn import metrics\n",
    "import itertools\n",
    "import pandas as pd\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import matplotlib.pyplot as plt\n",
    "import statistics\n",
    "from scipy.stats import levene\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=RuntimeWarning)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kPWWcc7LiVmU"
   },
   "source": [
    "# **Function: Partition all submissions according to \"Greedy\" and \"Multi-owner\" methods**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1745866528236,
     "user": {
      "displayName": "Buxin Su",
      "userId": "12574803226597557409"
     },
     "user_tz": 240
    },
    "id": "AlzU8-hqiU4Z"
   },
   "outputs": [],
   "source": [
    "def validate(partition, graph, n):\n",
    "\t# check that\n",
    "\t# 1. each paper is in exactly one partition\n",
    "\t# 2. the number of papers in all partition is equal to the number of papers\n",
    "\t# 3. each partition has at least two authors owns all papers in the partition\n",
    "\n",
    "\tpapers = set()\n",
    "\tfull_author_parts = []\n",
    "\tfor part in partition[:-1]:\n",
    "\t\tassert( len(part.intersection(papers)) == 0 )\n",
    "\t\tpapers |= part\n",
    "\t\t# find all authors that can rank all papers in this part\n",
    "\t\tcnt = 0\n",
    "\t\tauthor_part = set()\n",
    "\t\tfor author, val in graph.items():\n",
    "\t\t\tif len(val.intersection(part)) == len(part):\n",
    "\t\t\t\tcnt += 1\n",
    "\t\t\t\tauthor_part.add(author)\n",
    "\n",
    "\t\t# assert( cnt >= 2 )\n",
    "\t\tfull_author_parts.append(author_part)\n",
    "\n",
    "\t# add the last partition\n",
    "\tfull_author_parts.append(set())\n",
    "\tpapers |= partition[-1]\n",
    "\tassert(len(papers) == n)\n",
    "\n",
    "\treturn full_author_parts\n",
    "\n",
    "\n",
    "def greedy(graph, m, n, randomize=False, level=1):\n",
    "\tpartition = []\n",
    "\tauthor_parts = []\n",
    "\tallocated_papers = set()\n",
    "\n",
    "\tif level == 1:\n",
    "\t\tparts = [ graph[i].copy() for i in range(m) ]\n",
    "\t\tindex2pair = [ set([i]) for i in range(m) ]\n",
    "\telif level == 2:\n",
    "\t\tparts = [ graph[i].intersection(graph[j])  for i in range(m) for j in range(i+1, m) ]\n",
    "\t\tindex2pair = [ set([i,j]) for i in range(m) for j in range(i+1, m) ]\n",
    "\n",
    "\tmax_idx = 0\n",
    "\tmax_val = 0\n",
    "\tactive_indices = set( [i for i in range(len(parts)) if len(parts[i]) > 1] )\n",
    "\t# for i in range(0, len(parts)):\n",
    "\tfor i in active_indices:\n",
    "\t\tif len(parts[i]) > max_val:\n",
    "\t\t\tmax_idx = i\n",
    "\t\t\tmax_val = len(parts[i])\n",
    "\n",
    "\twhile len(allocated_papers) < n and len(parts[max_idx]) > 1:\n",
    "\t\tmax_part = parts[max_idx].copy()\n",
    "\t\tpartition.append( max_part )\n",
    "\t\tauthor_parts.append( index2pair[max_idx] )\n",
    "\t\tallocated_papers |= max_part\n",
    "\n",
    "\t\tmax_idx = 0\n",
    "\t\tmax_val = 0\n",
    "\t\t# for i in range(0, len(parts)):\n",
    "\t\tto_remove = set()\n",
    "\t\tfor i in active_indices:\n",
    "\t\t\tparts[i].difference_update(max_part)\n",
    "\t\t\tif len(parts[i]) < 2:\n",
    "\t\t\t\tto_remove.add(i)\n",
    "\t\t\t\tcontinue\n",
    "\t\t\tif len(parts[i]) > max_val:\n",
    "\t\t\t\tmax_idx = i\n",
    "\t\t\t\tmax_val = len(parts[i])\n",
    "\t\tmax_part = parts[max_idx].copy()\n",
    "\t\tactive_indices.difference_update(to_remove)\n",
    "\n",
    "\t# add all remaining papers to the last partition\n",
    "\tpartition.append(set())\n",
    "\tauthor_parts.append(set())\n",
    "\tfor i in range(n):\n",
    "\t\tif i not in allocated_papers:\n",
    "\t\t\tpartition[-1].add(i)\n",
    "\n",
    "\treturn partition, author_parts\n",
    "\n",
    "\n",
    "def arbitrary(graph, m, n, randomize=False):\n",
    "\tpartition = []\n",
    "\tauthor_parts = []\n",
    "\tallocated_papers = set()\n",
    "\n",
    "\tparts = [ graph[i].copy() for i in range(m) ]\n",
    "\tindex2pair = [ set([i]) for i in range(m) ]\n",
    "\n",
    "\tidx = 0\n",
    "\twhile len(parts[idx]) < 2 and idx < len(parts)-1: idx += 1\n",
    "\n",
    "\twhile len(allocated_papers) < n and idx != -1:\n",
    "\t\tpart = parts[idx].copy()\n",
    "\n",
    "\t\tpartition.append( part )\n",
    "\t\tauthor_parts.append( index2pair[idx] )\n",
    "\t\tallocated_papers |= part\n",
    "\n",
    "\t\tidx = -1\n",
    "\t\tval = None\n",
    "\t\tfor i in range(0, len(parts)):\n",
    "\t\t\tparts[i].difference_update(part)\n",
    "\t\t\tif len(parts[i]) >= 2:\n",
    "\t\t\t\tidx = i\n",
    "\t\t\t\tval = len(parts[i])\n",
    "\n",
    "\tpartition.append(set())\n",
    "\tauthor_parts.append(set())\n",
    "\tfor i in range(n):\n",
    "\t\tif i not in allocated_papers:\n",
    "\t\t\tpartition[-1].add(i)\n",
    "\n",
    "\treturn partition, author_parts\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "F7Y3yIRN8_p2"
   },
   "source": [
    "# **Simple-averaging Isotonic Scores, Proxy**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RnkrFd1f0YIN"
   },
   "source": [
    "## Load CSV file into a pandas DataFrame\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 73,
     "status": "ok",
     "timestamp": 1745866528307,
     "user": {
      "displayName": "Buxin Su",
      "userId": "12574803226597557409"
     },
     "user_tz": 240
    },
    "id": "Ak-WjHX90Zv6"
   },
   "outputs": [],
   "source": [
    "# Load CSV file into a pandas DataFrame\n",
    "df = pd.read_csv(r'proxy_score.csv')\n",
    "df = df.drop_duplicates(['submission_idx', 'author_idx'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7mCPHu1C0bDc"
   },
   "source": [
    "## Organize each block by {author: [submission, rank, score]}.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "executionInfo": {
     "elapsed": 3934,
     "status": "ok",
     "timestamp": 1745866532242,
     "user": {
      "displayName": "Buxin Su",
      "userId": "12574803226597557409"
     },
     "user_tz": 240
    },
    "id": "Sx-FhyBm0ebi"
   },
   "outputs": [],
   "source": [
    "author_submission_rank_old = {}\n",
    "authors = df['author_idx'].unique()\n",
    "for author in authors:\n",
    "    author_submission_rank_old[author] = []\n",
    "    submissions = list(set(df[df['author_idx'] == author]['submission_idx'].tolist()))\n",
    "\n",
    "    for i in range(len(submissions)):\n",
    "        rank = df[(df['submission_idx'] == submissions[i]) & (df['author_idx'] == author)]['rank'].tolist()[0]\n",
    "        ratings = df[(df['submission_idx'] == submissions[i]) & (df['author_idx'] == author)]['score'].tolist()[0]\n",
    "        author_submission_rank_old[author].append((submissions[i], rank, ratings))\n",
    "\n",
    "# print(author_submission_rank_old)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MFF6_8mg0pJZ"
   },
   "source": [
    "## Sort submissions by rank; in case of ties, sort by score.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "executionInfo": {
     "elapsed": 11,
     "status": "ok",
     "timestamp": 1745866532254,
     "user": {
      "displayName": "Buxin Su",
      "userId": "12574803226597557409"
     },
     "user_tz": 240
    },
    "id": "aVSHptys0quM"
   },
   "outputs": [],
   "source": [
    "def sort_submissions(author_submission_rank_old):\n",
    "    for author in author_submission_rank_old:\n",
    "        author_submission_rank_old[author].sort(key=lambda x: (x[1], -x[2]), reverse=False)\n",
    "    return author_submission_rank_old\n",
    "\n",
    "author_submission_rank_old = sort_submissions(author_submission_rank_old)\n",
    "# author_submission_rank_old"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BZUWHz7j0udU"
   },
   "source": [
    "## Compute isotonic scores for each author.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "executionInfo": {
     "elapsed": 458,
     "status": "ok",
     "timestamp": 1745866532721,
     "user": {
      "displayName": "Buxin Su",
      "userId": "12574803226597557409"
     },
     "user_tz": 240
    },
    "id": "KVQW_Pc70yTL"
   },
   "outputs": [],
   "source": [
    "author_submission_rank_new = {}\n",
    "for author in author_submission_rank_old:\n",
    "    ir_rank = []\n",
    "    for i in range(len(author_submission_rank_old[author])):\n",
    "        r1 = author_submission_rank_old[author][i][2]\n",
    "        ir_rank.append(r1)\n",
    "    ir_rank = np.array(ir_rank)\n",
    "    ir_rank_pred =  isotonic_regression(ir_rank, sample_weight = None, y_min=0.0, y_max=10.0, increasing=False)\n",
    "\n",
    "    author_submission_rank_new[author] = []\n",
    "    for i in range(len(author_submission_rank_old[author])):\n",
    "        author_submission_rank_new[author].append((author_submission_rank_old[author][i][0], author_submission_rank_old[author][i][1], ir_rank_pred[i]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bFKfCIwq00Bx"
   },
   "source": [
    "## For multi-author submissions, average the scores to get the isotonic score.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "executionInfo": {
     "elapsed": 1,
     "status": "ok",
     "timestamp": 1745866532723,
     "user": {
      "displayName": "Buxin Su",
      "userId": "12574803226597557409"
     },
     "user_tz": 240
    },
    "id": "hRHAlg3u01Xj"
   },
   "outputs": [],
   "source": [
    "final_submission_list = df['submission_idx'].unique()\n",
    "\n",
    "submission_new_rating = {}\n",
    "for submission in final_submission_list:\n",
    "    submission_new_rating[submission] = []\n",
    "\n",
    "for author in author_submission_rank_new:\n",
    "    for i in range(len(author_submission_rank_new[author])):\n",
    "      if author_submission_rank_new[author][i][0] in final_submission_list:\n",
    "        submission_new_rating[author_submission_rank_new[author][i][0]].append(author_submission_rank_new[author][i][2])\n",
    "\n",
    "for submission in final_submission_list:\n",
    "    submission_new_rating[submission] = [float(rating) for rating in submission_new_rating[submission]]\n",
    "    avg_rating = sum(submission_new_rating[submission])/len(submission_new_rating[submission])\n",
    "    submission_new_rating[submission] = avg_rating"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SdDxNarq1IiI"
   },
   "source": [
    "## Compute MSE values for all submissions and Plot.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1740,
     "status": "ok",
     "timestamp": 1745866534467,
     "user": {
      "displayName": "Buxin Su",
      "userId": "12574803226597557409"
     },
     "user_tz": 240
    },
    "id": "nbHJiLkM1QgC",
    "outputId": "cda89f7c-e7b8-4dc1-af90-a53c0d6506a1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ad-hoc Isotonic Mechanism 1.9656811444437243\n",
      "Review Rating 2.5687166227492315\n"
     ]
    }
   ],
   "source": [
    "# Isotonic score\n",
    "adhoc_iso_rating = []\n",
    "for submission in final_submission_list:\n",
    "  adhoc_iso_rating.append(submission_new_rating[submission])\n",
    "\n",
    "\n",
    "\n",
    "# Proxy\n",
    "submission_true_rating = {}\n",
    "for submission in final_submission_list:\n",
    "    submission_true_rating[submission] = df[df['submission_idx'] == submission]['proxy'].tolist()\n",
    "    submission_true_rating[submission] = submission_true_rating[submission][0]\n",
    "\n",
    "True_score_multi_iso = []\n",
    "for submission in final_submission_list:\n",
    "    True_score_multi_iso.append(submission_true_rating[submission])\n",
    "\n",
    "\n",
    "\n",
    "# Score\n",
    "old_rating = {}\n",
    "for submission in final_submission_list:\n",
    "    old_rating[submission] = df[df['submission_idx'] == submission]['score'].tolist()\n",
    "    old_rating[submission] = old_rating[submission][0]\n",
    "\n",
    "old_score_multi_iso = []\n",
    "for submission in final_submission_list:\n",
    "    old_score_multi_iso.append(old_rating[submission])\n",
    "\n",
    "\n",
    "\n",
    "# Compute MSE\n",
    "print('Ad-hoc Isotonic Mechanism', mean_squared_error(adhoc_iso_rating, True_score_multi_iso))\n",
    "print('Review Rating', mean_squared_error(old_score_multi_iso, True_score_multi_iso))\n",
    "\n",
    "\n",
    "\n",
    "# Create two lists to record: (y - R)^2 and (\\hat{R} - R)^2 values.\n",
    "adhoc_diff = []\n",
    "old_diff = []\n",
    "for i in range(len(True_score_multi_iso)):\n",
    "  adhoc_diff.append( (adhoc_iso_rating[i] - True_score_multi_iso[i])**2 )\n",
    "  old_diff.append( (old_score_multi_iso[i] - True_score_multi_iso[i])**2 )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 13,
     "status": "ok",
     "timestamp": 1745866534483,
     "user": {
      "displayName": "Buxin Su",
      "userId": "12574803226597557409"
     },
     "user_tz": 240
    },
    "id": "GMEKr8WZX78A",
    "outputId": "4366c5c0-996f-4b9d-dae5-e215fa266d3a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6030354783055071\n",
      "0.04283706004608841\n",
      "0.5190748406151738 0.6869961159958403\n",
      "0.4926872116267833 0.7133837449842308\n"
     ]
    }
   ],
   "source": [
    "estimator = []\n",
    "for i in range(len(True_score_multi_iso)):\n",
    "  estimator.append( old_diff[i] - adhoc_diff[i] )\n",
    "\n",
    "mean = statistics.mean(estimator)\n",
    "sd = statistics.stdev(estimator)/np.sqrt(len(True_score_multi_iso))\n",
    "print( mean )\n",
    "print( sd )\n",
    "\n",
    "print( mean - 1.96 * sd, mean + 1.96 * sd )\n",
    "print( mean - 2.576 * sd, mean + 2.576 * sd )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kQQuVCdX2UKJ"
   },
   "source": [
    "# **Greedy/Multi-owner Isotonic Scores, Proxy**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "e27iIugz2grj"
   },
   "source": [
    "## Load CSV file into a pandas DataFrame\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 530,
     "status": "ok",
     "timestamp": 1745866535017,
     "user": {
      "displayName": "Buxin Su",
      "userId": "12574803226597557409"
     },
     "user_tz": 240
    },
    "id": "tn0ZcvFA2g_a"
   },
   "outputs": [],
   "source": [
    "# Load CSV file into a pandas DataFrame\n",
    "df = pd.read_csv(r'proxy_score.csv')\n",
    "df = df.drop_duplicates(['submission_idx', 'author_idx'])\n",
    "\n",
    "\n",
    "# Extract the unique authors from the DataFrame\n",
    "authors = df['author_idx'].unique()\n",
    "submissions = df['submission_idx'].unique()\n",
    "\n",
    "author_submission = {}\n",
    "for author in authors:\n",
    "    submissionss = list( set(df[df['author_idx'] == author]['submission_idx'].tolist()) )\n",
    "    author_submission[author] = submissionss\n",
    "\n",
    "m_2 = len(author_submission)\n",
    "n_2 = len(submissions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lSrynyyK2pdI"
   },
   "source": [
    "## Organize all the authors and submissions as the following 'graph': authors = [..., {..., paper_idx : ranking, ...}, ...]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "executionInfo": {
     "elapsed": 1999,
     "status": "ok",
     "timestamp": 1745866537021,
     "user": {
      "displayName": "Buxin Su",
      "userId": "12574803226597557409"
     },
     "user_tz": 240
    },
    "id": "uNDek9xm2pth"
   },
   "outputs": [],
   "source": [
    "authors = []\n",
    "for author in author_submission:\n",
    "    submission_ranking = {}\n",
    "    for i in range(len(author_submission[author])):\n",
    "        submission_ranking[author_submission[author][i]] = df[(df['submission_idx'] == author_submission[author][i]) & (df['author_idx'] == author)]['rank'].tolist()\n",
    "        submission_ranking[author_submission[author][i]] = submission_ranking[author_submission[author][i]][0]\n",
    "    authors.append(submission_ranking)\n",
    "\n",
    "graph = {}\n",
    "for i, author in enumerate(authors):\n",
    "    graph[i] = set( int(k) for k in author.keys())\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aZOd2Vb63M-W"
   },
   "source": [
    "## Multi-owner Isotonic\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "executionInfo": {
     "elapsed": 4750,
     "status": "ok",
     "timestamp": 1745866541769,
     "user": {
      "displayName": "Buxin Su",
      "userId": "12574803226597557409"
     },
     "user_tz": 240
    },
    "id": "JprHQPzQ3wBU"
   },
   "outputs": [],
   "source": [
    "# Partition all the graph according to Multi-owner algorithm\n",
    "partition, author_parts = arbitrary(graph, m_2, n_2)\n",
    "author_parts = validate(partition, graph, n_2)\n",
    "\n",
    "calibrated_scores = np.zeros(n_2)\n",
    "for part, author_part in zip(partition, author_parts):\n",
    "  if len(author_part) == 0:\n",
    "    for i in part: calibrated_scores[i] = df[df['submission_idx'] == i]['score'].tolist()[0]\n",
    "    continue\n",
    "  paper_part = list(part)\n",
    "\n",
    "\n",
    "\n",
    "  # Organize each block by {author: [submission, rank, score]}.\n",
    "  author_submission_rank_old = {}\n",
    "  for author in author_part:\n",
    "    author_submission_rank_old[author] = []\n",
    "    for i in range(len(paper_part)):\n",
    "        rank = df[(df['submission_idx'] == paper_part[i]) & (df['author_idx'] == author)]['rank'].tolist()[0]\n",
    "        ratings = df[(df['submission_idx'] == paper_part[i]) & (df['author_idx'] == author)]['score'].tolist()[0]\n",
    "        author_submission_rank_old[author].append((paper_part[i], rank, ratings))\n",
    "\n",
    "\n",
    "\n",
    "  # Sort submissions by rank; in case of ties, sort by score.\n",
    "  def sort_submissions(author_submission_rank_old):\n",
    "    for author in author_submission_rank_old:\n",
    "      author_submission_rank_old[author].sort(key=lambda x: (x[1], -x[2]), reverse=False)\n",
    "    return author_submission_rank_old\n",
    "  author_submission_rank_old = sort_submissions(author_submission_rank_old)\n",
    "\n",
    "\n",
    "\n",
    "  # Compute isotonic scores for each author in the block.\n",
    "  author_submission_rank_multi_iso = {}\n",
    "  for author in author_submission_rank_old:\n",
    "      ir_rank = []\n",
    "      for i in range(len(author_submission_rank_old[author])):\n",
    "          r1 = author_submission_rank_old[author][i][2]\n",
    "          ir_rank.append(r1)\n",
    "      ir_rank = np.array(ir_rank)\n",
    "      ir_rank_pred =  isotonic_regression(ir_rank, sample_weight = None, y_min=0.0, y_max=10.0, increasing=False)\n",
    "\n",
    "      author_submission_rank_multi_iso[author] = []\n",
    "      for i in range(len(author_submission_rank_old[author])):\n",
    "          author_submission_rank_multi_iso[author].append((author_submission_rank_old[author][i][0], author_submission_rank_old[author][i][1], ir_rank_pred[i]))\n",
    "\n",
    "\n",
    "\n",
    "  # For multi-author submissions in a block, average the scores to get the isotonic score.\n",
    "  submission_multi_iso_rating = {}\n",
    "  for submission in paper_part:\n",
    "      submission_multi_iso_rating[submission] = []\n",
    "\n",
    "  for author in author_submission_rank_multi_iso:\n",
    "      for i in range(len(author_submission_rank_multi_iso[author])):\n",
    "          submission_multi_iso_rating[author_submission_rank_multi_iso[author][i][0]].append(author_submission_rank_multi_iso[author][i][2])\n",
    "\n",
    "  for submission in submission_multi_iso_rating:\n",
    "      submission_multi_iso_rating[submission] = [float(rating) for rating in submission_multi_iso_rating[submission]]\n",
    "      avg_rating = sum(submission_multi_iso_rating[submission])/len(submission_multi_iso_rating[submission])\n",
    "      submission_multi_iso_rating[submission] = avg_rating\n",
    "\n",
    "  for i in paper_part:\n",
    "    calibrated_scores[i] = submission_multi_iso_rating[i]\n",
    "\n",
    "\n",
    "\n",
    "# Multi-owner Isotonic Score\n",
    "multi_iso_rating = []\n",
    "for i in range(n_2):\n",
    "  multi_iso_rating.append(calibrated_scores[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9J4CQkym30mf"
   },
   "source": [
    "## Greedy Isotonic\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "executionInfo": {
     "elapsed": 3173,
     "status": "ok",
     "timestamp": 1745866544937,
     "user": {
      "displayName": "Buxin Su",
      "userId": "12574803226597557409"
     },
     "user_tz": 240
    },
    "id": "tPKDhzqM4aIB"
   },
   "outputs": [],
   "source": [
    "# Partition all the graph according to greedy algorithm\n",
    "partition, author_parts = greedy(graph, m_2, n_2)\n",
    "author_parts = validate(partition, graph, n_2)\n",
    "\n",
    "calibrated_scores = np.zeros(n_2)\n",
    "for part, author_part in zip(partition, author_parts):\n",
    "  if len(author_part) == 0:\n",
    "    for i in part: calibrated_scores[i] = df[df['submission_idx'] == i]['score'].tolist()[0]\n",
    "    continue\n",
    "  paper_part = list(part)\n",
    "\n",
    "\n",
    "\n",
    "  # Organize each block by {author: [submission, rank, score]}.\n",
    "  author_submission_rank_old = {}\n",
    "  for author in author_part:\n",
    "    author_submission_rank_old[author] = []\n",
    "    for i in range(len(paper_part)):\n",
    "        rank = df[(df['submission_idx'] == paper_part[i]) & (df['author_idx'] == author)]['rank'].tolist()[0]\n",
    "        ratings = df[(df['submission_idx'] == paper_part[i]) & (df['author_idx'] == author)]['score'].tolist()[0]\n",
    "        author_submission_rank_old[author].append((paper_part[i], rank, ratings))\n",
    "\n",
    "\n",
    "\n",
    "  # Sort submissions by rank; in case of ties, sort by score.\n",
    "  def sort_submissions(author_submission_rank_old):\n",
    "    for author in author_submission_rank_old:\n",
    "      author_submission_rank_old[author].sort(key=lambda x: (x[1], -x[2]), reverse=False)\n",
    "    return author_submission_rank_old\n",
    "  author_submission_rank_old = sort_submissions(author_submission_rank_old)\n",
    "\n",
    "\n",
    "\n",
    "  # Compute isotonic scores for each author in the block.\n",
    "  author_submission_rank_greedy_iso = {}\n",
    "  for author in author_submission_rank_old:\n",
    "      ir_rank = []\n",
    "      for i in range(len(author_submission_rank_old[author])):\n",
    "          r1 = author_submission_rank_old[author][i][2]\n",
    "          ir_rank.append(r1)\n",
    "      ir_rank = np.array(ir_rank)\n",
    "      ir_rank_pred =  isotonic_regression(ir_rank, sample_weight = None, y_min=0.0, y_max=10.0, increasing=False)\n",
    "\n",
    "      author_submission_rank_greedy_iso[author] = []\n",
    "      for i in range(len(author_submission_rank_old[author])):\n",
    "          author_submission_rank_greedy_iso[author].append((author_submission_rank_old[author][i][0], author_submission_rank_old[author][i][1], ir_rank_pred[i]))\n",
    "\n",
    "\n",
    "\n",
    "  # For multi-author submissions in a block, average the scores to get the isotonic score.\n",
    "  submission_greedy_iso_rating = {}\n",
    "  for submission in paper_part:\n",
    "      submission_greedy_iso_rating[submission] = []\n",
    "\n",
    "  for author in author_submission_rank_greedy_iso:\n",
    "      for i in range(len(author_submission_rank_greedy_iso[author])):\n",
    "          submission_greedy_iso_rating[author_submission_rank_greedy_iso[author][i][0]].append(author_submission_rank_greedy_iso[author][i][2])\n",
    "\n",
    "  for submission in submission_greedy_iso_rating:\n",
    "      submission_greedy_iso_rating[submission] = [float(rating) for rating in submission_greedy_iso_rating[submission]]\n",
    "      avg_rating = sum(submission_greedy_iso_rating[submission])/len(submission_greedy_iso_rating[submission])\n",
    "      submission_greedy_iso_rating[submission] = avg_rating\n",
    "\n",
    "  for i in paper_part:\n",
    "    calibrated_scores[i] = submission_greedy_iso_rating[i]\n",
    "\n",
    "\n",
    "\n",
    "# Greedy Isotonic Score\n",
    "greedy_iso_rating = []\n",
    "for i in range(n_2):\n",
    "  greedy_iso_rating.append(calibrated_scores[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Pb3YkCfz4b8T"
   },
   "source": [
    "## Compute MSE values for all submissions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1724,
     "status": "ok",
     "timestamp": 1745866546665,
     "user": {
      "displayName": "Buxin Su",
      "userId": "12574803226597557409"
     },
     "user_tz": 240
    },
    "id": "mCQnj1UK5KJY",
    "outputId": "d4083e44-9e42-4a1a-fce9-be4fc14169fb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Greedy Isotonic Mechanism 2.0216258401421445\n",
      "Multiowner Isotonic Mechanism 2.070980801806889\n",
      "Review Rating 2.5687166227492315\n"
     ]
    }
   ],
   "source": [
    "# proxy\n",
    "submission_true_rating = {}\n",
    "for submission in range(n_2):\n",
    "    submission_true_rating[submission] = df[df['submission_idx'] == submission]['proxy'].tolist()\n",
    "    submission_true_rating[submission] = submission_true_rating[submission][0]\n",
    "\n",
    "True_score_multi_iso = []\n",
    "for i in range(n_2):\n",
    "    True_score_multi_iso.append(submission_true_rating[i])\n",
    "\n",
    "\n",
    "\n",
    "# score\n",
    "old_rating = {}\n",
    "for submission in range(n_2):\n",
    "    old_rating[submission] = df[df['submission_idx'] == submission]['score'].tolist()\n",
    "    old_rating[submission] = old_rating[submission][0]\n",
    "\n",
    "old_score_multi_iso = []\n",
    "for i in range(n_2):\n",
    "    old_score_multi_iso.append(old_rating[i])\n",
    "\n",
    "\n",
    "\n",
    "# print the MSE\n",
    "print('Greedy Isotonic Mechanism', mean_squared_error(greedy_iso_rating, True_score_multi_iso))\n",
    "print('Multiowner Isotonic Mechanism', mean_squared_error(multi_iso_rating, True_score_multi_iso))\n",
    "#print('Singal Isotonic Mechanism:', mean_squared_error(iso_rating, True_score))\n",
    "print('Review Rating', mean_squared_error(old_score_multi_iso, True_score_multi_iso))\n",
    "\n",
    "\n",
    "\n",
    "# Create two lists to record: (y - R)^2 and (\\hat{R} - R)^2 values.\n",
    "greedy_diff = []\n",
    "multi_diff = []\n",
    "old_diff = []\n",
    "for i in range(len(True_score_multi_iso)):\n",
    "  greedy_diff.append( (greedy_iso_rating[i] - True_score_multi_iso[i])**2 )\n",
    "  multi_diff.append( (multi_iso_rating[i] - True_score_multi_iso[i])**2 )\n",
    "  old_diff.append( (old_score_multi_iso[i] - True_score_multi_iso[i])**2 )\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eePvZBiyp3SL"
   },
   "source": [
    "## Greedy Confidence Interval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 11,
     "status": "ok",
     "timestamp": 1745866546678,
     "user": {
      "displayName": "Buxin Su",
      "userId": "12574803226597557409"
     },
     "user_tz": 240
    },
    "id": "E7Jnh0BghlBb",
    "outputId": "8fd326d2-a495-47a1-fd4a-c8abf14bc00d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2530\n",
      "0.547090782607087\n",
      "0.043478098189115494\n",
      "0.46187371015642065 0.6323078550577533\n",
      "0.4350912016719255 0.6590903635422485\n"
     ]
    }
   ],
   "source": [
    "estimator = []\n",
    "for i in range(len(True_score_multi_iso)):\n",
    "  estimator.append( old_diff[i] - greedy_diff[i] )\n",
    "print(len(estimator))\n",
    "\n",
    "\n",
    "mean = statistics.mean(estimator)\n",
    "sd = statistics.stdev(estimator)/np.sqrt(len(True_score_multi_iso))\n",
    "print( mean )\n",
    "print( sd )\n",
    "\n",
    "print( mean - 1.96 * sd, mean + 1.96 * sd )\n",
    "print( mean - 2.576 * sd, mean + 2.576 * sd )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KClBxBmap6lz"
   },
   "source": [
    "## Multiowner Confidence Interval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1745866546688,
     "user": {
      "displayName": "Buxin Su",
      "userId": "12574803226597557409"
     },
     "user_tz": 240
    },
    "id": "JjlFXWRhp9LY",
    "outputId": "c15ec189-e313-413b-da07-60b54546dd55"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2530\n",
      "0.4977358209423427\n",
      "0.040552796025095074\n",
      "0.41825234073315637 0.5772193011515291\n",
      "0.3932718183816978 0.6021998235029876\n"
     ]
    }
   ],
   "source": [
    "estimator = []\n",
    "for i in range(len(True_score_multi_iso)):\n",
    "  estimator.append( old_diff[i] - multi_diff[i] )\n",
    "print(len(estimator))\n",
    "\n",
    "mean = statistics.mean(estimator)\n",
    "sd = statistics.stdev(estimator)/np.sqrt(len(True_score_multi_iso))\n",
    "print( mean )\n",
    "print( sd )\n",
    "\n",
    "print( mean - 1.96 * sd, mean + 1.96 * sd )\n",
    "print( mean - 2.576 * sd, mean + 2.576 * sd )\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyNBOLkZ9bJgS/i7+u9RrjXB",
   "collapsed_sections": [
    "Zd8s4wjVz-gv",
    "kPWWcc7LiVmU"
   ],
   "mount_file_id": "1ngu2BIK6f7Db0D82UHdK9A1J1Rc24O3S",
   "provenance": [
    {
     "file_id": "1NzNEMNJbN3cRGcD5i7v4CpV5aOFNqDFd",
     "timestamp": 1745856383815
    },
    {
     "file_id": "1ngu2BIK6f7Db0D82UHdK9A1J1Rc24O3S",
     "timestamp": 1717472119463
    }
   ],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
