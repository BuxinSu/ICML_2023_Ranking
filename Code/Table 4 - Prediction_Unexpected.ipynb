{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"101gyqAU231gl8yIuSVzNXC5kovEF9Fxq","timestamp":1745866703261}],"authorship_tag":"ABX9TyNgXjF+AYJw7xpcK/HFbpty"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# **Import Google Drive**\n"],"metadata":{"id":"IzvX_XX1CDtl"}},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"fg33FdknDKZV","executionInfo":{"status":"ok","timestamp":1745867346165,"user_tz":240,"elapsed":502,"user":{"displayName":"Buxin Su","userId":"12574803226597557409"}},"outputId":"d29bec8e-937d-4579-cc91-735fc137ec91"},"execution_count":14,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}]},{"cell_type":"markdown","source":["# **Setting**\n"],"metadata":{"id":"Zve7gI2zCF_G"}},{"cell_type":"code","source":["from sklearn.isotonic import isotonic_regression\n","import numpy as np\n","import pandas as pd\n","import matplotlib\n","from sklearn.metrics import mean_squared_error\n","import matplotlib.pyplot as plt\n","import statistics\n","import scipy.stats as stats\n","import seaborn as sns\n"],"metadata":{"id":"7iOHQguoDLNl","executionInfo":{"status":"ok","timestamp":1745867346166,"user_tz":240,"elapsed":3,"user":{"displayName":"Buxin Su","userId":"12574803226597557409"}}},"execution_count":15,"outputs":[]},{"cell_type":"markdown","source":["# **Load CSV file into a pandas DataFrame**"],"metadata":{"id":"Nqut4wZHB2c3"}},{"cell_type":"code","source":["# Load your data from a CSV file\n","df_review = pd.read_csv('/content/drive/MyDrive/Research/ICML_2023_Raw/Final_Datafile/review_daily_anon_2023_0422.csv')\n","# Extract the first number from the 'rating' column based on the specific format of the rating content\n","df_review['rating'] = df_review['rating'].str.extract(r'^(\\d+)', expand=False).astype(float)\n","# Extract the first number from the 'confidence' column\n","df_review['confidence'] = df_review['confidence'].str.extract(r'^(\\d+)', expand=False).astype(float)\n","\n","\n","\n","df = pd.read_csv(r'/content/drive/MyDrive/Research/ICML_2023_Result/proxy_score.csv')\n","df = df.drop_duplicates(['submission_idx', 'author_idx'])\n","\n","# check if all submissions have at least 2 reviews\n","for submission in df['submission_id'].unique():\n","  if len( df_review[df_review['submission_id'] == submission]['rating'].tolist() ) <= 1:\n","      print(submission)\n","\n","\n","final_submission_list = df['submission_id'].unique()\n","authors = df['author_id'].unique()\n","\n","df_expect = pd.read_csv(r'/content/drive/MyDrive/Research/ICML_2023_Data/Final_Datafile/aggregated_results_anonymized.csv')\n","df_expect = df_expect.dropna(subset=['submission_id_with_most_unexpected_scores'])\n","\n","\n","# all authors providing unexpected submissions\n","author_unexpect = df_expect['author_id'].unique()\n","author_unexpect = [author for author in authors if author in author_unexpect]\n","\n"],"metadata":{"id":"gnB-kj5LDcqD","executionInfo":{"status":"ok","timestamp":1745867353955,"user_tz":240,"elapsed":7788,"user":{"displayName":"Buxin Su","userId":"12574803226597557409"}}},"execution_count":16,"outputs":[]},{"cell_type":"markdown","source":["# **Record Residual, Confidence and Variance**"],"metadata":{"id":"TxSEFkBYB5Gn"}},{"cell_type":"code","execution_count":17,"metadata":{"id":"ubb_N9uNDHHa","executionInfo":{"status":"ok","timestamp":1745867370745,"user_tz":240,"elapsed":16792,"user":{"displayName":"Buxin Su","userId":"12574803226597557409"}}},"outputs":[],"source":["# Organize all the submissions by {author: [submission, rank, score]}.\n","author_submission_rank_old = {}\n","for author in authors:\n","    author_submission_rank_old[author] = []\n","    submissions = df[df['author_id'] == author]['submission_id'].tolist()\n","    for i in range(len(submissions)):\n","        rank = df[(df['submission_id'] == submissions[i]) & (df['author_id'] == author)]['rank'].tolist()[0]\n","        ratings = df[(df['submission_id'] == submissions[i]) & (df['author_id'] == author)]['rating_0422_mean'].tolist()[0]\n","        author_submission_rank_old[author].append((submissions[i], rank, ratings))\n","\n","\n","\n","# Sort submissions by rank; in case of ties, sort by score.\n","def sort_submissions(author_submission_rank_old):\n","    for author in author_submission_rank_old:\n","        author_submission_rank_old[author].sort(key=lambda x: (x[1], -x[2]), reverse=False)\n","    return author_submission_rank_old\n","author_submission_rank_old = sort_submissions(author_submission_rank_old)\n","\n","\n","\n","# Compute isotonic scores for each author.\n","author_submission_new = {}\n","for author in author_submission_rank_old:\n","    ir_rank = []\n","    for i in range(len(author_submission_rank_old[author])):\n","        r1 = author_submission_rank_old[author][i][2]\n","        ir_rank.append(r1)\n","    ir_rank = np.array(ir_rank)\n","    ir_rank_pred =  isotonic_regression(ir_rank, sample_weight = None, y_min=0.0, y_max=10.0, increasing=False)\n","\n","    for i in range(len(author_submission_rank_old[author])):\n","        author_submission_new[ (author, author_submission_rank_old[author][i][0]) ] = ir_rank_pred[i]\n","\n","\n","\n","# record average score\n","author_submission_old = {}\n","for author in author_submission_rank_old:\n","    for i in range(len(author_submission_rank_old[author])):\n","        author_submission_old[ (author, author_submission_rank_old[author][i][0]) ] = author_submission_rank_old[author][i][2]\n","\n","\n","\n","# record the residual\n","residual = {}\n","for author in author_unexpect:\n","    submission_list = df[df['author_id'] == author ]['submission_id'].tolist()\n","    for submission in submission_list:\n","        residual[(author, submission)] = abs( author_submission_old[ (author, submission) ] - author_submission_new[ (author, submission) ] )\n","\n","\n","\n","# record confidence\n","confidence = {}\n","for author in author_unexpect:\n","    submission_list = df[df['author_id'] == author ]['submission_id'].tolist()\n","    for submission in submission_list:\n","        confidences = df_review[df_review['submission_id'] == submission]['confidence'].tolist()\n","        confidences = np.array(confidences)\n","        confidence[(author, submission)] =  np.mean(confidences)\n","\n","\n","\n","# record variance\n","variance = {}\n","for author in author_unexpect:\n","    submission_list = df[df['author_id'] == author ]['submission_id'].tolist()\n","    for submission in submission_list:\n","        ratings = df_review[df_review['submission_id'] == submission]['rating'].tolist()\n","        ratings = np.array(ratings)\n","        variance[(author, submission)] =  np.var(ratings)"]},{"cell_type":"markdown","source":["# **Count prediction accuracy**"],"metadata":{"id":"Xu4RDXQLBBMB"}},{"cell_type":"code","source":["residual_count = 0\n","variance_count = 0\n","confidence_count = 0\n","total_authors = 0\n","for author in author_unexpect:\n","    submission_list = df[df['author_id'] == author ]['submission_id'].tolist()\n","    unexpect_submission = df_expect[df_expect['author_id'] == author]['submission_id_with_most_unexpected_scores'].tolist()[0]\n","    if unexpect_submission in submission_list:\n","      total_authors += 1\n","      if all( residual[(author, unexpect_submission)] >= residual[(author, submission)] for submission in submission_list ):\n","          residual_count += 1\n","      if all( variance[(author, unexpect_submission)] >= variance[(author, submission)] for submission in submission_list ):\n","          variance_count += 1\n","      if all( confidence[(author, unexpect_submission)] <= confidence[(author, submission)] for submission in submission_list ):\n","          confidence_count += 1\n","\n","\n","print(\"# authors with unexpected submissions:\", total_authors)\n","print(\"# authors with unexpected submissions that have the largest mean residual:\", residual_count)\n","print(\"# authors with unexpected submissions that have the largest variance:\", variance_count)\n","print(\"# authors with unexpected submissions that have the least confidence:\", confidence_count)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"tRs2GoFqEyAG","executionInfo":{"status":"ok","timestamp":1745867371110,"user_tz":240,"elapsed":336,"user":{"displayName":"Buxin Su","userId":"12574803226597557409"}},"outputId":"2819bae4-4d07-4edd-f6a2-9f9c4f74812a"},"execution_count":18,"outputs":[{"output_type":"stream","name":"stdout","text":["# authors with unexpected submissions: 322\n","# authors with unexpected submissions that have the largest mean residual: 254\n","# authors with unexpected submissions that have the largest variance: 162\n","# authors with unexpected submissions that have the least confidence: 136\n"]}]}]}