{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"L4","mount_file_id":"1xzpwbtx_o7pJ7GwRm2iAXttkSdIE69mY","authorship_tag":"ABX9TyNoT5b1cBwM0DntrMyjOOM+"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"aMIfhL3blyug","executionInfo":{"status":"ok","timestamp":1745871031738,"user_tz":240,"elapsed":9481,"user":{"displayName":"Buxin Su","userId":"12574803226597557409"}},"outputId":"83506886-bd13-4bb6-c2b2-9763042ebfe3"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}]},{"cell_type":"code","source":["import json\n","from pprint import pprint\n","\n","# Specify the path to your uploaded JSON file\n","json_file_path = '/content/drive/MyDrive/Research/ICML_2023_Raw/DataFile/submission_details_wid.jsonl'\n","\n","# Open the JSON file and load the data\n","with open(json_file_path, 'r') as file:\n","    data = json.load(file)\n","\n","filtered_json_data = []\n","# Iterate through each dictionary in the data\n","for obj in data:\n","    # Check if the dictionary has the key 'invitation' and if its value contains 'Submission6522'\n","    if '4abacaafefc7983e199c198c7fbbc9c02ed2d97f65c1bc5c5f6f1b719a88ef76' in obj['submission_id']:\n","        filtered_json_data.append(obj)\n","\n","\n","word_counts = 0\n","reply_counts = 0\n","for i in range(len(filtered_json_data)):\n","      #if '/Official_Review' in Submission[n][i]['invitations'][0]:\n","        #word_counts += len(Submission[n][i]['content'].split())\n","    if '/Rebuttal' in filtered_json_data[i]['invitations'][0]:\n","      word_counts += len(filtered_json_data[i]['content']['rebuttal']['value'].split())\n","      reply_counts += 1\n","    if '/Official_Comment' in filtered_json_data[i]['invitations'][0]:\n","      word_counts += len(filtered_json_data[i]['content']['comment']['value'].split())\n","      reply_counts += 1\n","\n","\n","\n","Oral_rebuttal = {}\n","Poster_rebuttal = {}\n","Reject_rebuttal = {}\n","Withdrawal_desk_rebuttal = {}\n","\n","\n","for i, sub_dict in enumerate(filtered_json_data):\n","    if '/Withdrawal' in sub_dict['invitations'][0] or '/Desk_Rejection' in sub_dict['invitations'][0]:\n","        print(sub_dict['submission_id'], \":g!\")\n","        break  # Stop inner loop if condition is met\n","\n","else:\n","  if filtered_json_data[-1]['content']['decision']['value'] == 'Reject':\n","    Reject_rebuttal[filtered_json_data[-1]['forum']] = (word_counts, reply_counts)\n","  if filtered_json_data[-1]['content']['decision']['value'] == 'Accept (Poster)':\n","    Poster_rebuttal[filtered_json_data[-1]['forum']] = (word_counts, reply_counts)\n","  if filtered_json_data[-1]['content']['decision']['value'] == 'Accept (Oral & Poster)':\n","    Oral_rebuttal[filtered_json_data[-1]['forum']] = (word_counts, reply_counts)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ZVFct06VFPXX","executionInfo":{"status":"ok","timestamp":1740001369849,"user_tz":300,"elapsed":1283,"user":{"displayName":"Buxin Su","userId":"12574803226597557409"}},"outputId":"2a0640bc-f8b3-4e47-af5f-db4cb1c24062"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["{'id': 'RMXQgVg04R', 'number': 1, 'cdate': 1676941946959, 'tcdate': 1676941946959, 'mdate': 1678801068784, 'tmdate': 1678801068784, 'forum': 'Lt0lAQtiI9', 'replyto': 'Lt0lAQtiI9', 'content': {'summary': {'value': 'This paper proposes a retrieval-augmented model for image captioning. The retrieval model uses CLIP image embedding to find similar images in the image-text database. The captioning model is a combination of the RETRO model and the Flamingo model architecture. The paper also proposes a filtering strategy to improve pre-training performance. The proposed model achieves improved performance for zero-shot/few-shot image captioning.'}, 'strengths_and_weaknesses': {'value': \"Strengths:\\n- Retrieval-augmented image captioning is an interesting direction to explore.\\n- The proposed filtering strategy is useful to prevent shortcut solutions.\\n\\nWeakness:\\n- The paper could have gone deeper in its analysis on the pros and cons of retrieval-augmented image captioning. There are several important questions that are not fully discussed, as listed in the Questions section.\\n- The paper uses existing model architectures (CLIP, RETRO, Flamingo) and the standard language modelling loss. However, it is unclear whether this is the best architecture / loss for retrieval-augmented captioning. \\n- It is unclear to me how the model performs few-shot learning. The inference speed is also not discussed.\\n- The model's improvement becomes marginal when more training data is available, in particular with larger language models.\"}, 'questions': {'value': \"- The image-text retrieval database would have a large influence on the performance of the model. It would be good if the authors could discuss more on how the noise and bias in the retrieval database affect the model's behavior.\\n\\n- Captions in MSCOCO and Flickr30k have a rather restricted vocabulary. It would be better if the authors could provide zero-shot evaluation on NoCaps and also provide more qualitative comparisons. \\n\\n- An important aspect of retrieval-augmented generation is that the model can easily incorporate **new** knowledge in the database. However, the paper has not shown such capability.\\n\\n- How does few-shot learning work? Does each in-context example have corresponding retrieved captions?\\n\\n- What is the inference speed compared to methods without retrieval-augmentation?\\n\\n\"}, 'limitations': {'value': 'The authors could discuss more on (1) how noise&bias in the retrieval database affect the model, (2) how much additional inference cost does the model incur.'}, 'ethics_flag': {'value': 'No'}, 'ethics_review_area': {'value': []}, 'soundness': {'value': '3 good'}, 'presentation': {'value': '3 good'}, 'contribution': {'value': '2 fair'}, 'rating': {'value': '4: Borderline reject: Technically solid paper where reasons to reject, e.g., limited evaluation, outweigh reasons to accept, e.g., good evaluation. Please use sparingly.'}, 'confidence': {'value': '5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully.'}, 'code_of_conduct': {'value': 'Yes'}}, 'invitations': ['ICML.cc/2023/Conference/Submission5660/-/Official_Review', 'ICML.cc/2023/Conference/-/Edit'], 'domain': 'ICML.cc/2023/Conference', 'version': 2, 'submission_id': '4abacaafefc7983e199c198c7fbbc9c02ed2d97f65c1bc5c5f6f1b719a88ef76'}\n","{'id': 'BITOmTqqnl', 'number': 2, 'cdate': 1677980615912, 'tcdate': 1677980615912, 'mdate': 1678801068722, 'tmdate': 1678801068722, 'forum': 'Lt0lAQtiI9', 'replyto': 'Lt0lAQtiI9', 'content': {'summary': {'value': 'This work focused on the task of zero and few-shot image captioning using pre-trained vision language models (e.g., CLIP) and language models (e.g., RETRO). The idea is to (1) establish a knowledge base using Faiss library, (2) retrieve the relevant image-caption pairs for the query image from the database with a filtering strategy, (3) encode the visual information of input image and retrieved results using a trainable attention module, (4) use RETRO as text decoder for caption generation. Experiments are conducted in three settings (zero-shot, few-shot, and fine-tuning) and three datasets (MSCOCO, Flickr30k, NoCaps), which show that the model can consistently achieve better performance than the recent state-of-the-art Flamingo framework.'}, 'strengths_and_weaknesses': {'value': 'Strengths:\\n\\n\\\\+ The paper is well written and organized. It is easy to understand the work and follow the idea.\\n\\n\\\\+ The experiments are conducted on three settings and three datasets to validate the effectiveness and generalization of the model.\\n\\n\\\\+ The improvement is significant compared to the reimplemented Flamingo model, especially when the number of few-shot samples is limited (i.e., 2-shot and 4-shot)\\n\\nWeaknesses:\\n\\n\\\\- The main technical contribution is not clear. The main components of the framework is (a) knowledge base (Faiss), (2) image-caption retriever, (3) image encoder (CLIP), (4) attention module (retrieval-augmented LM, following Flamingo, Lines 205-209), and (5) text decoder (RETRO). It seems that the data and main models are existing technologies. The main difference is the image-caption retriever, which is a combination of k-NN retrieval and a simple filter strategy. Therefore, the novelty of the components is not significant.\\n\\n\\\\- The paper claimed that the proposed approach \"reduces the number of model parameters\". However, compared to Flamingo (Tabs. 1-3), the number of parameters for Re-ViLM is larger. It would be great if a more clear and strict contribution can be claimed.\\n\\n\\\\- It would be great if the authors can summarize the main new messages of this work. According to the above two concerns, it is not clear to me what is the major contribution and novelty of this work, especially to the community of ICML. The aspects can be data, training method, framework, etc.\\n'}, 'questions': {'value': 'Please see weaknesses for the concerns.'}, 'limitations': {'value': 'The authors have adequately addressed the limitations and potential negative societal impact of their work.'}, 'ethics_flag': {'value': 'No'}, 'ethics_review_area': {'value': []}, 'soundness': {'value': '4 excellent'}, 'presentation': {'value': '4 excellent'}, 'contribution': {'value': '3 good'}, 'rating': {'value': '4: Borderline reject: Technically solid paper where reasons to reject, e.g., limited evaluation, outweigh reasons to accept, e.g., good evaluation. Please use sparingly.'}, 'confidence': {'value': '3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.'}, 'code_of_conduct': {'value': 'Yes'}}, 'invitations': ['ICML.cc/2023/Conference/Submission5660/-/Official_Review', 'ICML.cc/2023/Conference/-/Edit'], 'domain': 'ICML.cc/2023/Conference', 'version': 2, 'submission_id': '4abacaafefc7983e199c198c7fbbc9c02ed2d97f65c1bc5c5f6f1b719a88ef76'}\n","{'id': '3XK9V2Hq3h', 'number': 3, 'cdate': 1678022715314, 'tcdate': 1678022715314, 'mdate': 1679645784718, 'tmdate': 1679645784718, 'forum': 'Lt0lAQtiI9', 'replyto': 'Lt0lAQtiI9', 'content': {'summary': {'value': 'This paper improves the zero- and few-shot performance of visual-language models with a retrieval-augmented technique. Re-ViLM retrieves similar information from an external database (CCS and COYO) and trained Flamingo to increase its performance.'}, 'strengths_and_weaknesses': {'value': '+ (+) Paper is simple and easy to follow.\\n+ (+) With a 16% parameter increase, Re-ViLM shows a bootstrapping Flamingo in zero-shot evaluation.\\n\\n- (-) I am concerned about whether realistic use will be useful for performing poorly compared to using only four or eight images in a few-shot evaluation, despite utilizing an extremely large external dataset (CCS-15 million, COYO-104 million pairs).\\n- (-) The paper tackles the use of additional parameters for adapting LMs with visual domain, however, it also requires additional parameters for LM layers. I recommend comparing the trainable parameters with methods including MAGMA, Clip-cap, and so on, regarding performance.\\n- (-) The paper could be strengthened with further baselines. It includes Flamingo only. To show the generalization of the proposed method, it should be required to experiment with other baselines. \\n'}, 'questions': {'value': '- Why are the parameters of RETRO not included in all tables?\\n- What are the inference speed or computational cost (e.g., GFLOPs), and training cost? Is it really efficient to use your method?'}, 'limitations': {'value': \"I don't think the experimental results explain their motives well enough. Although they say that it is insufficient to model the learning data with parameters alone, performance does not dramatically increase even though they actually bring in databases that require much more storage space. Also, comparisons with recent methods of using large language models are dubious. It is not fair to simply compare it with pretraining methods. In addition, it is said that existing methods are limited in adding new data, but the results of table 8 in the paper show that when the model training with retrieval database with CCS and evaluation with CCS+COYO, the performance decreases.\\n\"}, 'ethics_flag': {'value': 'No'}, 'ethics_review_area': {'value': [\"I don't know\"]}, 'soundness': {'value': '1 poor'}, 'presentation': {'value': '2 fair'}, 'contribution': {'value': '2 fair'}, 'rating': {'value': '4: Borderline reject: Technically solid paper where reasons to reject, e.g., limited evaluation, outweigh reasons to accept, e.g., good evaluation. Please use sparingly.'}, 'confidence': {'value': '4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.'}, 'code_of_conduct': {'value': 'Yes'}}, 'invitations': ['ICML.cc/2023/Conference/Submission5660/-/Official_Review', 'ICML.cc/2023/Conference/-/Edit'], 'domain': 'ICML.cc/2023/Conference', 'version': 2, 'submission_id': '4abacaafefc7983e199c198c7fbbc9c02ed2d97f65c1bc5c5f6f1b719a88ef76'}\n","{'id': 'TDBtmYpqb7', 'number': 1, 'cdate': 1681080435831, 'tcdate': 1681080435831, 'mdate': 1681080435831, 'tmdate': 1681080435831, 'forum': 'Lt0lAQtiI9', 'replyto': 'Lt0lAQtiI9', 'content': {'recommendation': {'value': 'Reject'}, 'metareview': {'value': \"First, this paper introduced Re-ViLM, a model for retrieval-augmented image captioning. The paper is praised for being simple and easy to follow, and for showing improvement over the Flamingo model in few-shot settings. However, concerns are raised about realistic use cases and the increase in parameters compared to Flamingo.\\n\\nSecond, retrieval-augmented image-to-text generation model is seen as an interesting direction, and the proposed filtering strategy is useful. However, the paper could have gone deeper in its analysis and it is unclear whether the chosen architectures and loss function are optimal. The model's performance in few-shot learning and inference speed are also not thoroughly discussed, and the improvement becomes marginal with more training data.\\n\\nOverall, the papers are seen as having potential but could benefit from more analysis and clarification on their contributions and limitations. The authors are encouraged to explore alternative architectures and loss functions, and to compare their results to other baselines for greater generalizability.\\n\\nThe paper has been reviewed by domain experts, and comprehensive discussions are provided. All reviewers reach the consensus that the current form of the paper falls short of acceptance.\\n\"}, 'confidence': {'value': 'Certain'}, 'discussion_with_SAC_needed': {'value': 'No discussion needed.'}}, 'invitations': ['ICML.cc/2023/Conference/Submission5660/-/Meta_Review'], 'domain': 'ICML.cc/2023/Conference', 'version': 2, 'submission_id': '4abacaafefc7983e199c198c7fbbc9c02ed2d97f65c1bc5c5f6f1b719a88ef76'}\n","{'id': 'TzmOwXIakY', 'number': 1, 'cdate': 1682367021446, 'tcdate': 1682367021446, 'mdate': 1682372361397, 'tmdate': 1682372361397, 'forum': 'Lt0lAQtiI9', 'replyto': 'Lt0lAQtiI9', 'content': {'title': {'value': 'Paper Decision'}, 'decision': {'value': 'Reject'}, 'comment': {'value': \"First, this paper introduced Re-ViLM, a model for retrieval-augmented image captioning. The paper is praised for being simple and easy to follow, and for showing improvement over the Flamingo model in few-shot settings. However, concerns are raised about realistic use cases and the increase in parameters compared to Flamingo.\\n\\nSecond, retrieval-augmented image-to-text generation model is seen as an interesting direction, and the proposed filtering strategy is useful. However, the paper could have gone deeper in its analysis and it is unclear whether the chosen architectures and loss function are optimal. The model's performance in few-shot learning and inference speed are also not thoroughly discussed, and the improvement becomes marginal with more training data.\\n\\nOverall, the papers are seen as having potential but could benefit from more analysis and clarification on their contributions and limitations. The authors are encouraged to explore alternative architectures and loss functions, and to compare their results to other baselines for greater generalizability.\\n\\nThe paper has been reviewed by domain experts, and comprehensive discussions are provided. All reviewers reach the consensus that the current form of the paper falls short of acceptance.\\n\"}}, 'invitations': ['ICML.cc/2023/Conference/Submission5660/-/Decision', 'ICML.cc/2023/Conference/-/Edit'], 'domain': 'ICML.cc/2023/Conference', 'version': 2, 'submission_id': '4abacaafefc7983e199c198c7fbbc9c02ed2d97f65c1bc5c5f6f1b719a88ef76'}\n","0\n","{}\n","{}\n","{'Lt0lAQtiI9': (0, 0)}\n","{}\n"]}]},{"cell_type":"code","source":["import json\n","from pprint import pprint\n","from sklearn.isotonic import isotonic_regression\n","import cvxpy as cp\n","import numpy as np\n","import csv, os\n","from scipy import stats\n","from sklearn import metrics\n","import itertools\n","import pandas as pd\n","from sklearn.metrics import mean_squared_error\n","import matplotlib.pyplot as plt\n","import statistics\n","\n","# Specify the path to your uploaded JSON file\n","json_file_path = '/content/drive/MyDrive/Research/ICML_2023_Raw/DataFile/submission_details_wid.jsonl'\n","\n","# Open the JSON file and load the data\n","with open(json_file_path, 'r') as file:\n","    data = json.load(file)\n","\n","\n","# Load CSV file into a pandas DataFrame\n","df = pd.read_csv(r'/content/drive/MyDrive/Research/ICML_2023_Result/proxy_score.csv')\n","df = df.drop_duplicates(['submission_idx', 'author_idx'])\n","\n","\n","# For each author, list its ranked submissions according to its ranking\n","\n","author_submission_rank_4 = {}\n","\n","# Extract the unique authors from the DataFrame\n","authors = df['author_id'].unique()\n","\n","# Loop through every submission\n","for author in authors:\n","\n","    author_submission_rank_4[author] = []\n","\n","    # Extract the rating as sets\n","    submissions = df[df['author_id'] == author]['submission_id'].tolist()\n","\n","    for i in range(len(submissions)):\n","\n","        rank = df[(df['submission_id'] == submissions[i]) & (df['author_id'] == author)]['rank'].tolist()\n","        rank = rank[0]\n","\n","        # Add the ratings to the results dictionary\n","        author_submission_rank_4[author].append((submissions[i], rank))\n","\n","def sort_submissions(author_submission_rank_4):\n","    for author in author_submission_rank_4:\n","        author_submission_rank_4[author].sort(key=lambda x: x[1], reverse=False)\n","    return author_submission_rank_4\n","\n","author_submission_rank_4 = sort_submissions(author_submission_rank_4)\n","\n","\n","High_submission_list = []\n","Low_submission_list = []\n","for author in author_submission_rank_4:\n","    # for i in range(len(author_submission_rank_4[author]) - 1):\n","        High_submission_list.append(author_submission_rank_4[author][0][0] )\n","        Low_submission_list.append(author_submission_rank_4[author][-1][0] )\n","\n","\n","\n","High_Oral_rebuttal = {}\n","High_Poster_rebuttal = {}\n","High_Reject_rebuttal = {}\n","High_Withdrawn_rebuttal = {}\n","\n","for submission in High_submission_list:\n","  filtered_json_data = []\n","  # Iterate through each dictionary in the data\n","  for obj in data:\n","      # Check if the dictionary has the key 'invitation' and if its value contains 'Submission6522'\n","      if submission in obj['submission_id']:\n","          filtered_json_data.append(obj)\n","\n","  word_counts = 0\n","  reply_counts = 0\n","  for i in range(len(filtered_json_data)):\n","      #if '/Official_Review' in filtered_json_data[i]['invitations'][0]:\n","        #word_counts += len(filtered_json_data[i]['content'].split())\n","    if '/Rebuttal' in filtered_json_data[i]['invitations'][0]:\n","      word_counts += len(filtered_json_data[i]['content']['rebuttal']['value'].split())\n","      reply_counts += 1\n","    if '/Official_Comment' in filtered_json_data[i]['invitations'][0]:\n","      word_counts += len(filtered_json_data[i]['content']['comment']['value'].split())\n","      reply_counts += 1\n","\n","  for i, sub_dict in enumerate(filtered_json_data):\n","      if '/Withdrawal' in sub_dict['invitations'][0] or '/Desk_Rejection' in sub_dict['invitations'][0]:\n","          # print(sub_dict['submission_id'], \":g!\")\n","          break  # Stop inner loop if condition is met\n","\n","  else:\n","    if filtered_json_data[-1]['content']['decision']['value'] == 'Reject':\n","      High_Reject_rebuttal[filtered_json_data[-1]['submission_id']] = (word_counts, reply_counts)\n","    if filtered_json_data[-1]['content']['decision']['value'] == 'Accept (Poster)':\n","      High_Poster_rebuttal[filtered_json_data[-1]['submission_id']] = (word_counts, reply_counts)\n","    if filtered_json_data[-1]['content']['decision']['value'] == 'Accept (Oral & Poster)':\n","      High_Oral_rebuttal[filtered_json_data[-1]['submission_id']] = (word_counts, reply_counts)\n","\n","\n","High_Oral = []\n","High_Poster = []\n","High_Reject = []\n","\n","\n","for key in High_Oral_rebuttal:\n","  High_Oral.append( int(High_Oral_rebuttal[key][0]) )\n","for key in High_Poster_rebuttal:\n","  High_Poster.append( int(High_Poster_rebuttal[key][0]) )\n","for key in High_Reject_rebuttal:\n","  High_Reject.append( int(High_Reject_rebuttal[key][0]) )\n","\n","\n","\n","Low_Oral_rebuttal = {}\n","Low_Poster_rebuttal = {}\n","Low_Reject_rebuttal = {}\n","Low_Withdrawn_rebuttal = {}\n","\n","for submission in Low_submission_list:\n","  filtered_json_data = []\n","  # Iterate through each dictionary in the data\n","  for obj in data:\n","      # Check if the dictionary has the key 'invitation' and if its value contains 'Submission6522'\n","      if submission in obj['submission_id']:\n","          filtered_json_data.append(obj)\n","\n","  word_counts = 0\n","  reply_counts = 0\n","  for i in range(len(filtered_json_data)):\n","      #if '/Official_Review' in filtered_json_data[i]['invitations'][0]:\n","        #word_counts += len(filtered_json_data[i]['content'].split())\n","    if '/Rebuttal' in filtered_json_data[i]['invitations'][0]:\n","      word_counts += len(filtered_json_data[i]['content']['rebuttal']['value'].split())\n","      reply_counts += 1\n","    if '/Official_Comment' in filtered_json_data[i]['invitations'][0]:\n","      word_counts += len(filtered_json_data[i]['content']['comment']['value'].split())\n","      reply_counts += 1\n","\n","  for i, sub_dict in enumerate(filtered_json_data):\n","      if '/Withdrawal' in sub_dict['invitations'][0] or '/Desk_Rejection' in sub_dict['invitations'][0]:\n","          break  # Stop inner loop if condition is met\n","\n","  else:\n","    if filtered_json_data[-1]['content']['decision']['value'] == 'Reject':\n","      Low_Reject_rebuttal[filtered_json_data[-1]['submission_id']] = (word_counts, reply_counts)\n","    if filtered_json_data[-1]['content']['decision']['value'] == 'Accept (Poster)':\n","      Low_Poster_rebuttal[filtered_json_data[-1]['submission_id']] = (word_counts, reply_counts)\n","    if filtered_json_data[-1]['content']['decision']['value'] == 'Accept (Oral & Poster)':\n","      Low_Oral_rebuttal[filtered_json_data[-1]['submission_id']] = (word_counts, reply_counts)\n","\n","\n","Low_Oral = []\n","Low_Poster = []\n","Low_Reject = []\n","\n","\n","for key in Low_Oral_rebuttal:\n","  Low_Oral.append( int(Low_Oral_rebuttal[key][0]) )\n","for key in Low_Poster_rebuttal:\n","  Low_Poster.append( int(Low_Poster_rebuttal[key][0]) )\n","for key in Low_Reject_rebuttal:\n","  Low_Reject.append( int(Low_Reject_rebuttal[key][0]) )\n","\n","\n","\n","High_Accept = High_Oral + High_Poster\n","Low_Accept = Low_Oral + Low_Poster\n","\n","High_Reject = High_Reject\n","Low_Reject = Low_Reject\n","\n","\n","# Perform the unpaired t-test\n","t_statistic, p_value = stats.ttest_ind(High_Accept, Low_Accept, alternative='greater')\n","\n","# Print the results\n","print(\"Accepted T-statistic:\", t_statistic)\n","print(\"Accepted P-value:\", p_value)\n","\n","# Perform the unpaired t-test\n","t_statistic, p_value = stats.ttest_ind(High_Reject, Low_Reject, alternative='greater')\n","\n","# Print the results\n","print(\"Rejected T-statistic:\", t_statistic)\n","print(\"Rejected P-value:\", p_value)\n","\n","\n","print(np.mean(High_Accept))\n","print(np.mean(Low_Accept))\n","print(np.mean(High_Reject))\n","print(np.mean(Low_Reject))\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Gd9ft37kOTRy","executionInfo":{"status":"ok","timestamp":1745871110063,"user_tz":240,"elapsed":59937,"user":{"displayName":"Buxin Su","userId":"12574803226597557409"}},"outputId":"2dd97264-a4e5-49cc-b37b-4d9b12e4f022"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Accepted T-statistic: 1.2587205133054775\n","Accepted P-value: 0.10426332261770718\n","Rejected T-statistic: 1.5580958097122408\n","Rejected P-value: 0.059730333785854864\n","256.0846681922197\n","229.21428571428572\n","314.3530377668309\n","279.50911854103344\n"]}]},{"cell_type":"code","source":["import json\n","from pprint import pprint\n","from sklearn.isotonic import isotonic_regression\n","import cvxpy as cp\n","import numpy as np\n","import csv, os\n","from scipy import stats\n","from sklearn import metrics\n","import itertools\n","import pandas as pd\n","from sklearn.metrics import mean_squared_error\n","import matplotlib.pyplot as plt\n","import statistics\n","\n","# Specify the path to your uploaded JSON file\n","json_file_path = '/content/drive/MyDrive/Research/ICML_2023_Raw/DataFile/submission_details_wid.jsonl'\n","\n","# Open the JSON file and load the data\n","with open(json_file_path, 'r') as file:\n","    data = json.load(file)\n","\n","\n","# Load CSV file into a pandas DataFrame\n","df = pd.read_csv(r'/content/drive/MyDrive/Research/ICML_2023_Result/proxy_score.csv')\n","df = df.drop_duplicates(['submission_idx', 'author_idx'])\n","\n","\n","# For each author, list its ranked submissions according to its ranking\n","\n","author_submission_rank_4 = {}\n","\n","# Extract the unique authors from the DataFrame\n","authors = df['author_id'].unique()\n","\n","# Loop through every submission\n","for author in authors:\n","\n","    author_submission_rank_4[author] = []\n","\n","    # Extract the rating as sets\n","    submissions = df[df['author_id'] == author]['submission_id'].tolist()\n","\n","    for i in range(len(submissions)):\n","\n","        rank = df[(df['submission_id'] == submissions[i]) & (df['author_id'] == author)]['rank'].tolist()\n","        rank = rank[0]\n","\n","        # Add the ratings to the results dictionary\n","        author_submission_rank_4[author].append((submissions[i], rank))\n","\n","def sort_submissions(author_submission_rank_4):\n","    for author in author_submission_rank_4:\n","        author_submission_rank_4[author].sort(key=lambda x: x[1], reverse=False)\n","    return author_submission_rank_4\n","\n","author_submission_rank_4 = sort_submissions(author_submission_rank_4)\n","\n","\n","High_submission_list = []\n","Low_submission_list = []\n","for author in author_submission_rank_4:\n","    # for i in range(len(author_submission_rank_4[author]) - 1):\n","        High_submission_list.append(author_submission_rank_4[author][0][0] )\n","        Low_submission_list.append(author_submission_rank_4[author][-1][0] )\n","\n","High_Oral_rebuttal = {}\n","High_Poster_rebuttal = {}\n","High_Reject_rebuttal = {}\n","\n","for submission in High_submission_list:\n","  filtered_json_data = []\n","  # Iterate through each dictionary in the data\n","  for obj in data:\n","      # Check if the dictionary has the key 'invitation' and if its value contains 'Submission6522'\n","      if submission in obj['submission_id']:\n","          filtered_json_data.append(obj)\n","\n","  word_counts = 0\n","  reply_counts = 0\n","  for i in range(len(filtered_json_data)):\n","      #if '/Official_Review' in filtered_json_data[i]['invitations'][0]:\n","        #word_counts += len(filtered_json_data[i]['content'].split())\n","    if '/Rebuttal' in filtered_json_data[i]['invitations'][0]:\n","      word_counts += len(filtered_json_data[i]['content']['rebuttal']['value'].split())\n","      reply_counts += 1\n","    if '/Official_Comment' in filtered_json_data[i]['invitations'][0]:\n","      word_counts += len(filtered_json_data[i]['content']['comment']['value'].split())\n","      reply_counts += 1\n","\n","  for i, sub_dict in enumerate(filtered_json_data):\n","      if '/Withdrawal' in sub_dict['invitations'][0] or '/Desk_Rejection' in sub_dict['invitations'][0]:\n","          break  # Stop inner loop if condition is met\n","\n","  else:\n","    if filtered_json_data[-1]['content']['decision']['value'] == 'Reject':\n","      High_Reject_rebuttal[filtered_json_data[-1]['submission_id']] = (word_counts, reply_counts)\n","    if filtered_json_data[-1]['content']['decision']['value'] == 'Accept (Poster)':\n","      High_Poster_rebuttal[filtered_json_data[-1]['submission_id']] = (word_counts, reply_counts)\n","    if filtered_json_data[-1]['content']['decision']['value'] == 'Accept (Oral & Poster)':\n","      High_Oral_rebuttal[filtered_json_data[-1]['submission_id']] = (word_counts, reply_counts)\n","\n","\n","High_Oral = []\n","High_Poster = []\n","High_Reject = []\n","\n","for key in High_Oral_rebuttal:\n","  High_Oral.append( int(High_Oral_rebuttal[key][1]) )\n","for key in High_Poster_rebuttal:\n","  High_Poster.append( int(High_Poster_rebuttal[key][1]) )\n","for key in High_Reject_rebuttal:\n","  High_Reject.append( int(High_Reject_rebuttal[key][1]) )\n","\n","\n","Low_Oral_rebuttal = {}\n","Low_Poster_rebuttal = {}\n","Low_Reject_rebuttal = {}\n","\n","for submission in Low_submission_list:\n","  filtered_json_data = []\n","  # Iterate through each dictionary in the data\n","  for obj in data:\n","      # Check if the dictionary has the key 'invitation' and if its value contains 'Submission6522'\n","      if submission in obj['submission_id']:\n","          filtered_json_data.append(obj)\n","\n","  word_counts = 0\n","  reply_counts = 0\n","  for i in range(len(filtered_json_data)):\n","    if '/Rebuttal' in filtered_json_data[i]['invitations'][0]:\n","      word_counts += len(filtered_json_data[i]['content']['rebuttal']['value'].split())\n","      reply_counts += 1\n","    if '/Official_Comment' in filtered_json_data[i]['invitations'][0]:\n","      word_counts += len(filtered_json_data[i]['content']['comment']['value'].split())\n","      reply_counts += 1\n","\n","  for i, sub_dict in enumerate(filtered_json_data):\n","      if '/Withdrawal' in sub_dict['invitations'][0] or '/Desk_Rejection' in sub_dict['invitations'][0]:\n","          break  # Stop inner loop if condition is met\n","\n","  else:\n","    if filtered_json_data[-1]['content']['decision']['value'] == 'Reject':\n","      Low_Reject_rebuttal[filtered_json_data[-1]['submission_id']] = (word_counts, reply_counts)\n","    if filtered_json_data[-1]['content']['decision']['value'] == 'Accept (Poster)':\n","      Low_Poster_rebuttal[filtered_json_data[-1]['submission_id']] = (word_counts, reply_counts)\n","    if filtered_json_data[-1]['content']['decision']['value'] == 'Accept (Oral & Poster)':\n","      Low_Oral_rebuttal[filtered_json_data[-1]['submission_id']] = (word_counts, reply_counts)\n","\n","\n","Low_Oral = []\n","Low_Poster = []\n","Low_Reject = []\n","\n","for key in Low_Oral_rebuttal:\n","  Low_Oral.append( int(Low_Oral_rebuttal[key][1]) )\n","for key in Low_Poster_rebuttal:\n","  Low_Poster.append( int(Low_Poster_rebuttal[key][1]) )\n","for key in Low_Reject_rebuttal:\n","  Low_Reject.append( int(Low_Reject_rebuttal[key][1]) )\n","\n","High_Accept = High_Oral + High_Poster\n","Low_Accept = Low_Oral + Low_Poster\n","\n","\n","# Perform the unpaired t-test\n","t_statistic, p_value = stats.ttest_ind(High_Accept, Low_Accept, alternative='greater')\n","\n","# Print the results\n","print(\"Accepted T-statistic:\", t_statistic)\n","print(\"Accepted P-value:\", p_value)\n","\n","# Perform the unpaired t-test\n","t_statistic, p_value = stats.ttest_ind(High_Reject, Low_Reject, alternative='greater')\n","\n","# Print the results\n","print(\"Rejected T-statistic:\", t_statistic)\n","print(\"Rejected P-value:\", p_value)\n","\n","\n","print(np.mean(High_Accept))\n","print(np.mean(Low_Accept))\n","print(np.mean(High_Reject))\n","print(np.mean(Low_Reject))\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2XGea6w1SU_X","executionInfo":{"status":"ok","timestamp":1745871455984,"user_tz":240,"elapsed":51738,"user":{"displayName":"Buxin Su","userId":"12574803226597557409"}},"outputId":"c89581e6-062f-4871-d913-c1801c7fa12c"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["Accepted T-statistic: 1.6347032389018232\n","Accepted P-value: 0.051267423738227826\n","Rejected T-statistic: 1.5492497810007824\n","Rejected P-value: 0.06078590746782445\n","1.794050343249428\n","1.6331168831168832\n","1.9507389162561577\n","1.8145896656534954\n"]}]}]}