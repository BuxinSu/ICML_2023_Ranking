{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Zd8s4wjVz-gv"
   },
   "source": [
    "# **Import Google Drive**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 997,
     "status": "ok",
     "timestamp": 1745895991907,
     "user": {
      "displayName": "Buxin Su",
      "userId": "12574803226597557409"
     },
     "user_tz": 240
    },
    "id": "kpj7DF1k-jRR",
    "outputId": "89b01067-626c-44d0-9446-0290bb9973d5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7PcDKgM_0ElJ"
   },
   "source": [
    "# **Setting**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1745895991907,
     "user": {
      "displayName": "Buxin Su",
      "userId": "12574803226597557409"
     },
     "user_tz": 240
    },
    "id": "3LvEW5gO0E-K"
   },
   "outputs": [],
   "source": [
    "from sklearn.isotonic import isotonic_regression\n",
    "import cvxpy as cp\n",
    "import numpy as np\n",
    "import csv, os\n",
    "from scipy import stats\n",
    "from sklearn import metrics\n",
    "import itertools\n",
    "import pandas as pd\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import matplotlib.pyplot as plt\n",
    "import statistics\n",
    "from scipy.stats import levene\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "from sklearn.metrics import r2_score\n",
    "warnings.filterwarnings(\"ignore\", category=RuntimeWarning)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kPWWcc7LiVmU"
   },
   "source": [
    "# **Function: Partition all submissions according to \"Greedy\" and \"Multi-owner\" methods**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1745895991907,
     "user": {
      "displayName": "Buxin Su",
      "userId": "12574803226597557409"
     },
     "user_tz": 240
    },
    "id": "AlzU8-hqiU4Z"
   },
   "outputs": [],
   "source": [
    "def validate(partition, graph, n):\n",
    "\t# check that\n",
    "\t# 1. each paper is in exactly one partition\n",
    "\t# 2. the number of papers in all partition is equal to the number of papers\n",
    "\t# 3. each partition has at least two authors owns all papers in the partition\n",
    "\n",
    "\tpapers = set()\n",
    "\tfull_author_parts = []\n",
    "\tfor part in partition[:-1]:\n",
    "\t\tassert( len(part.intersection(papers)) == 0 )\n",
    "\t\tpapers |= part\n",
    "\t\t# find all authors that can rank all papers in this part\n",
    "\t\tcnt = 0\n",
    "\t\tauthor_part = set()\n",
    "\t\tfor author, val in graph.items():\n",
    "\t\t\tif len(val.intersection(part)) == len(part):\n",
    "\t\t\t\tcnt += 1\n",
    "\t\t\t\tauthor_part.add(author)\n",
    "\n",
    "\t\t# assert( cnt >= 2 )\n",
    "\t\tfull_author_parts.append(author_part)\n",
    "\n",
    "\t# add the last partition\n",
    "\tfull_author_parts.append(set())\n",
    "\tpapers |= partition[-1]\n",
    "\tassert(len(papers) == n)\n",
    "\n",
    "\treturn full_author_parts\n",
    "\n",
    "\n",
    "def greedy(graph, m, n, randomize=False, level=1):\n",
    "\tpartition = []\n",
    "\tauthor_parts = []\n",
    "\tallocated_papers = set()\n",
    "\n",
    "\tif level == 1:\n",
    "\t\tparts = [ graph[i].copy() for i in range(m) ]\n",
    "\t\tindex2pair = [ set([i]) for i in range(m) ]\n",
    "\telif level == 2:\n",
    "\t\tparts = [ graph[i].intersection(graph[j])  for i in range(m) for j in range(i+1, m) ]\n",
    "\t\tindex2pair = [ set([i,j]) for i in range(m) for j in range(i+1, m) ]\n",
    "\n",
    "\tmax_idx = 0\n",
    "\tmax_val = 0\n",
    "\tactive_indices = set( [i for i in range(len(parts)) if len(parts[i]) > 1] )\n",
    "\t# for i in range(0, len(parts)):\n",
    "\tfor i in active_indices:\n",
    "\t\tif len(parts[i]) > max_val:\n",
    "\t\t\tmax_idx = i\n",
    "\t\t\tmax_val = len(parts[i])\n",
    "\n",
    "\twhile len(allocated_papers) < n and len(parts[max_idx]) > 1:\n",
    "\t\tmax_part = parts[max_idx].copy()\n",
    "\t\tpartition.append( max_part )\n",
    "\t\tauthor_parts.append( index2pair[max_idx] )\n",
    "\t\tallocated_papers |= max_part\n",
    "\n",
    "\t\tmax_idx = 0\n",
    "\t\tmax_val = 0\n",
    "\t\t# for i in range(0, len(parts)):\n",
    "\t\tto_remove = set()\n",
    "\t\tfor i in active_indices:\n",
    "\t\t\tparts[i].difference_update(max_part)\n",
    "\t\t\tif len(parts[i]) < 2:\n",
    "\t\t\t\tto_remove.add(i)\n",
    "\t\t\t\tcontinue\n",
    "\t\t\tif len(parts[i]) > max_val:\n",
    "\t\t\t\tmax_idx = i\n",
    "\t\t\t\tmax_val = len(parts[i])\n",
    "\t\tmax_part = parts[max_idx].copy()\n",
    "\t\tactive_indices.difference_update(to_remove)\n",
    "\n",
    "\t# add all remaining papers to the last partition\n",
    "\tpartition.append(set())\n",
    "\tauthor_parts.append(set())\n",
    "\tfor i in range(n):\n",
    "\t\tif i not in allocated_papers:\n",
    "\t\t\tpartition[-1].add(i)\n",
    "\n",
    "\treturn partition, author_parts\n",
    "\n",
    "\n",
    "def arbitrary(graph, m, n, randomize=False):\n",
    "\tpartition = []\n",
    "\tauthor_parts = []\n",
    "\tallocated_papers = set()\n",
    "\n",
    "\tparts = [ graph[i].copy() for i in range(m) ]\n",
    "\tindex2pair = [ set([i]) for i in range(m) ]\n",
    "\n",
    "\tidx = 0\n",
    "\twhile len(parts[idx]) < 2 and idx < len(parts)-1: idx += 1\n",
    "\n",
    "\twhile len(allocated_papers) < n and idx != -1:\n",
    "\t\tpart = parts[idx].copy()\n",
    "\n",
    "\t\tpartition.append( part )\n",
    "\t\tauthor_parts.append( index2pair[idx] )\n",
    "\t\tallocated_papers |= part\n",
    "\n",
    "\t\tidx = -1\n",
    "\t\tval = None\n",
    "\t\tfor i in range(0, len(parts)):\n",
    "\t\t\tparts[i].difference_update(part)\n",
    "\t\t\tif len(parts[i]) >= 2:\n",
    "\t\t\t\tidx = i\n",
    "\t\t\t\tval = len(parts[i])\n",
    "\n",
    "\tpartition.append(set())\n",
    "\tauthor_parts.append(set())\n",
    "\tfor i in range(n):\n",
    "\t\tif i not in allocated_papers:\n",
    "\t\t\tpartition[-1].add(i)\n",
    "\n",
    "\treturn partition, author_parts\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Uz9kGazNypcN"
   },
   "source": [
    "#**Generate simulation dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 12358,
     "status": "ok",
     "timestamp": 1745896004262,
     "user": {
      "displayName": "Buxin Su",
      "userId": "12574803226597557409"
     },
     "user_tz": 240
    },
    "id": "ifq77FnGWTpF",
    "outputId": "464d4643-2b33-42e3-da37-a59fab1c83a9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset updated with new 'score' and 'proxy' columns saved.\n"
     ]
    }
   ],
   "source": [
    "# Load your dataset (replace 'your_dataset.csv' with your actual file path)\n",
    "data = pd.read_csv(r'proxy_score.csv')\n",
    "\n",
    "# Step 1: Create a dictionary to map each submission_id to its rating_0312 list\n",
    "submission_dict = {}\n",
    "for submission_id in data['submission_id'].unique():\n",
    "    first_author_data = data[(data['submission_id'] == submission_id) & (data['author_id'] == data[data['submission_id'] == submission_id]['author_id'].iloc[0])]\n",
    "    submission_dict[submission_id] = first_author_data['rating_0312'].tolist()\n",
    "\n",
    "# Step 2 and Step 3: Generate 'score' and 'proxy' for each submission_id\n",
    "score_proxy_results = {}\n",
    "for submission_id, ratings in submission_dict.items():\n",
    "    score_index = np.random.choice(len(ratings))\n",
    "    score = ratings[score_index]\n",
    "    remaining_ratings = [ratings[i] for i in range(len(ratings)) if i != score_index]\n",
    "    proxy = np.mean(remaining_ratings) if remaining_ratings else score\n",
    "    score_proxy_results[submission_id] = {'score': score, 'proxy': proxy}\n",
    "\n",
    "# Add the 'score' and 'proxy' columns to the original dataset\n",
    "data['score'] = data['submission_id'].map(lambda x: score_proxy_results[x]['score'])\n",
    "data['proxy'] = data['submission_id'].map(lambda x: score_proxy_results[x]['proxy'])\n",
    "\n",
    "# Save the updated dataset\n",
    "data.to_csv('proxy_score_6.csv', index=False)\n",
    "\n",
    "print(\"Dataset updated with new 'score' and 'proxy' columns saved.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "F7Y3yIRN8_p2"
   },
   "source": [
    "# **Simple-averaging Isotonic Scores, Proxy**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "STDyInmgexnB"
   },
   "source": [
    "## Compute L_2 values for all submissions and Plot.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 19703,
     "status": "ok",
     "timestamp": 1745896023959,
     "user": {
      "displayName": "Buxin Su",
      "userId": "12574803226597557409"
     },
     "user_tz": 240
    },
    "id": "Ak-WjHX90Zv6",
    "outputId": "00a118ec-5a7b-4d40-f2fd-b78c6a82c29d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "adhoc_diff_average: 1.9947407746772812\n",
      "old_diff_average: 2.612946201141853\n",
      "Before Rebuttal with proxy t-test for greedy: 20.369651013927328\n",
      "Before Rebuttal with proxy p-value for greedy: 7.85588140412992e-86\n"
     ]
    }
   ],
   "source": [
    "# Initialize list to store squared differences for each run\n",
    "adhoc_diff_all = []\n",
    "old_diff_all = []\n",
    "\n",
    "for trail_idx in range(1,4):\n",
    "    # Load CSV file into a pandas DataFrame\n",
    "    df = pd.read_csv(f'proxy_score_{trail_idx}.csv')\n",
    "    df = df.drop_duplicates(['submission_idx', 'author_idx'])\n",
    "\n",
    "    author_submission_rank_old = {}\n",
    "    authors = df['author_idx'].unique()\n",
    "    for author in authors:\n",
    "        author_submission_rank_old[author] = []\n",
    "        submissions = list(set(df[df['author_idx'] == author]['submission_idx'].tolist()))\n",
    "\n",
    "        for i in range(len(submissions)):\n",
    "            rank = df[(df['submission_idx'] == submissions[i]) & (df['author_idx'] == author)]['rank'].tolist()[0]\n",
    "            ratings = df[(df['submission_idx'] == submissions[i]) & (df['author_idx'] == author)]['score'].tolist()[0]\n",
    "            author_submission_rank_old[author].append((submissions[i], rank, ratings))\n",
    "\n",
    "    def sort_submissions(author_submission_rank_old):\n",
    "        for author in author_submission_rank_old:\n",
    "            author_submission_rank_old[author].sort(key=lambda x: (x[1], -x[2]), reverse=False)\n",
    "        return author_submission_rank_old\n",
    "\n",
    "    author_submission_rank_old = sort_submissions(author_submission_rank_old)\n",
    "\n",
    "    author_submission_rank_new = {}\n",
    "    for author in author_submission_rank_old:\n",
    "        ir_rank = []\n",
    "        for i in range(len(author_submission_rank_old[author])):\n",
    "            r1 = author_submission_rank_old[author][i][2]\n",
    "            ir_rank.append(r1)\n",
    "        ir_rank = np.array(ir_rank)\n",
    "        ir_rank_pred =  isotonic_regression(ir_rank, sample_weight = None, y_min=0.0, y_max=10.0, increasing=False)\n",
    "\n",
    "        author_submission_rank_new[author] = []\n",
    "        for i in range(len(author_submission_rank_old[author])):\n",
    "            author_submission_rank_new[author].append((author_submission_rank_old[author][i][0], author_submission_rank_old[author][i][1], ir_rank_pred[i]))\n",
    "\n",
    "    final_submission_list = df['submission_idx'].unique()\n",
    "\n",
    "    submission_new_rating = {}\n",
    "    for submission in final_submission_list:\n",
    "        submission_new_rating[submission] = []\n",
    "\n",
    "    for author in author_submission_rank_new:\n",
    "        for i in range(len(author_submission_rank_new[author])):\n",
    "          if author_submission_rank_new[author][i][0] in final_submission_list:\n",
    "            submission_new_rating[author_submission_rank_new[author][i][0]].append(author_submission_rank_new[author][i][2])\n",
    "\n",
    "    for submission in final_submission_list:\n",
    "        submission_new_rating[submission] = [float(rating) for rating in submission_new_rating[submission]]\n",
    "        avg_rating = sum(submission_new_rating[submission])/len(submission_new_rating[submission])\n",
    "        submission_new_rating[submission] = avg_rating\n",
    "\n",
    "\n",
    "    # Isotonic score\n",
    "    adhoc_iso_rating = []\n",
    "    for submission in final_submission_list:\n",
    "      adhoc_iso_rating.append(submission_new_rating[submission])\n",
    "\n",
    "    # Proxy\n",
    "    submission_true_rating = {}\n",
    "    for submission in final_submission_list:\n",
    "        submission_true_rating[submission] = df[df['submission_idx'] == submission]['proxy'].tolist()\n",
    "        submission_true_rating[submission] = submission_true_rating[submission][0]\n",
    "\n",
    "    True_score_multi_iso = []\n",
    "    for submission in final_submission_list:\n",
    "        True_score_multi_iso.append(submission_true_rating[submission])\n",
    "\n",
    "    # Score\n",
    "    old_rating = {}\n",
    "    for submission in final_submission_list:\n",
    "        old_rating[submission] = df[df['submission_idx'] == submission]['score'].tolist()\n",
    "        old_rating[submission] = old_rating[submission][0]\n",
    "\n",
    "    old_score_multi_iso = []\n",
    "    for submission in final_submission_list:\n",
    "        old_score_multi_iso.append(old_rating[submission])\n",
    "\n",
    "    # Compute and collect squared errors\n",
    "    adhoc_diff = [(adhoc_iso_rating[i] - True_score_multi_iso[i])**2 for i in range(len(True_score_multi_iso))]\n",
    "    old_diff = [(old_score_multi_iso[i] - True_score_multi_iso[i])**2 for i in range(len(True_score_multi_iso))]\n",
    "\n",
    "    adhoc_diff_all.append(adhoc_diff)\n",
    "    old_diff_all.append(old_diff)\n",
    "\n",
    "# ==========================\n",
    "# After all files are processed, compute the average over all i\n",
    "# ==========================\n",
    "\n",
    "# Convert to numpy arrays for easier computation\n",
    "adhoc_diff_all = np.array(adhoc_diff_all)\n",
    "old_diff_all = np.array(old_diff_all)\n",
    "\n",
    "# Average across the 3 files (axis=0 is file_idx)\n",
    "adhoc_diff_average = np.mean(adhoc_diff_all, axis=0)\n",
    "old_diff_average = np.mean(old_diff_all, axis=0)\n",
    "\n",
    "# Final outputs\n",
    "print('adhoc_diff_average:', np.mean(adhoc_diff_average))\n",
    "print('old_diff_average:', np.mean(old_diff_average))\n",
    "\n",
    "\n",
    "#Perform the paired sample t-test\n",
    "t_statistic, p_value = stats.ttest_rel(old_diff_average, adhoc_diff_average, alternative='greater')\n",
    "print(\"Before Rebuttal with proxy t-test for greedy:\", t_statistic)\n",
    "print(\"Before Rebuttal with proxy p-value for greedy:\", p_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3WsD3-VNf2lD"
   },
   "source": [
    "## Compute L_1 values for all submissions and Plot.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 19531,
     "status": "ok",
     "timestamp": 1745896043485,
     "user": {
      "displayName": "Buxin Su",
      "userId": "12574803226597557409"
     },
     "user_tz": 240
    },
    "id": "s01AsZfRf2lL",
    "outputId": "7db3968b-f46e-46c6-e8c9-45ebd634aa30"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "adhoc_diff_average: 1.1082301329910025\n",
      "old_diff_average: 1.273618796662275\n",
      "Before Rebuttal with proxy t-test for greedy: 19.13915094772145\n",
      "Before Rebuttal with proxy p-value for greedy: 1.1562964147679104e-76\n"
     ]
    }
   ],
   "source": [
    "# Initialize list to store squared differences for each run\n",
    "adhoc_diff_all = []\n",
    "old_diff_all = []\n",
    "\n",
    "for trail_idx in range(1,4):\n",
    "    # Load CSV file into a pandas DataFrame\n",
    "    df = pd.read_csv(f'proxy_score_{trail_idx}.csv')\n",
    "    df = df.drop_duplicates(['submission_idx', 'author_idx'])\n",
    "\n",
    "    author_submission_rank_old = {}\n",
    "    authors = df['author_idx'].unique()\n",
    "    for author in authors:\n",
    "        author_submission_rank_old[author] = []\n",
    "        submissions = list(set(df[df['author_idx'] == author]['submission_idx'].tolist()))\n",
    "\n",
    "        for i in range(len(submissions)):\n",
    "            rank = df[(df['submission_idx'] == submissions[i]) & (df['author_idx'] == author)]['rank'].tolist()[0]\n",
    "            ratings = df[(df['submission_idx'] == submissions[i]) & (df['author_idx'] == author)]['score'].tolist()[0]\n",
    "            author_submission_rank_old[author].append((submissions[i], rank, ratings))\n",
    "\n",
    "    def sort_submissions(author_submission_rank_old):\n",
    "        for author in author_submission_rank_old:\n",
    "            author_submission_rank_old[author].sort(key=lambda x: (x[1], -x[2]), reverse=False)\n",
    "        return author_submission_rank_old\n",
    "\n",
    "    author_submission_rank_old = sort_submissions(author_submission_rank_old)\n",
    "\n",
    "    author_submission_rank_new = {}\n",
    "    for author in author_submission_rank_old:\n",
    "        ir_rank = []\n",
    "        for i in range(len(author_submission_rank_old[author])):\n",
    "            r1 = author_submission_rank_old[author][i][2]\n",
    "            ir_rank.append(r1)\n",
    "        ir_rank = np.array(ir_rank)\n",
    "        ir_rank_pred =  isotonic_regression(ir_rank, sample_weight = None, y_min=0.0, y_max=10.0, increasing=False)\n",
    "\n",
    "        author_submission_rank_new[author] = []\n",
    "        for i in range(len(author_submission_rank_old[author])):\n",
    "            author_submission_rank_new[author].append((author_submission_rank_old[author][i][0], author_submission_rank_old[author][i][1], ir_rank_pred[i]))\n",
    "\n",
    "    final_submission_list = df['submission_idx'].unique()\n",
    "\n",
    "    submission_new_rating = {}\n",
    "    for submission in final_submission_list:\n",
    "        submission_new_rating[submission] = []\n",
    "\n",
    "    for author in author_submission_rank_new:\n",
    "        for i in range(len(author_submission_rank_new[author])):\n",
    "          if author_submission_rank_new[author][i][0] in final_submission_list:\n",
    "            submission_new_rating[author_submission_rank_new[author][i][0]].append(author_submission_rank_new[author][i][2])\n",
    "\n",
    "    for submission in final_submission_list:\n",
    "        submission_new_rating[submission] = [float(rating) for rating in submission_new_rating[submission]]\n",
    "        avg_rating = sum(submission_new_rating[submission])/len(submission_new_rating[submission])\n",
    "        submission_new_rating[submission] = avg_rating\n",
    "\n",
    "\n",
    "    # Isotonic score\n",
    "    adhoc_iso_rating = []\n",
    "    for submission in final_submission_list:\n",
    "      adhoc_iso_rating.append(submission_new_rating[submission])\n",
    "\n",
    "    # Proxy\n",
    "    submission_true_rating = {}\n",
    "    for submission in final_submission_list:\n",
    "        submission_true_rating[submission] = df[df['submission_idx'] == submission]['proxy'].tolist()\n",
    "        submission_true_rating[submission] = submission_true_rating[submission][0]\n",
    "\n",
    "    True_score_multi_iso = []\n",
    "    for submission in final_submission_list:\n",
    "        True_score_multi_iso.append(submission_true_rating[submission])\n",
    "\n",
    "    # Score\n",
    "    old_rating = {}\n",
    "    for submission in final_submission_list:\n",
    "        old_rating[submission] = df[df['submission_idx'] == submission]['score'].tolist()\n",
    "        old_rating[submission] = old_rating[submission][0]\n",
    "\n",
    "    old_score_multi_iso = []\n",
    "    for submission in final_submission_list:\n",
    "        old_score_multi_iso.append(old_rating[submission])\n",
    "\n",
    "    # Compute and collect squared errors\n",
    "    adhoc_diff = [abs(adhoc_iso_rating[i] - True_score_multi_iso[i]) for i in range(len(True_score_multi_iso))]\n",
    "    old_diff = [abs(old_score_multi_iso[i] - True_score_multi_iso[i]) for i in range(len(True_score_multi_iso))]\n",
    "\n",
    "    adhoc_diff_all.append(adhoc_diff)\n",
    "    old_diff_all.append(old_diff)\n",
    "\n",
    "# ==========================\n",
    "# After all files are processed, compute the average over all i\n",
    "# ==========================\n",
    "\n",
    "# Convert to numpy arrays for easier computation\n",
    "adhoc_diff_all = np.array(adhoc_diff_all)\n",
    "old_diff_all = np.array(old_diff_all)\n",
    "\n",
    "# Average across the 3 files (axis=0 is file_idx)\n",
    "adhoc_diff_average = np.mean(adhoc_diff_all, axis=0)\n",
    "old_diff_average = np.mean(old_diff_all, axis=0)\n",
    "\n",
    "# Final outputs\n",
    "print('adhoc_diff_average:', np.mean(adhoc_diff_average))\n",
    "print('old_diff_average:', np.mean(old_diff_average))\n",
    "\n",
    "\n",
    "#Perform the paired sample t-test\n",
    "t_statistic, p_value = stats.ttest_rel(old_diff_average, adhoc_diff_average, alternative='greater')\n",
    "print(\"Before Rebuttal with proxy t-test for greedy:\", t_statistic)\n",
    "print(\"Before Rebuttal with proxy p-value for greedy:\", p_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kQQuVCdX2UKJ"
   },
   "source": [
    "# **Greedy/Multi-owner Isotonic Scores, Proxy**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MQ7xW6x-gicC"
   },
   "source": [
    "## Compute L2 values for all submissions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 36171,
     "status": "ok",
     "timestamp": 1745896079650,
     "user": {
      "displayName": "Buxin Su",
      "userId": "12574803226597557409"
     },
     "user_tz": 240
    },
    "id": "tntDFD5pfXaw",
    "outputId": "1dec6128-f8d2-4003-ab6a-9ef1701de9aa"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Greedy_diff_average: 2.0680999531198805\n",
      "Multi_diff_average: 2.1073726437520905\n",
      "old_diff_average: 2.612946201141853\n",
      "Before Rebuttal with proxy t-test for greedy: 17.611348208377855\n",
      "Before Rebuttal with proxy p-value for greedy: 7.06470527213899e-66\n",
      "Before Rebuttal with proxy t-test for Multi-owner: 18.19408530907814\n",
      "Before Rebuttal with proxy p-value for Multi-owner: 6.53945434043408e-70\n"
     ]
    }
   ],
   "source": [
    "# Initialize list to store squared differences for each run\n",
    "greedy_diff_all = []\n",
    "multi_diff_all = []\n",
    "old_diff_all = []\n",
    "\n",
    "for trail_idx in range(1,4):\n",
    "\n",
    "    # Load CSV file into a pandas DataFrame\n",
    "    df = pd.read_csv(f'proxy_score_{trail_idx}.csv')\n",
    "    df = df.drop_duplicates(['submission_idx', 'author_idx'])\n",
    "\n",
    "\n",
    "    # Extract the unique authors from the DataFrame\n",
    "    authors = df['author_idx'].unique()\n",
    "    submissions = df['submission_idx'].unique()\n",
    "\n",
    "    author_submission = {}\n",
    "    for author in authors:\n",
    "        submissionss = list( set(df[df['author_idx'] == author]['submission_idx'].tolist()) )\n",
    "        author_submission[author] = submissionss\n",
    "\n",
    "    m_2 = len(author_submission)\n",
    "    n_2 = len(submissions)\n",
    "\n",
    "    authors = []\n",
    "    for author in author_submission:\n",
    "        submission_ranking = {}\n",
    "        for i in range(len(author_submission[author])):\n",
    "            submission_ranking[author_submission[author][i]] = df[(df['submission_idx'] == author_submission[author][i]) & (df['author_idx'] == author)]['rank'].tolist()\n",
    "            submission_ranking[author_submission[author][i]] = submission_ranking[author_submission[author][i]][0]\n",
    "        authors.append(submission_ranking)\n",
    "\n",
    "    graph = {}\n",
    "    for i, author in enumerate(authors):\n",
    "        graph[i] = set( int(k) for k in author.keys())\n",
    "\n",
    "    # Partition all the graph according to Multi-owner algorithm\n",
    "    partition, author_parts = arbitrary(graph, m_2, n_2)\n",
    "    author_parts = validate(partition, graph, n_2)\n",
    "\n",
    "    calibrated_scores = np.zeros(n_2)\n",
    "    for part, author_part in zip(partition, author_parts):\n",
    "      if len(author_part) == 0:\n",
    "        for i in part: calibrated_scores[i] = df[df['submission_idx'] == i]['score'].tolist()[0]\n",
    "        continue\n",
    "      paper_part = list(part)\n",
    "\n",
    "      # Organize each block by {author: [submission, rank, score]}.\n",
    "      author_submission_rank_old = {}\n",
    "      for author in author_part:\n",
    "        author_submission_rank_old[author] = []\n",
    "        for i in range(len(paper_part)):\n",
    "            rank = df[(df['submission_idx'] == paper_part[i]) & (df['author_idx'] == author)]['rank'].tolist()[0]\n",
    "            ratings = df[(df['submission_idx'] == paper_part[i]) & (df['author_idx'] == author)]['score'].tolist()[0]\n",
    "            author_submission_rank_old[author].append((paper_part[i], rank, ratings))\n",
    "\n",
    "\n",
    "\n",
    "      # Sort submissions by rank; in case of ties, sort by score.\n",
    "      def sort_submissions(author_submission_rank_old):\n",
    "        for author in author_submission_rank_old:\n",
    "          author_submission_rank_old[author].sort(key=lambda x: (x[1], -x[2]), reverse=False)\n",
    "        return author_submission_rank_old\n",
    "      author_submission_rank_old = sort_submissions(author_submission_rank_old)\n",
    "\n",
    "\n",
    "\n",
    "      # Compute isotonic scores for each author in the block.\n",
    "      author_submission_rank_multi_iso = {}\n",
    "      for author in author_submission_rank_old:\n",
    "          ir_rank = []\n",
    "          for i in range(len(author_submission_rank_old[author])):\n",
    "              r1 = author_submission_rank_old[author][i][2]\n",
    "              ir_rank.append(r1)\n",
    "          ir_rank = np.array(ir_rank)\n",
    "          ir_rank_pred =  isotonic_regression(ir_rank, sample_weight = None, y_min=0.0, y_max=10.0, increasing=False)\n",
    "\n",
    "          author_submission_rank_multi_iso[author] = []\n",
    "          for i in range(len(author_submission_rank_old[author])):\n",
    "              author_submission_rank_multi_iso[author].append((author_submission_rank_old[author][i][0], author_submission_rank_old[author][i][1], ir_rank_pred[i]))\n",
    "\n",
    "\n",
    "\n",
    "      # For multi-author submissions in a block, average the scores to get the isotonic score.\n",
    "      submission_multi_iso_rating = {}\n",
    "      for submission in paper_part:\n",
    "          submission_multi_iso_rating[submission] = []\n",
    "\n",
    "      for author in author_submission_rank_multi_iso:\n",
    "          for i in range(len(author_submission_rank_multi_iso[author])):\n",
    "              submission_multi_iso_rating[author_submission_rank_multi_iso[author][i][0]].append(author_submission_rank_multi_iso[author][i][2])\n",
    "\n",
    "      for submission in submission_multi_iso_rating:\n",
    "          submission_multi_iso_rating[submission] = [float(rating) for rating in submission_multi_iso_rating[submission]]\n",
    "          avg_rating = sum(submission_multi_iso_rating[submission])/len(submission_multi_iso_rating[submission])\n",
    "          submission_multi_iso_rating[submission] = avg_rating\n",
    "\n",
    "      for i in paper_part:\n",
    "        calibrated_scores[i] = submission_multi_iso_rating[i]\n",
    "\n",
    "    # Multi-owner Isotonic Score\n",
    "    multi_iso_rating = []\n",
    "    for i in range(n_2):\n",
    "      multi_iso_rating.append(calibrated_scores[i])\n",
    "\n",
    "\n",
    "\n",
    "    # Partition all the graph according to greedy algorithm\n",
    "    partition, author_parts = greedy(graph, m_2, n_2)\n",
    "    author_parts = validate(partition, graph, n_2)\n",
    "\n",
    "    calibrated_scores = np.zeros(n_2)\n",
    "    for part, author_part in zip(partition, author_parts):\n",
    "      if len(author_part) == 0:\n",
    "        for i in part: calibrated_scores[i] = df[df['submission_idx'] == i]['score'].tolist()[0]\n",
    "        continue\n",
    "      paper_part = list(part)\n",
    "\n",
    "      # Organize each block by {author: [submission, rank, score]}.\n",
    "      author_submission_rank_old = {}\n",
    "      for author in author_part:\n",
    "        author_submission_rank_old[author] = []\n",
    "        for i in range(len(paper_part)):\n",
    "            rank = df[(df['submission_idx'] == paper_part[i]) & (df['author_idx'] == author)]['rank'].tolist()[0]\n",
    "            ratings = df[(df['submission_idx'] == paper_part[i]) & (df['author_idx'] == author)]['score'].tolist()[0]\n",
    "            author_submission_rank_old[author].append((paper_part[i], rank, ratings))\n",
    "\n",
    "      # Sort submissions by rank; in case of ties, sort by score.\n",
    "      def sort_submissions(author_submission_rank_old):\n",
    "        for author in author_submission_rank_old:\n",
    "          author_submission_rank_old[author].sort(key=lambda x: (x[1], -x[2]), reverse=False)\n",
    "        return author_submission_rank_old\n",
    "      author_submission_rank_old = sort_submissions(author_submission_rank_old)\n",
    "\n",
    "\n",
    "\n",
    "      # Compute isotonic scores for each author in the block.\n",
    "      author_submission_rank_greedy_iso = {}\n",
    "      for author in author_submission_rank_old:\n",
    "          ir_rank = []\n",
    "          for i in range(len(author_submission_rank_old[author])):\n",
    "              r1 = author_submission_rank_old[author][i][2]\n",
    "              ir_rank.append(r1)\n",
    "          ir_rank = np.array(ir_rank)\n",
    "          ir_rank_pred =  isotonic_regression(ir_rank, sample_weight = None, y_min=0.0, y_max=10.0, increasing=False)\n",
    "\n",
    "          author_submission_rank_greedy_iso[author] = []\n",
    "          for i in range(len(author_submission_rank_old[author])):\n",
    "              author_submission_rank_greedy_iso[author].append((author_submission_rank_old[author][i][0], author_submission_rank_old[author][i][1], ir_rank_pred[i]))\n",
    "\n",
    "\n",
    "\n",
    "      # For multi-author submissions in a block, average the scores to get the isotonic score.\n",
    "      submission_greedy_iso_rating = {}\n",
    "      for submission in paper_part:\n",
    "          submission_greedy_iso_rating[submission] = []\n",
    "\n",
    "      for author in author_submission_rank_greedy_iso:\n",
    "          for i in range(len(author_submission_rank_greedy_iso[author])):\n",
    "              submission_greedy_iso_rating[author_submission_rank_greedy_iso[author][i][0]].append(author_submission_rank_greedy_iso[author][i][2])\n",
    "\n",
    "      for submission in submission_greedy_iso_rating:\n",
    "          submission_greedy_iso_rating[submission] = [float(rating) for rating in submission_greedy_iso_rating[submission]]\n",
    "          avg_rating = sum(submission_greedy_iso_rating[submission])/len(submission_greedy_iso_rating[submission])\n",
    "          submission_greedy_iso_rating[submission] = avg_rating\n",
    "\n",
    "      for i in paper_part:\n",
    "        calibrated_scores[i] = submission_greedy_iso_rating[i]\n",
    "\n",
    "\n",
    "\n",
    "    # Greedy Isotonic Score\n",
    "    greedy_iso_rating = []\n",
    "    for i in range(n_2):\n",
    "      greedy_iso_rating.append(calibrated_scores[i])\n",
    "\n",
    "    # proxy\n",
    "    submission_true_rating = {}\n",
    "    for submission in range(n_2):\n",
    "        submission_true_rating[submission] = df[df['submission_idx'] == submission]['proxy'].tolist()\n",
    "        submission_true_rating[submission] = submission_true_rating[submission][0]\n",
    "\n",
    "    True_score_multi_iso = []\n",
    "    for i in range(n_2):\n",
    "        True_score_multi_iso.append(submission_true_rating[i])\n",
    "\n",
    "\n",
    "    # score\n",
    "    old_rating = {}\n",
    "    for submission in range(n_2):\n",
    "        old_rating[submission] = df[df['submission_idx'] == submission]['score'].tolist()\n",
    "        old_rating[submission] = old_rating[submission][0]\n",
    "\n",
    "    old_score_multi_iso = []\n",
    "    for i in range(n_2):\n",
    "        old_score_multi_iso.append(old_rating[i])\n",
    "\n",
    "\n",
    "    # Create two lists to record: (y - R)^2 and (\\hat{R} - R)^2 values.\n",
    "    greedy_diff = []\n",
    "    multi_diff = []\n",
    "    old_diff = []\n",
    "    for i in range(len(True_score_multi_iso)):\n",
    "      greedy_diff.append( (greedy_iso_rating[i] - True_score_multi_iso[i])**2 )\n",
    "      multi_diff.append( (multi_iso_rating[i] - True_score_multi_iso[i])**2 )\n",
    "      old_diff.append( (old_score_multi_iso[i] - True_score_multi_iso[i])**2 )\n",
    "\n",
    "\n",
    "    greedy_diff_all.append(greedy_diff)\n",
    "    multi_diff_all.append(multi_diff)\n",
    "    old_diff_all.append(old_diff)\n",
    "\n",
    "\n",
    "# ==========================\n",
    "# After all files are processed, compute the average over all i\n",
    "# ==========================\n",
    "\n",
    "# Convert to numpy arrays for easier computation\n",
    "greedy_diff_all = np.array(greedy_diff_all)\n",
    "multi_diff_all = np.array(multi_diff_all)\n",
    "old_diff_all = np.array(old_diff_all)\n",
    "\n",
    "# Average across the 3 files (axis=0 is file_idx)\n",
    "greedy_diff_average = np.mean(greedy_diff_all, axis=0)\n",
    "multi_diff_average = np.mean(multi_diff_all, axis=0)\n",
    "old_diff_average = np.mean(old_diff_all, axis=0)\n",
    "\n",
    "# Final outputs\n",
    "print('Greedy_diff_average:', np.mean(greedy_diff_average))\n",
    "print('Multi_diff_average:', np.mean(multi_diff_average))\n",
    "print('old_diff_average:', np.mean(old_diff_average))\n",
    "\n",
    "#Perform the paired sample t-test\n",
    "t_statistic, p_value = stats.ttest_rel(old_diff_average, greedy_diff_average, alternative='greater')\n",
    "print(\"Before Rebuttal with proxy t-test for greedy:\", t_statistic)\n",
    "print(\"Before Rebuttal with proxy p-value for greedy:\", p_value)\n",
    "\n",
    "#Perform the paired sample t-test\n",
    "t_statistic, p_value = stats.ttest_rel(old_diff_average, multi_diff_average, alternative='greater')\n",
    "print(\"Before Rebuttal with proxy t-test for Multi-owner:\", t_statistic)\n",
    "print(\"Before Rebuttal with proxy p-value for Multi-owner:\", p_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2TZFKZQ1hb1s"
   },
   "source": [
    "## Compute L1 values for all submissions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 34915,
     "status": "ok",
     "timestamp": 1745896114561,
     "user": {
      "displayName": "Buxin Su",
      "userId": "12574803226597557409"
     },
     "user_tz": 240
    },
    "id": "s-7e228Shb10",
    "outputId": "099901ec-d5a4-4a0f-f9ed-78757b06b7d9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Greedy_diff_average: 1.1240108281412629\n",
      "Multi_diff_average: 1.136489608327553\n",
      "old_diff_average: 1.273618796662275\n",
      "Before Rebuttal with proxy t-test for greedy: 16.649052097738977\n",
      "Before Rebuttal with proxy p-value for greedy: 1.9278948001921145e-59\n",
      "Before Rebuttal with proxy t-test for Multi-owner: 16.892870107284295\n",
      "Before Rebuttal with proxy p-value for Multi-owner: 4.80100352077003e-61\n"
     ]
    }
   ],
   "source": [
    "# Initialize list to store squared differences for each run\n",
    "greedy_diff_all = []\n",
    "multi_diff_all = []\n",
    "old_diff_all = []\n",
    "\n",
    "for trail_idx in range(1,4):\n",
    "\n",
    "    # Load CSV file into a pandas DataFrame\n",
    "    df = pd.read_csv(f'proxy_score_{trail_idx}.csv')\n",
    "    df = df.drop_duplicates(['submission_idx', 'author_idx'])\n",
    "\n",
    "\n",
    "    # Extract the unique authors from the DataFrame\n",
    "    authors = df['author_idx'].unique()\n",
    "    submissions = df['submission_idx'].unique()\n",
    "\n",
    "    author_submission = {}\n",
    "    for author in authors:\n",
    "        submissionss = list( set(df[df['author_idx'] == author]['submission_idx'].tolist()) )\n",
    "        author_submission[author] = submissionss\n",
    "\n",
    "    m_2 = len(author_submission)\n",
    "    n_2 = len(submissions)\n",
    "\n",
    "    authors = []\n",
    "    for author in author_submission:\n",
    "        submission_ranking = {}\n",
    "        for i in range(len(author_submission[author])):\n",
    "            submission_ranking[author_submission[author][i]] = df[(df['submission_idx'] == author_submission[author][i]) & (df['author_idx'] == author)]['rank'].tolist()\n",
    "            submission_ranking[author_submission[author][i]] = submission_ranking[author_submission[author][i]][0]\n",
    "        authors.append(submission_ranking)\n",
    "\n",
    "    graph = {}\n",
    "    for i, author in enumerate(authors):\n",
    "        graph[i] = set( int(k) for k in author.keys())\n",
    "\n",
    "    # Partition all the graph according to Multi-owner algorithm\n",
    "    partition, author_parts = arbitrary(graph, m_2, n_2)\n",
    "    author_parts = validate(partition, graph, n_2)\n",
    "\n",
    "    calibrated_scores = np.zeros(n_2)\n",
    "    for part, author_part in zip(partition, author_parts):\n",
    "      if len(author_part) == 0:\n",
    "        for i in part: calibrated_scores[i] = df[df['submission_idx'] == i]['score'].tolist()[0]\n",
    "        continue\n",
    "      paper_part = list(part)\n",
    "\n",
    "      # Organize each block by {author: [submission, rank, score]}.\n",
    "      author_submission_rank_old = {}\n",
    "      for author in author_part:\n",
    "        author_submission_rank_old[author] = []\n",
    "        for i in range(len(paper_part)):\n",
    "            rank = df[(df['submission_idx'] == paper_part[i]) & (df['author_idx'] == author)]['rank'].tolist()[0]\n",
    "            ratings = df[(df['submission_idx'] == paper_part[i]) & (df['author_idx'] == author)]['score'].tolist()[0]\n",
    "            author_submission_rank_old[author].append((paper_part[i], rank, ratings))\n",
    "\n",
    "\n",
    "\n",
    "      # Sort submissions by rank; in case of ties, sort by score.\n",
    "      def sort_submissions(author_submission_rank_old):\n",
    "        for author in author_submission_rank_old:\n",
    "          author_submission_rank_old[author].sort(key=lambda x: (x[1], -x[2]), reverse=False)\n",
    "        return author_submission_rank_old\n",
    "      author_submission_rank_old = sort_submissions(author_submission_rank_old)\n",
    "\n",
    "\n",
    "\n",
    "      # Compute isotonic scores for each author in the block.\n",
    "      author_submission_rank_multi_iso = {}\n",
    "      for author in author_submission_rank_old:\n",
    "          ir_rank = []\n",
    "          for i in range(len(author_submission_rank_old[author])):\n",
    "              r1 = author_submission_rank_old[author][i][2]\n",
    "              ir_rank.append(r1)\n",
    "          ir_rank = np.array(ir_rank)\n",
    "          ir_rank_pred =  isotonic_regression(ir_rank, sample_weight = None, y_min=0.0, y_max=10.0, increasing=False)\n",
    "\n",
    "          author_submission_rank_multi_iso[author] = []\n",
    "          for i in range(len(author_submission_rank_old[author])):\n",
    "              author_submission_rank_multi_iso[author].append((author_submission_rank_old[author][i][0], author_submission_rank_old[author][i][1], ir_rank_pred[i]))\n",
    "\n",
    "\n",
    "\n",
    "      # For multi-author submissions in a block, average the scores to get the isotonic score.\n",
    "      submission_multi_iso_rating = {}\n",
    "      for submission in paper_part:\n",
    "          submission_multi_iso_rating[submission] = []\n",
    "\n",
    "      for author in author_submission_rank_multi_iso:\n",
    "          for i in range(len(author_submission_rank_multi_iso[author])):\n",
    "              submission_multi_iso_rating[author_submission_rank_multi_iso[author][i][0]].append(author_submission_rank_multi_iso[author][i][2])\n",
    "\n",
    "      for submission in submission_multi_iso_rating:\n",
    "          submission_multi_iso_rating[submission] = [float(rating) for rating in submission_multi_iso_rating[submission]]\n",
    "          avg_rating = sum(submission_multi_iso_rating[submission])/len(submission_multi_iso_rating[submission])\n",
    "          submission_multi_iso_rating[submission] = avg_rating\n",
    "\n",
    "      for i in paper_part:\n",
    "        calibrated_scores[i] = submission_multi_iso_rating[i]\n",
    "\n",
    "    # Multi-owner Isotonic Score\n",
    "    multi_iso_rating = []\n",
    "    for i in range(n_2):\n",
    "      multi_iso_rating.append(calibrated_scores[i])\n",
    "\n",
    "\n",
    "\n",
    "    # Partition all the graph according to greedy algorithm\n",
    "    partition, author_parts = greedy(graph, m_2, n_2)\n",
    "    author_parts = validate(partition, graph, n_2)\n",
    "\n",
    "    calibrated_scores = np.zeros(n_2)\n",
    "    for part, author_part in zip(partition, author_parts):\n",
    "      if len(author_part) == 0:\n",
    "        for i in part: calibrated_scores[i] = df[df['submission_idx'] == i]['score'].tolist()[0]\n",
    "        continue\n",
    "      paper_part = list(part)\n",
    "\n",
    "      # Organize each block by {author: [submission, rank, score]}.\n",
    "      author_submission_rank_old = {}\n",
    "      for author in author_part:\n",
    "        author_submission_rank_old[author] = []\n",
    "        for i in range(len(paper_part)):\n",
    "            rank = df[(df['submission_idx'] == paper_part[i]) & (df['author_idx'] == author)]['rank'].tolist()[0]\n",
    "            ratings = df[(df['submission_idx'] == paper_part[i]) & (df['author_idx'] == author)]['score'].tolist()[0]\n",
    "            author_submission_rank_old[author].append((paper_part[i], rank, ratings))\n",
    "\n",
    "      # Sort submissions by rank; in case of ties, sort by score.\n",
    "      def sort_submissions(author_submission_rank_old):\n",
    "        for author in author_submission_rank_old:\n",
    "          author_submission_rank_old[author].sort(key=lambda x: (x[1], -x[2]), reverse=False)\n",
    "        return author_submission_rank_old\n",
    "      author_submission_rank_old = sort_submissions(author_submission_rank_old)\n",
    "\n",
    "\n",
    "\n",
    "      # Compute isotonic scores for each author in the block.\n",
    "      author_submission_rank_greedy_iso = {}\n",
    "      for author in author_submission_rank_old:\n",
    "          ir_rank = []\n",
    "          for i in range(len(author_submission_rank_old[author])):\n",
    "              r1 = author_submission_rank_old[author][i][2]\n",
    "              ir_rank.append(r1)\n",
    "          ir_rank = np.array(ir_rank)\n",
    "          ir_rank_pred =  isotonic_regression(ir_rank, sample_weight = None, y_min=0.0, y_max=10.0, increasing=False)\n",
    "\n",
    "          author_submission_rank_greedy_iso[author] = []\n",
    "          for i in range(len(author_submission_rank_old[author])):\n",
    "              author_submission_rank_greedy_iso[author].append((author_submission_rank_old[author][i][0], author_submission_rank_old[author][i][1], ir_rank_pred[i]))\n",
    "\n",
    "\n",
    "\n",
    "      # For multi-author submissions in a block, average the scores to get the isotonic score.\n",
    "      submission_greedy_iso_rating = {}\n",
    "      for submission in paper_part:\n",
    "          submission_greedy_iso_rating[submission] = []\n",
    "\n",
    "      for author in author_submission_rank_greedy_iso:\n",
    "          for i in range(len(author_submission_rank_greedy_iso[author])):\n",
    "              submission_greedy_iso_rating[author_submission_rank_greedy_iso[author][i][0]].append(author_submission_rank_greedy_iso[author][i][2])\n",
    "\n",
    "      for submission in submission_greedy_iso_rating:\n",
    "          submission_greedy_iso_rating[submission] = [float(rating) for rating in submission_greedy_iso_rating[submission]]\n",
    "          avg_rating = sum(submission_greedy_iso_rating[submission])/len(submission_greedy_iso_rating[submission])\n",
    "          submission_greedy_iso_rating[submission] = avg_rating\n",
    "\n",
    "      for i in paper_part:\n",
    "        calibrated_scores[i] = submission_greedy_iso_rating[i]\n",
    "\n",
    "\n",
    "\n",
    "    # Greedy Isotonic Score\n",
    "    greedy_iso_rating = []\n",
    "    for i in range(n_2):\n",
    "      greedy_iso_rating.append(calibrated_scores[i])\n",
    "\n",
    "    # proxy\n",
    "    submission_true_rating = {}\n",
    "    for submission in range(n_2):\n",
    "        submission_true_rating[submission] = df[df['submission_idx'] == submission]['proxy'].tolist()\n",
    "        submission_true_rating[submission] = submission_true_rating[submission][0]\n",
    "\n",
    "    True_score_multi_iso = []\n",
    "    for i in range(n_2):\n",
    "        True_score_multi_iso.append(submission_true_rating[i])\n",
    "\n",
    "\n",
    "    # score\n",
    "    old_rating = {}\n",
    "    for submission in range(n_2):\n",
    "        old_rating[submission] = df[df['submission_idx'] == submission]['score'].tolist()\n",
    "        old_rating[submission] = old_rating[submission][0]\n",
    "\n",
    "    old_score_multi_iso = []\n",
    "    for i in range(n_2):\n",
    "        old_score_multi_iso.append(old_rating[i])\n",
    "\n",
    "\n",
    "    # Create two lists to record: (y - R)^2 and (\\hat{R} - R)^2 values.\n",
    "    greedy_diff = []\n",
    "    multi_diff = []\n",
    "    old_diff = []\n",
    "    for i in range(len(True_score_multi_iso)):\n",
    "      greedy_diff.append( abs(greedy_iso_rating[i] - True_score_multi_iso[i]) )\n",
    "      multi_diff.append( abs(multi_iso_rating[i] - True_score_multi_iso[i]) )\n",
    "      old_diff.append( abs(old_score_multi_iso[i] - True_score_multi_iso[i]) )\n",
    "\n",
    "\n",
    "    greedy_diff_all.append(greedy_diff)\n",
    "    multi_diff_all.append(multi_diff)\n",
    "    old_diff_all.append(old_diff)\n",
    "\n",
    "\n",
    "# ==========================\n",
    "# After all files are processed, compute the average over all i\n",
    "# ==========================\n",
    "\n",
    "# Convert to numpy arrays for easier computation\n",
    "greedy_diff_all = np.array(greedy_diff_all)\n",
    "multi_diff_all = np.array(multi_diff_all)\n",
    "old_diff_all = np.array(old_diff_all)\n",
    "\n",
    "# Average across the 3 files (axis=0 is file_idx)\n",
    "greedy_diff_average = np.mean(greedy_diff_all, axis=0)\n",
    "multi_diff_average = np.mean(multi_diff_all, axis=0)\n",
    "old_diff_average = np.mean(old_diff_all, axis=0)\n",
    "\n",
    "# Final outputs\n",
    "print('Greedy_diff_average:', np.mean(greedy_diff_average))\n",
    "print('Multi_diff_average:', np.mean(multi_diff_average))\n",
    "print('old_diff_average:', np.mean(old_diff_average))\n",
    "\n",
    "#Perform the paired sample t-test\n",
    "t_statistic, p_value = stats.ttest_rel(old_diff_average, greedy_diff_average, alternative='greater')\n",
    "print(\"Before Rebuttal with proxy t-test for greedy:\", t_statistic)\n",
    "print(\"Before Rebuttal with proxy p-value for greedy:\", p_value)\n",
    "\n",
    "#Perform the paired sample t-test\n",
    "t_statistic, p_value = stats.ttest_rel(old_diff_average, multi_diff_average, alternative='greater')\n",
    "print(\"Before Rebuttal with proxy t-test for Multi-owner:\", t_statistic)\n",
    "print(\"Before Rebuttal with proxy p-value for Multi-owner:\", p_value)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyMo3QWyxAcGthCjOCTnY8D6",
   "collapsed_sections": [
    "kPWWcc7LiVmU"
   ],
   "mount_file_id": "1ngu2BIK6f7Db0D82UHdK9A1J1Rc24O3S",
   "provenance": [
    {
     "file_id": "1ngu2BIK6f7Db0D82UHdK9A1J1Rc24O3S",
     "timestamp": 1736797473028
    }
   ],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
