{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Zd8s4wjVz-gv"
   },
   "source": [
    "# **Import Google Drive**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 15685,
     "status": "ok",
     "timestamp": 1745891717447,
     "user": {
      "displayName": "Buxin Su",
      "userId": "12574803226597557409"
     },
     "user_tz": 240
    },
    "id": "kpj7DF1k-jRR",
    "outputId": "a08f0293-d94b-477f-d175-7545dca1ba37"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7PcDKgM_0ElJ"
   },
   "source": [
    "# **Setting**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "executionInfo": {
     "elapsed": 10084,
     "status": "ok",
     "timestamp": 1745891727528,
     "user": {
      "displayName": "Buxin Su",
      "userId": "12574803226597557409"
     },
     "user_tz": 240
    },
    "id": "3LvEW5gO0E-K"
   },
   "outputs": [],
   "source": [
    "from sklearn.isotonic import isotonic_regression\n",
    "import cvxpy as cp\n",
    "import numpy as np\n",
    "import csv, os\n",
    "from scipy import stats\n",
    "from sklearn import metrics\n",
    "import itertools\n",
    "import pandas as pd\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import matplotlib.pyplot as plt\n",
    "import statistics\n",
    "from scipy.stats import levene\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=RuntimeWarning)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kPWWcc7LiVmU"
   },
   "source": [
    "# **Function: Partition all submissions according to \"Greedy\" and \"Multi-owner\" methods**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "executionInfo": {
     "elapsed": 55,
     "status": "ok",
     "timestamp": 1745891727593,
     "user": {
      "displayName": "Buxin Su",
      "userId": "12574803226597557409"
     },
     "user_tz": 240
    },
    "id": "AlzU8-hqiU4Z"
   },
   "outputs": [],
   "source": [
    "def validate(partition, graph, n):\n",
    "\t# check that\n",
    "\t# 1. each paper is in exactly one partition\n",
    "\t# 2. the number of papers in all partition is equal to the number of papers\n",
    "\t# 3. each partition has at least two authors owns all papers in the partition\n",
    "\n",
    "\tpapers = set()\n",
    "\tfull_author_parts = []\n",
    "\tfor part in partition[:-1]:\n",
    "\t\tassert( len(part.intersection(papers)) == 0 )\n",
    "\t\tpapers |= part\n",
    "\t\t# find all authors that can rank all papers in this part\n",
    "\t\tcnt = 0\n",
    "\t\tauthor_part = set()\n",
    "\t\tfor author, val in graph.items():\n",
    "\t\t\tif len(val.intersection(part)) == len(part):\n",
    "\t\t\t\tcnt += 1\n",
    "\t\t\t\tauthor_part.add(author)\n",
    "\n",
    "\t\t# assert( cnt >= 2 )\n",
    "\t\tfull_author_parts.append(author_part)\n",
    "\n",
    "\t# add the last partition\n",
    "\tfull_author_parts.append(set())\n",
    "\tpapers |= partition[-1]\n",
    "\tassert(len(papers) == n)\n",
    "\n",
    "\treturn full_author_parts\n",
    "\n",
    "\n",
    "def greedy(graph, m, n, randomize=False, level=1):\n",
    "\tpartition = []\n",
    "\tauthor_parts = []\n",
    "\tallocated_papers = set()\n",
    "\n",
    "\tif level == 1:\n",
    "\t\tparts = [ graph[i].copy() for i in range(m) ]\n",
    "\t\tindex2pair = [ set([i]) for i in range(m) ]\n",
    "\telif level == 2:\n",
    "\t\tparts = [ graph[i].intersection(graph[j])  for i in range(m) for j in range(i+1, m) ]\n",
    "\t\tindex2pair = [ set([i,j]) for i in range(m) for j in range(i+1, m) ]\n",
    "\n",
    "\tmax_idx = 0\n",
    "\tmax_val = 0\n",
    "\tactive_indices = set( [i for i in range(len(parts)) if len(parts[i]) > 1] )\n",
    "\t# for i in range(0, len(parts)):\n",
    "\tfor i in active_indices:\n",
    "\t\tif len(parts[i]) > max_val:\n",
    "\t\t\tmax_idx = i\n",
    "\t\t\tmax_val = len(parts[i])\n",
    "\n",
    "\twhile len(allocated_papers) < n and len(parts[max_idx]) > 1:\n",
    "\t\tmax_part = parts[max_idx].copy()\n",
    "\t\tpartition.append( max_part )\n",
    "\t\tauthor_parts.append( index2pair[max_idx] )\n",
    "\t\tallocated_papers |= max_part\n",
    "\n",
    "\t\tmax_idx = 0\n",
    "\t\tmax_val = 0\n",
    "\t\t# for i in range(0, len(parts)):\n",
    "\t\tto_remove = set()\n",
    "\t\tfor i in active_indices:\n",
    "\t\t\tparts[i].difference_update(max_part)\n",
    "\t\t\tif len(parts[i]) < 2:\n",
    "\t\t\t\tto_remove.add(i)\n",
    "\t\t\t\tcontinue\n",
    "\t\t\tif len(parts[i]) > max_val:\n",
    "\t\t\t\tmax_idx = i\n",
    "\t\t\t\tmax_val = len(parts[i])\n",
    "\t\tmax_part = parts[max_idx].copy()\n",
    "\t\tactive_indices.difference_update(to_remove)\n",
    "\n",
    "\t# add all remaining papers to the last partition\n",
    "\tpartition.append(set())\n",
    "\tauthor_parts.append(set())\n",
    "\tfor i in range(n):\n",
    "\t\tif i not in allocated_papers:\n",
    "\t\t\tpartition[-1].add(i)\n",
    "\n",
    "\treturn partition, author_parts\n",
    "\n",
    "\n",
    "def arbitrary(graph, m, n, randomize=False):\n",
    "\tpartition = []\n",
    "\tauthor_parts = []\n",
    "\tallocated_papers = set()\n",
    "\n",
    "\tparts = [ graph[i].copy() for i in range(m) ]\n",
    "\tindex2pair = [ set([i]) for i in range(m) ]\n",
    "\n",
    "\tidx = 0\n",
    "\twhile len(parts[idx]) < 2 and idx < len(parts)-1: idx += 1\n",
    "\n",
    "\twhile len(allocated_papers) < n and idx != -1:\n",
    "\t\tpart = parts[idx].copy()\n",
    "\n",
    "\t\tpartition.append( part )\n",
    "\t\tauthor_parts.append( index2pair[idx] )\n",
    "\t\tallocated_papers |= part\n",
    "\n",
    "\t\tidx = -1\n",
    "\t\tval = None\n",
    "\t\tfor i in range(0, len(parts)):\n",
    "\t\t\tparts[i].difference_update(part)\n",
    "\t\t\tif len(parts[i]) >= 2:\n",
    "\t\t\t\tidx = i\n",
    "\t\t\t\tval = len(parts[i])\n",
    "\n",
    "\tpartition.append(set())\n",
    "\tauthor_parts.append(set())\n",
    "\tfor i in range(n):\n",
    "\t\tif i not in allocated_papers:\n",
    "\t\t\tpartition[-1].add(i)\n",
    "\n",
    "\treturn partition, author_parts\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Uz9kGazNypcN"
   },
   "source": [
    "#**Generate outlier**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 1565,
     "status": "ok",
     "timestamp": 1745891729168,
     "user": {
      "displayName": "Buxin Su",
      "userId": "12574803226597557409"
     },
     "user_tz": 240
    },
    "id": "Z1BXWqzXym6A"
   },
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "df = pd.read_csv('proxy_score.csv')\n",
    "\n",
    "# Generate a unique random number for each submission_id\n",
    "np.random.seed(42)  # Optional: for reproducibility\n",
    "unique_submission_ids = df['submission_id'].unique()\n",
    "submission_outlier_map = {sub_id: np.random.randint(0, 11) for sub_id in unique_submission_ids}\n",
    "\n",
    "# Map the outlier values to the dataframe\n",
    "df['outlier'] = df['submission_id'].map(submission_outlier_map)\n",
    "\n",
    "# Compute 'score_outlier' as the average of 'score' and 'outlier'\n",
    "df['score_outlier'] = (df['score'] + df['outlier']) / 2\n",
    "\n",
    "# Save the modified dataset\n",
    "df.to_csv('proxy_score_with_outlier.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "F7Y3yIRN8_p2"
   },
   "source": [
    "# **Simple-averaging Isotonic Scores, Proxy**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RnkrFd1f0YIN"
   },
   "source": [
    "## Load CSV file into a pandas DataFrame\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 103,
     "status": "ok",
     "timestamp": 1745891729272,
     "user": {
      "displayName": "Buxin Su",
      "userId": "12574803226597557409"
     },
     "user_tz": 240
    },
    "id": "Ak-WjHX90Zv6"
   },
   "outputs": [],
   "source": [
    "# Load CSV file into a pandas DataFrame\n",
    "df = pd.read_csv(r'proxy_score_with_outlier.csv')\n",
    "df = df.drop_duplicates(['submission_idx', 'author_idx'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7mCPHu1C0bDc"
   },
   "source": [
    "## Organize each block by {author: [submission, rank, score]}.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "executionInfo": {
     "elapsed": 4224,
     "status": "ok",
     "timestamp": 1745891733505,
     "user": {
      "displayName": "Buxin Su",
      "userId": "12574803226597557409"
     },
     "user_tz": 240
    },
    "id": "Sx-FhyBm0ebi"
   },
   "outputs": [],
   "source": [
    "author_submission_rank_old = {}\n",
    "authors = df['author_idx'].unique()\n",
    "for author in authors:\n",
    "    author_submission_rank_old[author] = []\n",
    "    submissions = list(set(df[df['author_idx'] == author]['submission_idx'].tolist()))\n",
    "\n",
    "    for i in range(len(submissions)):\n",
    "        rank = df[(df['submission_idx'] == submissions[i]) & (df['author_idx'] == author)]['rank'].tolist()[0]\n",
    "        ratings = df[(df['submission_idx'] == submissions[i]) & (df['author_idx'] == author)]['score_outlier'].tolist()[0]\n",
    "        author_submission_rank_old[author].append((submissions[i], rank, ratings))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MFF6_8mg0pJZ"
   },
   "source": [
    "## Sort submissions by rank; in case of ties, sort by score.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1745891733506,
     "user": {
      "displayName": "Buxin Su",
      "userId": "12574803226597557409"
     },
     "user_tz": 240
    },
    "id": "aVSHptys0quM"
   },
   "outputs": [],
   "source": [
    "def sort_submissions(author_submission_rank_old):\n",
    "    for author in author_submission_rank_old:\n",
    "        author_submission_rank_old[author].sort(key=lambda x: (x[1], -x[2]), reverse=False)\n",
    "    return author_submission_rank_old\n",
    "\n",
    "author_submission_rank_old = sort_submissions(author_submission_rank_old)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BZUWHz7j0udU"
   },
   "source": [
    "## Compute isotonic scores for each author.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "executionInfo": {
     "elapsed": 292,
     "status": "ok",
     "timestamp": 1745891733795,
     "user": {
      "displayName": "Buxin Su",
      "userId": "12574803226597557409"
     },
     "user_tz": 240
    },
    "id": "KVQW_Pc70yTL"
   },
   "outputs": [],
   "source": [
    "author_submission_rank_new = {}\n",
    "for author in author_submission_rank_old:\n",
    "    ir_rank = []\n",
    "    for i in range(len(author_submission_rank_old[author])):\n",
    "        r1 = author_submission_rank_old[author][i][2]\n",
    "        ir_rank.append(r1)\n",
    "    ir_rank = np.array(ir_rank)\n",
    "    ir_rank_pred =  isotonic_regression(ir_rank, sample_weight = None, y_min=0.0, y_max=10.0, increasing=False)\n",
    "\n",
    "    author_submission_rank_new[author] = []\n",
    "    for i in range(len(author_submission_rank_old[author])):\n",
    "        author_submission_rank_new[author].append((author_submission_rank_old[author][i][0], author_submission_rank_old[author][i][1], ir_rank_pred[i]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bFKfCIwq00Bx"
   },
   "source": [
    "## For multi-author submissions, average the scores to get the isotonic score.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "executionInfo": {
     "elapsed": 31,
     "status": "ok",
     "timestamp": 1745891733828,
     "user": {
      "displayName": "Buxin Su",
      "userId": "12574803226597557409"
     },
     "user_tz": 240
    },
    "id": "hRHAlg3u01Xj"
   },
   "outputs": [],
   "source": [
    "final_submission_list = df['submission_idx'].unique()\n",
    "\n",
    "submission_new_rating = {}\n",
    "for submission in final_submission_list:\n",
    "    submission_new_rating[submission] = []\n",
    "\n",
    "for author in author_submission_rank_new:\n",
    "    for i in range(len(author_submission_rank_new[author])):\n",
    "      if author_submission_rank_new[author][i][0] in final_submission_list:\n",
    "        submission_new_rating[author_submission_rank_new[author][i][0]].append(author_submission_rank_new[author][i][2])\n",
    "\n",
    "for submission in final_submission_list:\n",
    "    submission_new_rating[submission] = [float(rating) for rating in submission_new_rating[submission]]\n",
    "    avg_rating = sum(submission_new_rating[submission])/len(submission_new_rating[submission])\n",
    "    submission_new_rating[submission] = avg_rating"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SdDxNarq1IiI"
   },
   "source": [
    "## Compute MSE values for all submissions and Plot.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2384,
     "status": "ok",
     "timestamp": 1745891736234,
     "user": {
      "displayName": "Buxin Su",
      "userId": "12574803226597557409"
     },
     "user_tz": 240
    },
    "id": "nbHJiLkM1QgC",
    "outputId": "40f347dd-a5e6-4303-c0ab-9f7769c0caa5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Simple-averaging Isotonic Mechanism 2.7635560299159283\n",
      "Review Rating 3.9505084541062807\n",
      "Before Rebuttal with proxy t-test for greedy: 18.768786056021035\n",
      "Before Rebuttal with proxy p-value for greedy: 5.494327891087578e-74\n"
     ]
    }
   ],
   "source": [
    "# Isotonic score\n",
    "adhoc_iso_rating = []\n",
    "for submission in final_submission_list:\n",
    "  adhoc_iso_rating.append(submission_new_rating[submission])\n",
    "\n",
    "\n",
    "\n",
    "# Proxy\n",
    "submission_true_rating = {}\n",
    "for submission in final_submission_list:\n",
    "    submission_true_rating[submission] = df[df['submission_idx'] == submission]['proxy'].tolist()\n",
    "    submission_true_rating[submission] = submission_true_rating[submission][0]\n",
    "\n",
    "True_score_multi_iso = []\n",
    "for submission in final_submission_list:\n",
    "    True_score_multi_iso.append(submission_true_rating[submission])\n",
    "\n",
    "\n",
    "\n",
    "# Score\n",
    "old_rating = {}\n",
    "for submission in final_submission_list:\n",
    "    old_rating[submission] = df[df['submission_idx'] == submission]['score_outlier'].tolist()\n",
    "    old_rating[submission] = old_rating[submission][0]\n",
    "\n",
    "old_score_multi_iso = []\n",
    "for submission in final_submission_list:\n",
    "    old_score_multi_iso.append(old_rating[submission])\n",
    "\n",
    "\n",
    "\n",
    "# Compute MSE\n",
    "print('Simple-averaging Isotonic Mechanism', mean_squared_error(adhoc_iso_rating, True_score_multi_iso))\n",
    "print('Review Rating', mean_squared_error(old_score_multi_iso, True_score_multi_iso))\n",
    "\n",
    "\n",
    "\n",
    "# Create two lists to record: (y - R)^2 and (\\hat{R} - R)^2 values.\n",
    "adhoc_diff = []\n",
    "old_diff = []\n",
    "for i in range(len(True_score_multi_iso)):\n",
    "  adhoc_diff.append( (adhoc_iso_rating[i] - True_score_multi_iso[i])**2 )\n",
    "  old_diff.append( (old_score_multi_iso[i] - True_score_multi_iso[i])**2 )\n",
    "\n",
    "\n",
    "\n",
    "#Perform the paired sample t-test\n",
    "t_statistic, p_value = stats.ttest_rel(old_diff, adhoc_diff, alternative='greater')\n",
    "print(\"Before Rebuttal with proxy t-test for greedy:\", t_statistic)\n",
    "print(\"Before Rebuttal with proxy p-value for greedy:\", p_value)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3WsD3-VNf2lD"
   },
   "source": [
    "## Compute L_1 values for all submissions and Plot.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2213,
     "status": "ok",
     "timestamp": 1745891738448,
     "user": {
      "displayName": "Buxin Su",
      "userId": "12574803226597557409"
     },
     "user_tz": 240
    },
    "id": "s01AsZfRf2lL",
    "outputId": "9e15b77e-bdbc-418a-ce9f-f3ce39769ec7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Simple-averaging Isotonic Mechanism 1.339168948201557\n",
      "Review Rating 1.6172266139657445\n",
      "Before Rebuttal with proxy t-test for greedy: 18.029082640056785\n",
      "Before Rebuttal with proxy p-value for greedy: 9.286977023896243e-69\n"
     ]
    }
   ],
   "source": [
    "# Isotonic score\n",
    "adhoc_iso_rating = []\n",
    "for submission in final_submission_list:\n",
    "  adhoc_iso_rating.append(submission_new_rating[submission])\n",
    "\n",
    "\n",
    "\n",
    "# Proxy\n",
    "submission_true_rating = {}\n",
    "for submission in final_submission_list:\n",
    "    submission_true_rating[submission] = df[df['submission_idx'] == submission]['proxy'].tolist()\n",
    "    submission_true_rating[submission] = submission_true_rating[submission][0]\n",
    "\n",
    "True_score_multi_iso = []\n",
    "for submission in final_submission_list:\n",
    "    True_score_multi_iso.append(submission_true_rating[submission])\n",
    "\n",
    "\n",
    "\n",
    "# Score\n",
    "old_rating = {}\n",
    "for submission in final_submission_list:\n",
    "    old_rating[submission] = df[df['submission_idx'] == submission]['score_outlier'].tolist()\n",
    "    old_rating[submission] = old_rating[submission][0]\n",
    "\n",
    "old_score_multi_iso = []\n",
    "for submission in final_submission_list:\n",
    "    old_score_multi_iso.append(old_rating[submission])\n",
    "\n",
    "\n",
    "\n",
    "# Create two lists to record: (y - R)^2 and (\\hat{R} - R)^2 values.\n",
    "adhoc_diff = []\n",
    "old_diff = []\n",
    "for i in range(len(True_score_multi_iso)):\n",
    "  adhoc_diff.append( abs(adhoc_iso_rating[i] - True_score_multi_iso[i]) )\n",
    "  old_diff.append( abs(old_score_multi_iso[i] - True_score_multi_iso[i]) )\n",
    "\n",
    "\n",
    "\n",
    "# Compute MSE\n",
    "print('Simple-averaging Isotonic Mechanism', np.mean(adhoc_diff) )\n",
    "print('Review Rating', np.mean(old_diff) )\n",
    "\n",
    "\n",
    "\n",
    "#Perform the paired sample t-test\n",
    "t_statistic, p_value = stats.ttest_rel(old_diff, adhoc_diff, alternative='greater')\n",
    "print(\"Before Rebuttal with proxy t-test for greedy:\", t_statistic)\n",
    "print(\"Before Rebuttal with proxy p-value for greedy:\", p_value)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kQQuVCdX2UKJ"
   },
   "source": [
    "# **Greedy/Multi-owner Isotonic Scores, Proxy**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "e27iIugz2grj"
   },
   "source": [
    "## Load CSV file into a pandas DataFrame\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 750,
     "status": "ok",
     "timestamp": 1745891739197,
     "user": {
      "displayName": "Buxin Su",
      "userId": "12574803226597557409"
     },
     "user_tz": 240
    },
    "id": "tn0ZcvFA2g_a"
   },
   "outputs": [],
   "source": [
    "# Load CSV file into a pandas DataFrame\n",
    "df = pd.read_csv(r'proxy_score_with_outlier.csv')\n",
    "df = df.drop_duplicates(['submission_idx', 'author_idx'])\n",
    "\n",
    "\n",
    "# Extract the unique authors from the DataFrame\n",
    "authors = df['author_idx'].unique()\n",
    "submissions = df['submission_idx'].unique()\n",
    "\n",
    "author_submission = {}\n",
    "for author in authors:\n",
    "    submissionss = list( set(df[df['author_idx'] == author]['submission_idx'].tolist()) )\n",
    "    author_submission[author] = submissionss\n",
    "\n",
    "m_2 = len(author_submission)\n",
    "n_2 = len(submissions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lSrynyyK2pdI"
   },
   "source": [
    "## Organize all the authors and submissions as the following 'graph': authors = [..., {..., paper_idx : ranking, ...}, ...]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "executionInfo": {
     "elapsed": 2214,
     "status": "ok",
     "timestamp": 1745891741423,
     "user": {
      "displayName": "Buxin Su",
      "userId": "12574803226597557409"
     },
     "user_tz": 240
    },
    "id": "uNDek9xm2pth"
   },
   "outputs": [],
   "source": [
    "authors = []\n",
    "for author in author_submission:\n",
    "    submission_ranking = {}\n",
    "    for i in range(len(author_submission[author])):\n",
    "        submission_ranking[author_submission[author][i]] = df[(df['submission_idx'] == author_submission[author][i]) & (df['author_idx'] == author)]['rank'].tolist()\n",
    "        submission_ranking[author_submission[author][i]] = submission_ranking[author_submission[author][i]][0]\n",
    "    authors.append(submission_ranking)\n",
    "\n",
    "graph = {}\n",
    "for i, author in enumerate(authors):\n",
    "    graph[i] = set( int(k) for k in author.keys())\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aZOd2Vb63M-W"
   },
   "source": [
    "## Multi-owner Isotonic\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "executionInfo": {
     "elapsed": 4019,
     "status": "ok",
     "timestamp": 1745891745455,
     "user": {
      "displayName": "Buxin Su",
      "userId": "12574803226597557409"
     },
     "user_tz": 240
    },
    "id": "JprHQPzQ3wBU"
   },
   "outputs": [],
   "source": [
    "# Partition all the graph according to Multi-owner algorithm\n",
    "partition, author_parts = arbitrary(graph, m_2, n_2)\n",
    "author_parts = validate(partition, graph, n_2)\n",
    "\n",
    "calibrated_scores = np.zeros(n_2)\n",
    "for part, author_part in zip(partition, author_parts):\n",
    "  if len(author_part) == 0:\n",
    "    for i in part: calibrated_scores[i] = df[df['submission_idx'] == i]['score_outlier'].tolist()[0]\n",
    "    continue\n",
    "  paper_part = list(part)\n",
    "\n",
    "\n",
    "\n",
    "  # Organize each block by {author: [submission, rank, score]}.\n",
    "  author_submission_rank_old = {}\n",
    "  for author in author_part:\n",
    "    author_submission_rank_old[author] = []\n",
    "    for i in range(len(paper_part)):\n",
    "        rank = df[(df['submission_idx'] == paper_part[i]) & (df['author_idx'] == author)]['rank'].tolist()[0]\n",
    "        ratings = df[(df['submission_idx'] == paper_part[i]) & (df['author_idx'] == author)]['score_outlier'].tolist()[0]\n",
    "        author_submission_rank_old[author].append((paper_part[i], rank, ratings))\n",
    "\n",
    "\n",
    "\n",
    "  # Sort submissions by rank; in case of ties, sort by score.\n",
    "  def sort_submissions(author_submission_rank_old):\n",
    "    for author in author_submission_rank_old:\n",
    "      author_submission_rank_old[author].sort(key=lambda x: (x[1], -x[2]), reverse=False)\n",
    "    return author_submission_rank_old\n",
    "  author_submission_rank_old = sort_submissions(author_submission_rank_old)\n",
    "\n",
    "\n",
    "\n",
    "  # Compute isotonic scores for each author in the block.\n",
    "  author_submission_rank_multi_iso = {}\n",
    "  for author in author_submission_rank_old:\n",
    "      ir_rank = []\n",
    "      for i in range(len(author_submission_rank_old[author])):\n",
    "          r1 = author_submission_rank_old[author][i][2]\n",
    "          ir_rank.append(r1)\n",
    "      ir_rank = np.array(ir_rank)\n",
    "      ir_rank_pred =  isotonic_regression(ir_rank, sample_weight = None, y_min=0.0, y_max=10.0, increasing=False)\n",
    "\n",
    "      author_submission_rank_multi_iso[author] = []\n",
    "      for i in range(len(author_submission_rank_old[author])):\n",
    "          author_submission_rank_multi_iso[author].append((author_submission_rank_old[author][i][0], author_submission_rank_old[author][i][1], ir_rank_pred[i]))\n",
    "\n",
    "\n",
    "\n",
    "  # For multi-author submissions in a block, average the scores to get the isotonic score.\n",
    "  submission_multi_iso_rating = {}\n",
    "  for submission in paper_part:\n",
    "      submission_multi_iso_rating[submission] = []\n",
    "\n",
    "  for author in author_submission_rank_multi_iso:\n",
    "      for i in range(len(author_submission_rank_multi_iso[author])):\n",
    "          submission_multi_iso_rating[author_submission_rank_multi_iso[author][i][0]].append(author_submission_rank_multi_iso[author][i][2])\n",
    "\n",
    "  for submission in submission_multi_iso_rating:\n",
    "      submission_multi_iso_rating[submission] = [float(rating) for rating in submission_multi_iso_rating[submission]]\n",
    "      avg_rating = sum(submission_multi_iso_rating[submission])/len(submission_multi_iso_rating[submission])\n",
    "      submission_multi_iso_rating[submission] = avg_rating\n",
    "\n",
    "  for i in paper_part:\n",
    "    calibrated_scores[i] = submission_multi_iso_rating[i]\n",
    "\n",
    "\n",
    "\n",
    "# Multi-owner Isotonic Score\n",
    "multi_iso_rating = []\n",
    "for i in range(n_2):\n",
    "  multi_iso_rating.append(calibrated_scores[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9J4CQkym30mf"
   },
   "source": [
    "## Greedy Isotonic\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "executionInfo": {
     "elapsed": 3503,
     "status": "ok",
     "timestamp": 1745891748980,
     "user": {
      "displayName": "Buxin Su",
      "userId": "12574803226597557409"
     },
     "user_tz": 240
    },
    "id": "tPKDhzqM4aIB"
   },
   "outputs": [],
   "source": [
    "# Partition all the graph according to greedy algorithm\n",
    "partition, author_parts = greedy(graph, m_2, n_2)\n",
    "author_parts = validate(partition, graph, n_2)\n",
    "\n",
    "calibrated_scores = np.zeros(n_2)\n",
    "for part, author_part in zip(partition, author_parts):\n",
    "  if len(author_part) == 0:\n",
    "    for i in part: calibrated_scores[i] = df[df['submission_idx'] == i]['score_outlier'].tolist()[0]\n",
    "    continue\n",
    "  paper_part = list(part)\n",
    "\n",
    "\n",
    "\n",
    "  # Organize each block by {author: [submission, rank, score]}.\n",
    "  author_submission_rank_old = {}\n",
    "  for author in author_part:\n",
    "    author_submission_rank_old[author] = []\n",
    "    for i in range(len(paper_part)):\n",
    "        rank = df[(df['submission_idx'] == paper_part[i]) & (df['author_idx'] == author)]['rank'].tolist()[0]\n",
    "        ratings = df[(df['submission_idx'] == paper_part[i]) & (df['author_idx'] == author)]['score_outlier'].tolist()[0]\n",
    "        author_submission_rank_old[author].append((paper_part[i], rank, ratings))\n",
    "\n",
    "\n",
    "\n",
    "  # Sort submissions by rank; in case of ties, sort by score.\n",
    "  def sort_submissions(author_submission_rank_old):\n",
    "    for author in author_submission_rank_old:\n",
    "      author_submission_rank_old[author].sort(key=lambda x: (x[1], -x[2]), reverse=False)\n",
    "    return author_submission_rank_old\n",
    "  author_submission_rank_old = sort_submissions(author_submission_rank_old)\n",
    "\n",
    "\n",
    "\n",
    "  # Compute isotonic scores for each author in the block.\n",
    "  author_submission_rank_greedy_iso = {}\n",
    "  for author in author_submission_rank_old:\n",
    "      ir_rank = []\n",
    "      for i in range(len(author_submission_rank_old[author])):\n",
    "          r1 = author_submission_rank_old[author][i][2]\n",
    "          ir_rank.append(r1)\n",
    "      ir_rank = np.array(ir_rank)\n",
    "      ir_rank_pred =  isotonic_regression(ir_rank, sample_weight = None, y_min=0.0, y_max=10.0, increasing=False)\n",
    "\n",
    "      author_submission_rank_greedy_iso[author] = []\n",
    "      for i in range(len(author_submission_rank_old[author])):\n",
    "          author_submission_rank_greedy_iso[author].append((author_submission_rank_old[author][i][0], author_submission_rank_old[author][i][1], ir_rank_pred[i]))\n",
    "\n",
    "\n",
    "\n",
    "  # For multi-author submissions in a block, average the scores to get the isotonic score.\n",
    "  submission_greedy_iso_rating = {}\n",
    "  for submission in paper_part:\n",
    "      submission_greedy_iso_rating[submission] = []\n",
    "\n",
    "  for author in author_submission_rank_greedy_iso:\n",
    "      for i in range(len(author_submission_rank_greedy_iso[author])):\n",
    "          submission_greedy_iso_rating[author_submission_rank_greedy_iso[author][i][0]].append(author_submission_rank_greedy_iso[author][i][2])\n",
    "\n",
    "  for submission in submission_greedy_iso_rating:\n",
    "      submission_greedy_iso_rating[submission] = [float(rating) for rating in submission_greedy_iso_rating[submission]]\n",
    "      avg_rating = sum(submission_greedy_iso_rating[submission])/len(submission_greedy_iso_rating[submission])\n",
    "      submission_greedy_iso_rating[submission] = avg_rating\n",
    "\n",
    "  for i in paper_part:\n",
    "    calibrated_scores[i] = submission_greedy_iso_rating[i]\n",
    "\n",
    "\n",
    "\n",
    "# Greedy Isotonic Score\n",
    "greedy_iso_rating = []\n",
    "for i in range(n_2):\n",
    "  greedy_iso_rating.append(calibrated_scores[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Pb3YkCfz4b8T"
   },
   "source": [
    "## Compute MSE values for all submissions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1711,
     "status": "ok",
     "timestamp": 1745891750692,
     "user": {
      "displayName": "Buxin Su",
      "userId": "12574803226597557409"
     },
     "user_tz": 240
    },
    "id": "mCQnj1UK5KJY",
    "outputId": "0a7bfd75-7ae5-4fb1-f824-68f0b010423e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Greedy Isotonic Mechanism 2.8245348044165977\n",
      "Multiowner Isotonic Mechanism 2.9371673588086633\n",
      "Review Rating 3.9505084541062807\n",
      "Before Rebuttal with proxy t-test for greedy: 17.402671068682533\n",
      "Before Rebuttal with proxy p-value for greedy: 1.8568895111609705e-64\n",
      "Before Rebuttal with proxy t-test for multi-owner: 16.78409547969191\n",
      "Before Rebuttal with proxy p-value for multi-owner: 2.5066734120747304e-60\n"
     ]
    }
   ],
   "source": [
    "# proxy\n",
    "submission_true_rating = {}\n",
    "for submission in range(n_2):\n",
    "    submission_true_rating[submission] = df[df['submission_idx'] == submission]['proxy'].tolist()\n",
    "    submission_true_rating[submission] = submission_true_rating[submission][0]\n",
    "\n",
    "True_score_multi_iso = []\n",
    "for i in range(n_2):\n",
    "    True_score_multi_iso.append(submission_true_rating[i])\n",
    "\n",
    "\n",
    "\n",
    "# score\n",
    "old_rating = {}\n",
    "for submission in range(n_2):\n",
    "    old_rating[submission] = df[df['submission_idx'] == submission]['score_outlier'].tolist()\n",
    "    old_rating[submission] = old_rating[submission][0]\n",
    "\n",
    "old_score_multi_iso = []\n",
    "for i in range(n_2):\n",
    "    old_score_multi_iso.append(old_rating[i])\n",
    "\n",
    "\n",
    "\n",
    "# print the MSE\n",
    "print('Greedy Isotonic Mechanism', mean_squared_error(greedy_iso_rating, True_score_multi_iso))\n",
    "print('Multiowner Isotonic Mechanism', mean_squared_error(multi_iso_rating, True_score_multi_iso))\n",
    "#print('Singal Isotonic Mechanism:', mean_squared_error(iso_rating, True_score))\n",
    "print('Review Rating', mean_squared_error(old_score_multi_iso, True_score_multi_iso))\n",
    "\n",
    "\n",
    "\n",
    "# Create two lists to record: (y - R)^2 and (\\hat{R} - R)^2 values.\n",
    "greedy_diff = []\n",
    "multi_diff = []\n",
    "old_diff = []\n",
    "for i in range(len(True_score_multi_iso)):\n",
    "  greedy_diff.append( (greedy_iso_rating[i] - True_score_multi_iso[i])**2 )\n",
    "  multi_diff.append( (multi_iso_rating[i] - True_score_multi_iso[i])**2 )\n",
    "  old_diff.append( (old_score_multi_iso[i] - True_score_multi_iso[i])**2 )\n",
    "\n",
    "\n",
    "\n",
    "#Perform the paired sample t-test\n",
    "t_statistic, p_value = stats.ttest_rel(old_diff, greedy_diff, alternative='greater')\n",
    "print(\"Before Rebuttal with proxy t-test for greedy:\", t_statistic)\n",
    "print(\"Before Rebuttal with proxy p-value for greedy:\", p_value)\n",
    "\n",
    "\n",
    "\n",
    "#Perform the paired sample t-test\n",
    "t_statistic, p_value = stats.ttest_rel(old_diff, multi_diff, alternative='greater')\n",
    "print(\"Before Rebuttal with proxy t-test for multi-owner:\", t_statistic)\n",
    "print(\"Before Rebuttal with proxy p-value for multi-owner:\", p_value)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2TZFKZQ1hb1s"
   },
   "source": [
    "## Compute L1 values for all submissions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2271,
     "status": "ok",
     "timestamp": 1745891752964,
     "user": {
      "displayName": "Buxin Su",
      "userId": "12574803226597557409"
     },
     "user_tz": 240
    },
    "id": "s-7e228Shb10",
    "outputId": "3ef1ade8-8080-498f-c70a-2e02e52a34c4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Greedy Isotonic Mechanism 1.3446382723556636\n",
      "Multiowner Isotonic Mechanism 1.376582584082584\n",
      "Review Rating 1.6172266139657445\n",
      "Before Rebuttal with proxy t-test for greedy: 16.94115356475954\n",
      "Before Rebuttal with proxy p-value for greedy: 2.2990686127904982e-61\n",
      "Before Rebuttal with proxy t-test for multi-owner: 16.101443119507906\n",
      "Before Rebuttal with proxy p-value for multi-owner: 6.593380730666755e-56\n"
     ]
    }
   ],
   "source": [
    "# proxy\n",
    "submission_true_rating = {}\n",
    "for submission in range(n_2):\n",
    "    submission_true_rating[submission] = df[df['submission_idx'] == submission]['proxy'].tolist()\n",
    "    submission_true_rating[submission] = submission_true_rating[submission][0]\n",
    "\n",
    "True_score_multi_iso = []\n",
    "for i in range(n_2):\n",
    "    True_score_multi_iso.append(submission_true_rating[i])\n",
    "\n",
    "\n",
    "\n",
    "# score\n",
    "old_rating = {}\n",
    "for submission in range(n_2):\n",
    "    old_rating[submission] = df[df['submission_idx'] == submission]['score_outlier'].tolist()\n",
    "    old_rating[submission] = old_rating[submission][0]\n",
    "\n",
    "old_score_multi_iso = []\n",
    "for i in range(n_2):\n",
    "    old_score_multi_iso.append(old_rating[i])\n",
    "\n",
    "\n",
    "\n",
    "# Create two lists to record: (y - R)^2 and (\\hat{R} - R)^2 values.\n",
    "greedy_diff = []\n",
    "multi_diff = []\n",
    "old_diff = []\n",
    "for i in range(len(True_score_multi_iso)):\n",
    "  greedy_diff.append( abs(greedy_iso_rating[i] - True_score_multi_iso[i]) )\n",
    "  multi_diff.append( abs(multi_iso_rating[i] - True_score_multi_iso[i]) )\n",
    "  old_diff.append( abs(old_score_multi_iso[i] - True_score_multi_iso[i]) )\n",
    "\n",
    "\n",
    "\n",
    "# print the MSE\n",
    "print('Greedy Isotonic Mechanism', np.mean(greedy_diff) )\n",
    "print('Multiowner Isotonic Mechanism', np.mean(multi_diff) )\n",
    "print('Review Rating', np.mean(old_diff) )\n",
    "\n",
    "\n",
    "\n",
    "#Perform the paired sample t-test\n",
    "t_statistic, p_value = stats.ttest_rel(old_diff, greedy_diff, alternative='greater')\n",
    "print(\"Before Rebuttal with proxy t-test for greedy:\", t_statistic)\n",
    "print(\"Before Rebuttal with proxy p-value for greedy:\", p_value)\n",
    "\n",
    "\n",
    "\n",
    "#Perform the paired sample t-test\n",
    "t_statistic, p_value = stats.ttest_rel(old_diff, multi_diff, alternative='greater')\n",
    "print(\"Before Rebuttal with proxy t-test for multi-owner:\", t_statistic)\n",
    "print(\"Before Rebuttal with proxy p-value for multi-owner:\", p_value)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyM99M/6pLNwB6uYD107pPKH",
   "collapsed_sections": [
    "Zd8s4wjVz-gv",
    "7PcDKgM_0ElJ",
    "kPWWcc7LiVmU",
    "RnkrFd1f0YIN",
    "7mCPHu1C0bDc",
    "MFF6_8mg0pJZ",
    "BZUWHz7j0udU",
    "bFKfCIwq00Bx"
   ],
   "mount_file_id": "1ngu2BIK6f7Db0D82UHdK9A1J1Rc24O3S",
   "provenance": [
    {
     "file_id": "1ngu2BIK6f7Db0D82UHdK9A1J1Rc24O3S",
     "timestamp": 1736740144259
    }
   ],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
